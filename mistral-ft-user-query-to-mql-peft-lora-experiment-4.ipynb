{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06dcc636",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!sudo pip install -q transformers --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1b437fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.34.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef7ece4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!sudo pip install -q accelerate peft==0.4.0 bitsandbytes trl==0.4.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57fbc6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02bb11f9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/data/mistral/query-to-mql/training-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "219fed17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Query', 'MQL', 'Rationale'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8070e590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290a2a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b6b4c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c37f45b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model that you want to train from the Hugging Face hub\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "\n",
    "# The instruction dataset to use\n",
    "#dataset_name = \"\"\n",
    "\n",
    "# Fine-tuned model name\n",
    "#new_model = \"mistral-ft-peft-on-template_and_user_query-data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f2ceeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# QLoRA parameters\n",
    "################################################################################\n",
    "\n",
    "# LoRA attention dimension\n",
    "lora_r = 64\n",
    "\n",
    "# Alpha parameter for LoRA scaling\n",
    "lora_alpha = 16\n",
    "\n",
    "# Dropout probability for LoRA layers\n",
    "lora_dropout = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f83e1317",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# bitsandbytes parameters\n",
    "################################################################################\n",
    "\n",
    "# Activate 4-bit precision base model loading\n",
    "use_4bit = True\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "bnb_4bit_compute_dtype = \"float16\"\n",
    "\n",
    "# Quantization type (fp4 or nf4)\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "# Activate nested quantization for 4-bit base models (double quantization)\n",
    "use_nested_quant = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b95b0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# TrainingArguments parameters\n",
    "################################################################################\n",
    "\n",
    "# Output directory where the model predictions and checkpoints will be stored\n",
    "output_dir = \"/data/mistral/query-to-mql/oct-27\"\n",
    "\n",
    "# Number of training epochs\n",
    "num_train_epochs = 15\n",
    "\n",
    "# Enable fp16/bf16 training (set bf16 to True with an A100)\n",
    "# fp16 = False\n",
    "fp16 = True # not using quantisation\n",
    "bf16 = False\n",
    "\n",
    "# Batch size per GPU for training\n",
    "per_device_train_batch_size = 1\n",
    "\n",
    "# Batch size per GPU for evaluation\n",
    "per_device_eval_batch_size = 1\n",
    "\n",
    "# Number of update steps to accumulate the gradients for\n",
    "gradient_accumulation_steps = 1\n",
    "\n",
    "# Enable gradient checkpointing\n",
    "gradient_checkpointing = True\n",
    "\n",
    "\n",
    "# Maximum gradient normal (gradient clipping)\n",
    "max_grad_norm = 0.3\n",
    "\n",
    "# Initial learning rate (AdamW optimizer)\n",
    "learning_rate = 2e-4\n",
    "\n",
    "# Weight decay to apply to all layers except bias/LayerNorm weights\n",
    "weight_decay = 0.001\n",
    "\n",
    "# Optimizer to use\n",
    "optim = \"paged_adamw_32bit\"\n",
    "\n",
    "# Learning rate schedule (constant a bit better than cosine)\n",
    "lr_scheduler_type = \"constant\"\n",
    "\n",
    "# Number of training steps (overrides num_train_epochs)\n",
    "max_steps = 200\n",
    "\n",
    "# Ratio of steps for a linear warmup (from 0 to learning rate)\n",
    "warmup_ratio = 0.03\n",
    "\n",
    "# Group sequences into batches with same length\n",
    "# Saves memory and speeds up training considerably\n",
    "group_by_length = True\n",
    "\n",
    "# Save checkpoint every X updates steps\n",
    "save_steps = 20\n",
    "\n",
    "# Log every X updates steps\n",
    "logging_steps = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd83a980",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# SFT parameters\n",
    "################################################################################\n",
    "\n",
    "# Maximum sequence length to use\n",
    "max_seq_length = None\n",
    "\n",
    "# Pack multiple short examples in the same input sequence to increase efficiency\n",
    "packing = False\n",
    "\n",
    "# Load the entire model on the GPU 0\n",
    "device_map = {\"\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36063e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "promt_template_measure = \"\"\"<s>[INST]<<SYS>>\n",
    "Given the context : {context} and date reference: {date_input}, the query: {user_query}, is converted into below shown structured output.\n",
    "\n",
    "<</SYS>>\n",
    "[/INST]\n",
    "[MQL]\n",
    "{mql}\n",
    "[/MQL]\n",
    "\n",
    "the steps and rationale used to achieve above structured output is as below.\n",
    "{rationale}\n",
    "</s>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7303ea0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "promt_template = \"\"\"Given the context : {context} and date reference: {date_input}, the query: {user_query}, is converted into below shown structured output.\n",
    "[MQL]\n",
    "{mql}\n",
    "[/MQL]\n",
    "the steps and rationale used to achieve above structured output is as below.\n",
    "{rationale}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50d534e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Query', 'MQL', 'Rationale'], dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47730f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"{\n",
    "    \"MEASURE\": [{\"ENTITY\": \"Discount\", \"other names\": [\"discount\", \"discount rate\", \"discount value\", \"deduction\"]},\n",
    "                {\"ENTITY\": \"Purchase Vol\", \"other names\": [\"purchase\", \"purchase value\", \"purchase model\"]},\n",
    "                {\"ENTITY\": \"Quantity\", \"other names\": [\"quantity\", \"volume\"]},\n",
    "                {\"ENTITY\": \"Sales\", \"other names\": [\"sales\", \"sale\"]}],\n",
    "    \"DIMENSION\": [{\"ENTITY\": \"Sub-Category\", \"other names\": [\"sub-category\", \"sub category\", \"categories\", \"section\"]},\n",
    "                  {\"ENTITY\": \"Segment\", \"other names\": [\"segment\", \"segments\", \"units\", \"divisions\"]},\n",
    "                  {\"ENTITY\": \"Parts\", \"other names\": [\"parts\", \"part\", \"section\", \"divisions\"]},\n",
    "                  {\"ENTITY\": \"Country\", \"other names\": [\"country\", \"countries\"]}],\n",
    "    \"FILTER\": [{\"ENTITY\": \"Consumer\", \"other names\": [\"consumers\", \"consumer\"], \"parent\": \"Segment\"},\n",
    "               {\"ENTITY\": \"Phone\", \"other names\": [\"phone\", \"phones\", \"mobile phones\"], \"parent\": \"Sub-Category\"},\n",
    "               {\"ENTITY\": \"Binder\", \"other names\": [\"binders\", \"binder\"], \"parent\": \"Sub-Category\"},\n",
    "               {\"ENTITY\": \"Corporate\", \"other names\": [\"corporates\", \"corporate\"], \"parent\": \"Segment\"},\n",
    "               {\"ENTITY\": \"India\", \"other names\": [\"india\"], \"parent\": \"Country\"},\n",
    "               {\"ENTITY\": \"Dubai\", \"other names\": [\"dubai\"], \"parent\": \"Country\"}],\n",
    "    \"DERIVED MEASURE\": [{\"ENTITY\": \"Ratio\",\n",
    "             \"other names\": [\"ratio\", \"share\", \"contribution\", \"percentage\", \"proportion\", \"contributing\"]},\n",
    "            {\"ENTITY\": \"Why\", \"other names\": [\"why\", \"cause of\", \"reason for\", \"diagnose\"]},\n",
    "            {\"ENTITY\": \"contribution_to_growth\", \"other names\": [\"contribution to growth\", \"growth\", \"grown\"]},\n",
    "            {\"ENTITY\": \"kda_transactional\", \"other names\": [\"kda\", \"key drivers\", \"key driver\", \"drivers\", \"driver\"]},\n",
    "            {\"ENTITY\": \"Growth Rate\", \"other names\": [\"growth rate\", \"growth\", \"grown\"]},\n",
    "            {\"ENTITY\": \"correlation\",\n",
    "             \"other names\": [\"associate\", \"associated\", \"association\", \"associations\", \"correlate\", \"correlated\",\n",
    "                             \"correlation\", \"correlations\", \"relate\", \"related\", \"relation\", \"relations\",\n",
    "                             \"relationship\",\n",
    "                             \"relationships\"]}\n",
    "            ],\n",
    "    \"DATE VARIABLE\": [{\"ENTITY\": \"Order Date\", \"other names\": [\"order date\", \"date\", \"trend\", \"time\", \"when\", \"mom\", \"yoy\"]}]\n",
    "    }\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78a95227",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_input = {\n",
    "    \"start_date\": \"01/01/2020\",\n",
    "    \"end_date\": \"15/09/2023\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bc719f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fine_tuning_dataset(row):\n",
    "    mql = row['MQL']\n",
    "    user_query = row['Query']\n",
    "    rationale = row['Rationale']\n",
    "    formated = promt_template.format(context=context,\n",
    "                                             date_input=date_input,\n",
    "                                             user_query=user_query,\n",
    "                                             mql=mql,\n",
    "                                             rationale=rationale)\n",
    "    return formated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a558ea0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fine_tuning_dataset']=df.apply(create_fine_tuning_dataset, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0550eb5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['Query', 'MQL', 'Rationale'], inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f4c4086",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af0efa36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['fine_tuning_dataset'],\n",
       "    num_rows: 37\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "555e910f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Given the context : {\\n    \"MEASURE\": [{\"ENTITY\": \"Discount\", \"other names\": [\"discount\", \"discount rate\", \"discount value\", \"deduction\"]},\\n                {\"ENTITY\": \"Purchase Vol\", \"other names\": [\"purchase\", \"purchase value\", \"purchase model\"]},\\n                {\"ENTITY\": \"Quantity\", \"other names\": [\"quantity\", \"volume\"]},\\n                {\"ENTITY\": \"Sales\", \"other names\": [\"sales\", \"sale\"]}],\\n    \"DIMENSION\": [{\"ENTITY\": \"Sub-Category\", \"other names\": [\"sub-category\", \"sub category\", \"categories\", \"section\"]},\\n                  {\"ENTITY\": \"Segment\", \"other names\": [\"segment\", \"segments\", \"units\", \"divisions\"]},\\n                  {\"ENTITY\": \"Parts\", \"other names\": [\"parts\", \"part\", \"section\", \"divisions\"]},\\n                  {\"ENTITY\": \"Country\", \"other names\": [\"country\", \"countries\"]}],\\n    \"FILTER\": [{\"ENTITY\": \"Consumer\", \"other names\": [\"consumers\", \"consumer\"], \"parent\": \"Segment\"},\\n               {\"ENTITY\": \"Phone\", \"other names\": [\"phone\", \"phones\", \"mobile phones\"], \"parent\": \"Sub-Category\"},\\n               {\"ENTITY\": \"Binder\", \"other names\": [\"binders\", \"binder\"], \"parent\": \"Sub-Category\"},\\n               {\"ENTITY\": \"Corporate\", \"other names\": [\"corporates\", \"corporate\"], \"parent\": \"Segment\"},\\n               {\"ENTITY\": \"India\", \"other names\": [\"india\"], \"parent\": \"Country\"},\\n               {\"ENTITY\": \"Dubai\", \"other names\": [\"dubai\"], \"parent\": \"Country\"}],\\n    \"DERIVED MEASURE\": [{\"ENTITY\": \"Ratio\",\\n             \"other names\": [\"ratio\", \"share\", \"contribution\", \"percentage\", \"proportion\", \"contributing\"]},\\n            {\"ENTITY\": \"Why\", \"other names\": [\"why\", \"cause of\", \"reason for\", \"diagnose\"]},\\n            {\"ENTITY\": \"contribution_to_growth\", \"other names\": [\"contribution to growth\", \"growth\", \"grown\"]},\\n            {\"ENTITY\": \"kda_transactional\", \"other names\": [\"kda\", \"key drivers\", \"key driver\", \"drivers\", \"driver\"]},\\n            {\"ENTITY\": \"Growth Rate\", \"other names\": [\"growth rate\", \"growth\", \"grown\"]},\\n            {\"ENTITY\": \"correlation\",\\n             \"other names\": [\"associate\", \"associated\", \"association\", \"associations\", \"correlate\", \"correlated\",\\n                             \"correlation\", \"correlations\", \"relate\", \"related\", \"relation\", \"relations\",\\n                             \"relationship\",\\n                             \"relationships\"]}\\n            ],\\n    \"DATE VARIABLE\": [{\"ENTITY\": \"Order Date\", \"other names\": [\"order date\", \"date\", \"trend\", \"time\", \"when\", \"mom\", \"yoy\"]}]\\n    } and date reference: {\\'start_date\\': \\'01/01/2020\\', \\'end_date\\': \\'15/09/2023\\'}, the query: what is purchase across segments, is converted into below shown structured output.\\n[MQL]\\n{\\n    \"DIMENSION\": {\\n        \"segments\": [\\n            {\\n                \"ENTITY\": \"Segment\",\\n                \"RANK\": [\\n                    {\\n                        \"RANK ADJECTIVE\": \"\",\\n                        \"RANK VALUE\": \"\"\\n                    }\\n                ]\\n            }\\n        ]\\n    },\\n    \"MEASURE\": {\\n        \"purchase\": [\\n            {\\n                \"ENTITY\": \"Purchase Vol\",\\n                \"MEASURE CONSTRAINT\": [\\n                    {\\n                        \"COMPARISON VALUE\": \"\",\\n                        \"COMPARSION OPERATOR\": \"\"\\n                    }\\n                ]\\n            }\\n        ]\\n    }\\n}\\n[/MQL]\\nthe steps and rationale used to achieve above structured output is as below.\\nStep 1: Identify the main components of the query\\nIn the given query \"what is purchase across segments\", the main components are \"purchase\" and \"segments\".\\n\\nStep 2: Map the components to the context\\n- \"purchase\" can be mapped to the \\'Purchase Vol\\' entity under \\'MEASURE\\' in the context.\\n- \"segments\" can be mapped to the \\'Segment\\' entity under \\'DIMENSION\\' in the context.\\n\\nStep 3: Create the structured output\\n- For the \\'DIMENSION\\' part of the output, we include the \\'Segment\\' entity since the query asks for purchase across segments.\\n- For the \\'MEASURE\\' part of the output, we include the \\'Purchase Vol\\' entity as the query is asking for the purchase value.\\n\\nRationale:\\nThe structured output is created by identifying the main components of the query and mapping them to the given context. This helps in understanding the user\\'s intent and provides a structured format that can be used for further analysis or processing.\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset['fine_tuning_dataset'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68cc3cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer and model with QLoRA configuration\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed25c775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nf4'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb_4bit_quant_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6664ecee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e2c3788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU compatibility with bfloat16\n",
    "if compute_dtype == torch.float16 and use_4bit:\n",
    "    major, _ = torch.cuda.get_device_capability()\n",
    "    if major >= 8:\n",
    "        print(\"=\" * 80)\n",
    "        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n",
    "        print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a38e3e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f49a0ae",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "!sudo pip install -q pynvml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e994711a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpu': [{'fb_memory_usage': {'total': 16384.0,\n",
       "    'free': 15972.9375,\n",
       "    'unit': 'MiB'}}]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pynvml.smi import nvidia_smi\n",
    "nvsmi = nvidia_smi.getInstance()\n",
    "nvsmi.DeviceQuery('memory.free, memory.total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eec98fb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!df -H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "202bb865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ca0d0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ba0a15e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2892a1e3177c4a27a5fa1d3aa940d096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load base model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ef60f964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load LLaMA tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True,\n",
    "                                          # add_eos_token=True,\n",
    "                                          use_fast=False)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a6716c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1576"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(tokenizer.encode(df['fine_tuning_dataset'][i])) for i in range(df.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc5bf25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75ffc6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA configuration\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    target_modules = [\"q_proj\", \"v_proj\"],\n",
    "    r=lora_r,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85583ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7e30b281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training parameters\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    optim=optim,\n",
    "    save_steps=save_steps,\n",
    "#     eval_steps=50, # requires when eval_dataset is defined\n",
    "#     per_device_eval_batch_size=1, # Batch size for evaluation\n",
    "#     evaluation_strategy=\"steps\", # requires when eval_dataset is defined\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=5,\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    fp16=fp16,\n",
    "    bf16=bf16,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    max_steps=600,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    group_by_length=group_by_length,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    report_to=\"tensorboard\",\n",
    "#     load_best_model_at_end=True,\n",
    "#     save_total_limit=1,\n",
    "#     metric_for_best_model=\"eval_loss\",\n",
    "#     greater_is_better=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6ee91f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory footprint 4.551360512 GB\n",
      "Flops 87375.791259648 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "## Getting FLOPs of model\n",
    "\n",
    "model_flops = (\n",
    "  model.floating_point_ops(\n",
    "    {\n",
    "       \"input_ids\": torch.zeros(\n",
    "           (1, 2048)\n",
    "      )\n",
    "    }\n",
    "  )\n",
    "  * training_arguments.gradient_accumulation_steps\n",
    ")\n",
    "\n",
    "#print(model)\n",
    "print(\"Memory footprint\", model.get_memory_footprint() / 1e9, \"GB\")\n",
    "print(\"Flops\", model_flops / 1e9, \"GFLOPs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "de52effd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['fine_tuning_dataset'],\n",
       "    num_rows: 37\n",
       "})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e9aa438a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f8bf5981",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/peft/utils/other.py:122: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "334268640b204c78819b86992641dc73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/37 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set supervised fine-tuning parameters\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "#     eval_dataset=val_dataset,\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"fine_tuning_dataset\",\n",
    "    max_seq_length=2048,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing=packing,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d942d91c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5769042",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 19/600 01:37 < 55:28, 0.17 it/s, Epoch 0.49/17]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.893300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.753500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.552700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f0633f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuned model name\n",
    "new_model_name = \"mistral-ft-peft-v1-lr-64-with-more-data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5c3526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "trainer.model.save_pretrained(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c5cbfc1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): MistralForCausalLM(\n",
       "      (model): MistralModel(\n",
       "        (embed_tokens): Embedding(32000, 4096)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x MistralDecoderLayer(\n",
       "            (self_attn): MistralAttention(\n",
       "              (q_proj): Linear4bit(\n",
       "                in_features=4096, out_features=4096, bias=False\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "              (v_proj): Linear4bit(\n",
       "                in_features=4096, out_features=1024, bias=False\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "              (rotary_emb): MistralRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): MistralMLP(\n",
       "              (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "              (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "              (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "              (act_fn): SiLUActivation()\n",
       "            )\n",
       "            (input_layernorm): MistralRMSNorm()\n",
       "            (post_attention_layernorm): MistralRMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (norm): MistralRMSNorm()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84916548",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel, PeftConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3ad3884",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model_name = \"/data/mistral/query-to-mql/oct-27/checkpoint-100\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5e0e40bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model\n",
    "# del trainer\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fb064755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpu': [{'fb_memory_usage': {'total': 16384.0,\n",
       "    'free': 6580.9375,\n",
       "    'unit': 'MiB'}}]}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nvsmi = nvidia_smi.getInstance()\n",
    "nvsmi.DeviceQuery('memory.free, memory.total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e10ab609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15ab78300fa34c8bb5ee8b54d7fa0cd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# del model\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(new_model_name, device_map=\"auto\", torch_dtype=torch.bfloat16)\n",
    "model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a87991b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ad5254",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83d80e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4d7fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7be81f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_template_v1 = \"\"\"Given the context : {context} and date reference: {date_input}, the query: {user_query}, is converted into below shown structured output.\n",
    "[MQL]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbc1fd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4530b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f512be43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MistralForCausalLM(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8a9a2513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_template_query_v1(user_query):\n",
    "    inp = query_template_v1.format(context=context,\n",
    "                                   user_query=user_query,\n",
    "                                  date_input=date_input)\n",
    "    _inputs = tokenizer.encode(inp, return_tensors=\"pt\")\n",
    "    outputs = model.generate(input_ids=_inputs.to('cuda'), max_length= 1600, pad_token_id=tokenizer.eos_token_id)\n",
    "    output = tokenizer.decode(outputs[0])\n",
    "    output_new = output.split('[MQL]\\n')[1]\n",
    "    return output_new.split('\\n[/MQL]')[0], output\n",
    "#     return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd027c42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ab141b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user query:  show me the bottom 10 segments basis sales\n",
      "CPU times: user 35 s, sys: 1.04 s, total: 36 s\n",
      "Wall time: 36 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'DIMENSION': {'segments': [{'ENTITY': 'Segment',\n",
       "    'RANK': [{'RANK ADJECTIVE': 'bottom', 'RANK VALUE': '10'}]}]},\n",
       " 'MEASURE': {'sales': [{'ENTITY': 'Sales'}]}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "user_query = 'show me the bottom 10 segments basis sales'\n",
    "print('user query: ', user_query)\n",
    "output, raw = predict_template_query_v1(user_query=user_query)\n",
    "eval(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8c0d9f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user query:  top 2 and bottom 3 segments by sales\n",
      "CPU times: user 35 s, sys: 1.03 s, total: 36 s\n",
      "Wall time: 36 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'DIMENSION': {'segments': [{'ENTITY': 'Segment',\n",
       "    'RANK': [{'RANK ADJECTIVE': 'top', 'RANK VALUE': '2'},\n",
       "     {'RANK ADJECTIVE': 'bottom', 'RANK VALUE': '3'}]}]},\n",
       " 'MEASURE': {'sales': [{'ENTITY': 'Sales'}]}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "user_query = 'top 2 and bottom 3 segments by sales'\n",
    "print('user query: ', user_query)\n",
    "output, raw = predict_template_query_v1(user_query=user_query)\n",
    "eval(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "576f99f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user query:  top 2 segments and bottom 3 sub-category basis quantity\n",
      "CPU times: user 42.2 s, sys: 1.06 s, total: 43.2 s\n",
      "Wall time: 43.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'DIMENSION': {'segments': [{'ENTITY': 'Segment',\n",
       "    'RANK': [{'RANK ADJECTIVE': 'top', 'RANK VALUE': '2'}]}],\n",
       "  'sub-category': [{'ENTITY': 'Sub-Category',\n",
       "    'RANK': [{'RANK ADJECTIVE': 'bottom', 'RANK VALUE': '3'}]}]},\n",
       " 'MEASURE': {'quantity': [{'ENTITY': 'Quantity'}]}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "user_query = 'top 2 segments and bottom 3 sub-category basis quantity'\n",
    "print('user query: ', user_query)\n",
    "output, raw = predict_template_query_v1(user_query=user_query)\n",
    "eval(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2c99af15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user query:  quantity across segments except consumer and corporate in dubai\n",
      "CPU times: user 53.3 s, sys: 1.03 s, total: 54.3 s\n",
      "Wall time: 54.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'DIMENSION': {'segments': [{'ENTITY': 'Segment',\n",
       "    'RANK': [{'RANK ADJECTIVE': '', 'RANK VALUE': ''}]}]},\n",
       " 'FILTER': {'consumer': [{'ENTITY': 'Consumer',\n",
       "    'EXCLUDE': 'True',\n",
       "    'PARENT': 'Segment'}],\n",
       "  'corporate': [{'ENTITY': 'Corporate',\n",
       "    'EXCLUDE': 'True',\n",
       "    'PARENT': 'Segment'}],\n",
       "  'dubai': [{'ENTITY': 'Dubai', 'INCLUDE': 'True', 'PARENT': 'Country'}]},\n",
       " 'MEASURE': {'quantity': [{'ENTITY': 'Quantity',\n",
       "    'MEASURE CONSTRAINT': [{'COMPARISON VALUE': '',\n",
       "      'COMPARSION OPERATOR': ''}]}]}}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "user_query = 'quantity across segments except consumer and corporate in dubai'\n",
    "print('user query: ', user_query)\n",
    "output, raw = predict_template_query_v1(user_query=user_query)\n",
    "eval(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155e3b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a599fbf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b160ef5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e13e650",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a86402b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c05a18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "652444f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> Given the context : {\\n    \"MEASURE\": [{\"ENTITY\": \"Discount\", \"other names\": [\"discount\", \"discount rate\", \"discount value\", \"deduction\"]},\\n                {\"ENTITY\": \"Purchase Vol\", \"other names\": [\"purchase\", \"purchase value\", \"purchase model\"]},\\n                {\"ENTITY\": \"Quantity\", \"other names\": [\"quantity\", \"volume\"]},\\n                {\"ENTITY\": \"Sales\", \"other names\": [\"sales\", \"sale\"]}],\\n    \"DIMENSION\": [{\"ENTITY\": \"Sub-Category\", \"other names\": [\"sub-category\", \"sub category\", \"categories\", \"section\"]},\\n                  {\"ENTITY\": \"Segment\", \"other names\": [\"segment\", \"segments\", \"units\", \"divisions\"]},\\n                  {\"ENTITY\": \"Parts\", \"other names\": [\"parts\", \"part\", \"section\", \"divisions\"]},\\n                  {\"ENTITY\": \"Country\", \"other names\": [\"country\", \"countries\"]}],\\n    \"FILTER\": [{\"ENTITY\": \"Consumer\", \"other names\": [\"consumers\", \"consumer\"], \"parent\": \"Segment\"},\\n               {\"ENTITY\": \"Phone\", \"other names\": [\"phone\", \"phones\", \"mobile phones\"], \"parent\": \"Sub-Category\"},\\n               {\"ENTITY\": \"Binder\", \"other names\": [\"binders\", \"binder\"], \"parent\": \"Sub-Category\"},\\n               {\"ENTITY\": \"Corporate\", \"other names\": [\"corporates\", \"corporate\"], \"parent\": \"Segment\"},\\n               {\"ENTITY\": \"India\", \"other names\": [\"india\"], \"parent\": \"Country\"},\\n               {\"ENTITY\": \"Dubai\", \"other names\": [\"dubai\"], \"parent\": \"Country\"}],\\n    \"DERIVED MEASURE\": [{\"ENTITY\": \"Ratio\",\\n             \"other names\": [\"ratio\", \"share\", \"contribution\", \"percentage\", \"proportion\", \"contributing\"]},\\n            {\"ENTITY\": \"Why\", \"other names\": [\"why\", \"cause of\", \"reason for\", \"diagnose\"]},\\n            {\"ENTITY\": \"contribution_to_growth\", \"other names\": [\"contribution to growth\", \"growth\", \"grown\"]},\\n            {\"ENTITY\": \"kda_transactional\", \"other names\": [\"kda\", \"key drivers\", \"key driver\", \"drivers\", \"driver\"]},\\n            {\"ENTITY\": \"Growth Rate\", \"other names\": [\"growth rate\", \"growth\", \"grown\"]},\\n            {\"ENTITY\": \"correlation\",\\n             \"other names\": [\"associate\", \"associated\", \"association\", \"associations\", \"correlate\", \"correlated\",\\n                             \"correlation\", \"correlations\", \"relate\", \"related\", \"relation\", \"relations\",\\n                             \"relationship\",\\n                             \"relationships\"]}\\n            ],\\n    \"DATE VARIABLE\": [{\"ENTITY\": \"Order Date\", \"other names\": [\"order date\", \"date\", \"trend\", \"time\", \"when\", \"mom\", \"yoy\"]}]\\n    } and date reference: {\\'start_date\\': \\'01/01/2020\\', \\'end_date\\': \\'15/09/2023\\'}, the query: show me the top 2 segments basis sales, is converted into below shown structured output.\\n[MQL]\\n{\\n    \"DIMENSION\": {\\n        \"segments\": [\\n            {\\n                \"ENTITY\": \"Segment\",\\n                \"RANK\": [\\n                    {\\n                        \"RANK ADJECTIVE\": \"top\",\\n                        \"RANK VALUE\": \"2\"\\n                    }\\n                ]\\n            }\\n        ]\\n    },\\n    \"MEASURE\": {\\n        \"sales\": [\\n            {\\n                \"ENTITY\": \"Sales\"\\n            }\\n        ]\\n    }\\n}\\n[/MQL]\\nthe steps and rationale used to achieve above structured output is as below.\\nStep 1: Identify the main components of the query\\n- The query asks for the \"top 2 segments\" based on \"sales\".\\n\\nStep 2: Map the components to the context\\n- \"segments\" can be mapped to the \"Segment\" entity in the \\'DIMENSION\\' section of the context.\\n- \"sales\" can be mapped to the \"Sales\" entity in the \\'MEASURE\\' section of the context.\\n\\nStep 3: Create the structured output\\n- For the \"DIMENSION\" part of the output, we include the \"Segment\" entity and specify the ranking information (top 2) as a property of the entity.\\n- For the \"MEASURE\" part of the output, we include the \"Sales\" entity as the main measure.\\n\\nStep 4: Combine the structured output components\\n- Combine the \"DIMENSION\" and \"MEASURE\" parts of the output into a single structured output, which is the final output.\\n\\nRationale:\\n- The query is asking for a ranking of segments based on sales, so the main components are \"segments\" and \"sales\".\\n- The context provides the necessary entities for these components (Segment and Sales), so we can map them directly.\\n- The structured output is created by including the relevant entities and specifying the ranking information (top 2) for the \"DIMENSION\" part, and including the main measure (Sales) for the \"MEASURE\" part.\\n- Finally, the structured output is combined into a single output that includes both the \"DIMENSION\" and \"MEASURE\" parts.\\n\\nBy following these steps and using the provided context, the query \"show me the top 2 segments basis sales\" can be converted into a structured output that can be used for further analysis or processing.</s>'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec88bd26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08da2299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912f2759",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
