{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30a8dda2",
   "metadata": {},
   "source": [
    "Reference\n",
    "\n",
    "- https://github.com/adapter-hub/adapters\n",
    "- https://docs.adapterhub.ml/loading.html\n",
    "- https://docs.adapterhub.ml/adapter_composition.html\n",
    "\n",
    "\n",
    "-https://huggingface.co/docs/transformers/peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16059f19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting q\n",
      "  Using cached https://files.pythonhosted.org/packages/75/f0/ae942c0530d02092702211fd36d9a465e203f732789c84d0b96fbebe3039/q-2.7-py2.py3-none-any.whl\n",
      "Collecting transformers\n",
      "  Using cached https://files.pythonhosted.org/packages/12/dd/f17b11a93a9ca27728e12512d167eb1281c151c4c6881d3ab59eb58f4127/transformers-4.35.2-py3-none-any.whl\n",
      "Collecting tokenizers<0.19,>=0.14\n",
      "  Using cached https://files.pythonhosted.org/packages/ad/75/56230c5c65b226e707e1adbc759c19fdf1b20bb02c0276796b132c97118a/tokenizers-0.15.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting numpy>=1.17\n",
      "  Using cached https://files.pythonhosted.org/packages/98/5d/5738903efe0ecb73e51eb44feafba32bdba2081263d40c5043568ff60faf/numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting huggingface-hub<1.0,>=0.16.4\n",
      "  Using cached https://files.pythonhosted.org/packages/05/09/1945ca6ba3ad8ad6e2872ba682ce8d68c5e63c8e55458ed8ab4885709f1d/huggingface_hub-0.19.4-py3-none-any.whl\n",
      "Collecting requests\n",
      "  Using cached https://files.pythonhosted.org/packages/70/8e/0e2d847013cb52cd35b38c009bb167a1a26b2ce6cd6965bf26b47bc0bf44/requests-2.31.0-py3-none-any.whl\n",
      "Collecting safetensors>=0.3.1\n",
      "  Using cached https://files.pythonhosted.org/packages/b6/ae/ef743263a42e21e3722845678c809e3962b6f886453431e847d520839bf0/safetensors-0.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting tqdm>=4.27\n",
      "  Using cached https://files.pythonhosted.org/packages/00/e5/f12a80907d0884e6dff9c16d0c0114d81b8cd07dc3ae54c5e962cc83037e/tqdm-4.66.1-py3-none-any.whl\n",
      "Collecting packaging>=20.0\n",
      "  Using cached https://files.pythonhosted.org/packages/ec/1a/610693ac4ee14fcdf2d9bf3c493370e4f2ef7ae2e19217d7a237ff42367d/packaging-23.2-py3-none-any.whl\n",
      "Collecting filelock\n",
      "  Using cached https://files.pythonhosted.org/packages/81/54/84d42a0bee35edba99dee7b59a8d4970eccdd44b99fe728ed912106fc781/filelock-3.13.1-py3-none-any.whl\n",
      "Collecting pyyaml>=5.1\n",
      "  Using cached https://files.pythonhosted.org/packages/c8/6b/6600ac24725c7388255b2f5add93f91e58a5d7efaf4af244fdbcc11a541b/PyYAML-6.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached https://files.pythonhosted.org/packages/79/33/67c4ed826f5227655225c3feaaecd15afb8453e827334ddae95a7fba07ac/regex-2023.10.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Using cached https://files.pythonhosted.org/packages/67/32/9276db0647d8142da3d9ec1af536522081813005a9d7aaebbdba082967c1/fsspec-2023.12.0-py3-none-any.whl\n",
      "Collecting typing-extensions>=3.7.4.3\n",
      "  Using cached https://files.pythonhosted.org/packages/24/21/7d397a4b7934ff4028987914ac1044d3b7d52712f30e2ac7a2ae5bc86dd0/typing_extensions-4.8.0-py3-none-any.whl\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached https://files.pythonhosted.org/packages/c2/e7/a82b05cf63a603df6e68d59ae6a68bf5064484a0718ea5033660af4b54a9/idna-3.6-py3-none-any.whl\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Using cached https://files.pythonhosted.org/packages/96/94/c31f58c7a7f470d5665935262ebd7455c7e4c7782eb525658d3dbf4b9403/urllib3-2.1.0-py3-none-any.whl\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Using cached https://files.pythonhosted.org/packages/3d/09/d82fe4a34c5f0585f9ea1df090e2a71eb9bb1e469723053e1ee9f57c16f3/charset_normalizer-3.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached https://files.pythonhosted.org/packages/64/62/428ef076be88fa93716b576e4a01f919d25968913e817077a386fcbe4f42/certifi-2023.11.17-py3-none-any.whl\n",
      "\u001b[31mERROR: refractml 1.0.3 has requirement PyYAML==6.0, but you'll have pyyaml 6.0.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: refractml 1.0.3 has requirement urllib3==1.26.15, but you'll have urllib3 2.1.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: mosaic-utils 1.0.2 has requirement scikit-learn==1.2.1; python_version >= \"3.8\", but you'll have scikit-learn 1.3.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: jupyterlab 3.2.4 has requirement jupyter-server~=1.4, but you'll have jupyter-server 2.0.0a1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: jupyterlab-server 2.23.0 has requirement jsonschema>=4.17.3, but you'll have jsonschema 3.2.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: google-auth 2.22.0 has requirement urllib3<2.0, but you'll have urllib3 2.1.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: q, tqdm, packaging, idna, urllib3, charset-normalizer, certifi, requests, fsspec, filelock, pyyaml, typing-extensions, huggingface-hub, tokenizers, numpy, safetensors, regex, transformers\n",
      "Successfully installed certifi-2023.11.17 charset-normalizer-3.3.2 filelock-3.13.1 fsspec-2023.12.0 huggingface-hub-0.19.4 idna-3.6 numpy-1.24.4 packaging-23.2 pyyaml-6.0.1 q-2.7 regex-2023.10.3 requests-2.31.0 safetensors-0.4.1 tokenizers-0.15.0 tqdm-4.66.1 transformers-4.35.2 typing-extensions-4.8.0 urllib3-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95036ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f598ead7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "# from peft import LoraConfig, PeftModel\n",
    "# from trl import SFTTrainer\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da40f42d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d34574c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2db4ee962b77424788802d5e4ef63990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "################################################################################\n",
    "# bitsandbytes parameters\n",
    "################################################################################\n",
    "\n",
    "# Activate 4-bit precision base model loading\n",
    "use_4bit = True\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "bnb_4bit_compute_dtype = \"float16\"\n",
    "\n",
    "# Quantization type (fp4 or nf4)\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "# Activate nested quantization for 4-bit base models (double quantization)\n",
    "use_nested_quant = True\n",
    "\n",
    "\n",
    "# Load tokenizer and model with QLoRA configuration\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")\n",
    "\n",
    "\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "\n",
    "# Load base model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "#     quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "#     load_in_8bit=False\n",
    ")\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9bfc396",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c8ee55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d419d6b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6d1cada",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel, PeftConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be3dc802",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter1 = \"/data/mistral/query-to-mql/exp-10/nov-20/checkpoint-8000\"\n",
    "adapter2 = \"/data/mistral/query-to-mql/exp-10/nov-20/checkpoint-4000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d9da97a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Adapter with name adapter1 already exists. Please use a different name.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# using load_adapter\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_adapter\u001b[49m\u001b[43m(\u001b[49m\u001b[43madapter1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madapter_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43madapter1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/tmp/pip_packages/transformers/integrations/peft.py:147\u001b[0m, in \u001b[0;36mPeftAdapterMixin.load_adapter\u001b[0;34m(self, peft_model_id, adapter_name, revision, token, device_map, max_memory, offload_folder, offload_index, peft_config, adapter_state_dict, adapter_kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpeft\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m set_peft_model_state_dict\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hf_peft_config_loaded \u001b[38;5;129;01mand\u001b[39;00m adapter_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpeft_config:\n\u001b[0;32m--> 147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdapter with name \u001b[39m\u001b[38;5;132;01m{\u001b[39;00madapter_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m already exists. Please use a different name.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m peft_model_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m (adapter_state_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m peft_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    151\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou should either pass a `peft_model_id` or a `peft_config` and `adapter_state_dict` to load an adapter.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    152\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Adapter with name adapter1 already exists. Please use a different name."
     ]
    }
   ],
   "source": [
    "# using load_adapter\n",
    "\n",
    "model.load_adapter(adapter1, adapter_name = 'adapter1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2ff26322",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_adapter(adapter2, adapter_name = 'adapter2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aee93e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 ms, sys: 2.63 ms, total: 4.64 ms\n",
      "Wall time: 12.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model.set_adapter('adapter1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5a64e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.05 s, sys: 0 ns, total: 1.05 s\n",
      "Wall time: 376 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_to_merge = PeftModel.from_pretrained(model,adapter1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7565f1d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0bc149b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.1 s, sys: 4.36 ms, total: 1.11 s\n",
      "Wall time: 403 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): MistralForCausalLM(\n",
       "      (model): MistralModel(\n",
       "        (embed_tokens): Embedding(32000, 4096)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x MistralDecoderLayer(\n",
       "            (self_attn): MistralAttention(\n",
       "              (q_proj): Linear4bit(\n",
       "                in_features=4096, out_features=4096, bias=False\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "              (v_proj): Linear4bit(\n",
       "                in_features=4096, out_features=1024, bias=False\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "              (rotary_emb): MistralRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): MistralMLP(\n",
       "              (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "              (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "              (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "              (act_fn): SiLUActivation()\n",
       "            )\n",
       "            (input_layernorm): MistralRMSNorm()\n",
       "            (post_attention_layernorm): MistralRMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (norm): MistralRMSNorm()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_to_merge2 = PeftModel.from_pretrained(model,adapter2)\n",
    "model_to_merge2.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397dbf9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f8218699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_template_query_v1(user_query):\n",
    "    inp = query_template_v1.format(context=context,\n",
    "                                   user_query=user_query,\n",
    "                                  date_input=date_input)\n",
    "    _inputs = tokenizer.encode(inp, return_tensors=\"pt\").to('cuda')\n",
    "    outputs = model.generate(input_ids=_inputs, max_length= 1200, pad_token_id=tokenizer.eos_token_id)\n",
    "    output = tokenizer.decode(outputs[0])\n",
    "    output_new = output.split('[MQL]\\n')[1]\n",
    "    return output_new.split('\\n[/MQL]')[0], output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bf712a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "352b4efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user query:  what is purchase across segments\n",
      "----------------------------------------------------------------------------------------------------\n",
      "time taken :  482.13821148872375\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "user_query = 'what is purchase across segments'\n",
    "print('user query: ', user_query)\n",
    "print('-'*100)\n",
    "output, raw = predict_template_query_v1(user_query=user_query)\n",
    "print(\"time taken : \", time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b3ca998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'DIMENSION': {'segments': [{'ENTITY': 'Segment', 'RANK': [{'RANK ADJECTIVE': '', 'RANK VALUE': ''}]}]}, 'MEASURE': {'purchase': [{'ENTITY': 'Purchase Vol', 'MEASURE CONSTRAINT': [{'COMPARISON VALUE': '', 'COMPARSION OPERATOR': ''}]}]}}\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "115101e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"{\n",
    "    \"MEASURE\": [{\"ENTITY\": \"Discount\", \"other names\": [\"discount\", \"discount rate\", \"discount value\", \"deduction\"]},\n",
    "                {\"ENTITY\": \"Purchase Vol\", \"other names\": [\"purchase\", \"purchase value\", \"purchase model\"]},\n",
    "                {\"ENTITY\": \"Quantity\", \"other names\": [\"quantity\", \"volume\"]},\n",
    "                {\"ENTITY\": \"Sales\", \"other names\": [\"sales\", \"sale\"]}],\n",
    "    \"DIMENSION\": [{\"ENTITY\": \"Sub-Category\", \"other names\": [\"sub-category\", \"sub category\", \"categories\", \"section\"]},\n",
    "                  {\"ENTITY\": \"Segment\", \"other names\": [\"segment\", \"segments\", \"units\", \"divisions\"]},\n",
    "                  {\"ENTITY\": \"Parts\", \"other names\": [\"parts\", \"part\", \"section\", \"divisions\"]},\n",
    "                  {\"ENTITY\": \"Country\", \"other names\": [\"country\", \"countries\"]}],\n",
    "    \"FILTER\": [{\"ENTITY\": \"Consumer\", \"other names\": [\"consumers\", \"consumer\"], \"parent\": \"Segment\"},\n",
    "               {\"ENTITY\": \"Phone\", \"other names\": [\"phone\", \"phones\", \"mobile phones\"], \"parent\": \"Sub-Category\"},\n",
    "               {\"ENTITY\": \"Binder\", \"other names\": [\"binders\", \"binder\"], \"parent\": \"Sub-Category\"},\n",
    "               {\"ENTITY\": \"Corporate\", \"other names\": [\"corporates\", \"corporate\"], \"parent\": \"Segment\"},\n",
    "               {\"ENTITY\": \"India\", \"other names\": [\"india\"], \"parent\": \"Country\"},\n",
    "               {\"ENTITY\": \"Dubai\", \"other names\": [\"dubai\"], \"parent\": \"Country\"}],\n",
    "    \"DERIVED MEASURE\": [{\"ENTITY\": \"Ratio\",\n",
    "             \"other names\": [\"ratio\", \"share\", \"contribution\", \"percentage\", \"proportion\", \"contributing\"]},\n",
    "            {\"ENTITY\": \"Why\", \"other names\": [\"why\", \"cause of\", \"reason for\", \"diagnose\"]},\n",
    "            {\"ENTITY\": \"contribution_to_growth\", \"other names\": [\"contribution to growth\", \"growth\", \"grown\"]},\n",
    "            {\"ENTITY\": \"kda_transactional\", \"other names\": [\"kda\", \"key drivers\", \"key driver\", \"drivers\", \"driver\"]},\n",
    "            {\"ENTITY\": \"Growth Rate\", \"other names\": [\"growth rate\", \"growth\", \"grown\"]},\n",
    "            {\"ENTITY\": \"correlation\",\n",
    "             \"other names\": [\"associate\", \"associated\", \"association\", \"associations\", \"correlate\", \"correlated\",\n",
    "                             \"correlation\", \"correlations\", \"relate\", \"related\", \"relation\", \"relations\",\n",
    "                             \"relationship\",\n",
    "                             \"relationships\"]}\n",
    "            ],\n",
    "    \"DATE VARIABLE\": [{\"ENTITY\": \"Order Date\", \"other names\": [\"order date\", \"date\", \"trend\", \"time\", \"when\", \"mom\", \"yoy\"]}]\n",
    "    }\"\"\"\n",
    "\n",
    "date_input = {\n",
    "    \"start_date\": \"01/01/2020\",\n",
    "    \"end_date\": \"15/09/2023\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20d90d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_template_v1 = \"\"\"Given the context : {context} and date reference: {date_input}, the query: {user_query}, is converted into below shown structured output.\n",
    "[MQL]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83e8902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = AutoAdapterModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "\n",
    "model.load_adapter(\"AdapterHub/roberta-base-pf-imdb\", source=\"hf\", set_active=True)\n",
    "\n",
    "print(model(**tokenizer(\"This works great!\", return_tensors=\"pt\")).logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81afbc4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c5a283",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7863ff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efc8830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86b39c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc51a585",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
