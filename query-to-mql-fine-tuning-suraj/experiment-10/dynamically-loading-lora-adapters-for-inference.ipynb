{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30a8dda2",
   "metadata": {},
   "source": [
    "Reference\n",
    "\n",
    "- https://github.com/adapter-hub/adapters\n",
    "- https://docs.adapterhub.ml/loading.html\n",
    "- https://docs.adapterhub.ml/adapter_composition.html\n",
    "\n",
    "\n",
    "-https://huggingface.co/docs/transformers/peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2a65d29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!sudo -H pip install -Uq transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95036ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f598ead7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "# from peft import LoraConfig, PeftModel\n",
    "# from trl import SFTTrainer\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da40f42d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d34574c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a5262fba4d74912b2ad9e6f07987d6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "################################################################################\n",
    "# bitsandbytes parameters\n",
    "################################################################################\n",
    "\n",
    "# Activate 4-bit precision base model loading\n",
    "use_4bit = True\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "bnb_4bit_compute_dtype = \"float16\"\n",
    "\n",
    "# Quantization type (fp4 or nf4)\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "# Activate nested quantization for 4-bit base models (double quantization)\n",
    "use_nested_quant = True\n",
    "\n",
    "\n",
    "# Load tokenizer and model with QLoRA configuration\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")\n",
    "\n",
    "\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "\n",
    "# Load base model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "#     quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "#     load_in_8bit=False,\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28238ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39c683f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90596209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting peft\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/0b/8402305043884c76a9d98e5e924c3f2211c75b02acd5b742e6c45d70506d/peft-0.6.2-py3-none-any.whl (174kB)\n",
      "\u001b[K     |████████████████████████████████| 184kB 4.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.8/site-packages (from peft) (2.0.1+cpu)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from peft) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from peft) (1.21.1)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.8/site-packages (from peft) (6.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.8/site-packages (from peft) (5.9.5)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.8/site-packages (from peft) (4.35.2)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.8/site-packages (from peft) (0.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from peft) (23.0)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.8/site-packages (from peft) (0.21.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->peft) (3.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->peft) (4.1.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->peft) (3.1.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->peft) (1.11.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->peft) (3.9.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers->peft) (2.29.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.8/site-packages (from transformers->peft) (0.16.4)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.8/site-packages (from transformers->peft) (0.15.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers->peft) (2023.6.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.8/site-packages (from sympy->torch>=1.13.0->peft) (1.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers->peft) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers->peft) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests->transformers->peft) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers->peft) (3.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers->peft) (2023.6.0)\n",
      "Installing collected packages: peft\n",
      "Successfully installed peft-0.6.2\n"
     ]
    }
   ],
   "source": [
    "!sudo -H pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06e6a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel, PeftConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6c92c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter1 = \"/data/mistral/query-to-mql/exp-10/nov-20/checkpoint-8000\"\n",
    "adapter2 = \"/data/mistral/query-to-mql/exp-10/nov-20/checkpoint-4000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1602ac6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "PEFT is not installed. Please install it with `pip install peft`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# using load_adapter\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_adapter\u001b[49m\u001b[43m(\u001b[49m\u001b[43madapter1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madapter_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43madapter1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/packages/Transformers_CPU/8d52bc28-4231-418c-8b06-7a9c433a1b7a/3.8/transformers/integrations/peft.py:137\u001b[0m, in \u001b[0;36mPeftAdapterMixin.load_adapter\u001b[0;34m(self, peft_model_id, adapter_name, revision, token, device_map, max_memory, offload_folder, offload_index, peft_config, adapter_state_dict, adapter_kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_adapter\u001b[39m(\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     71\u001b[0m     peft_model_id: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     81\u001b[0m     adapter_kwargs: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     82\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m    Load adapter weights from file or remote Hub folder. If you are not familiar with adapters and PEFT methods, we\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m    invite you to read more about them on PEFT official documentation: https://huggingface.co/docs/peft\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m            `find_adapter_config_file` method.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[43mcheck_peft_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmin_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMIN_PEFT_VERSION\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m     adapter_name \u001b[38;5;241m=\u001b[39m adapter_name \u001b[38;5;28;01mif\u001b[39;00m adapter_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m adapter_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/packages/Transformers_CPU/8d52bc28-4231-418c-8b06-7a9c433a1b7a/3.8/transformers/utils/peft_utils.py:115\u001b[0m, in \u001b[0;36mcheck_peft_version\u001b[0;34m(min_version)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03mChecks if the version of PEFT is compatible.\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m        The version of PEFT to check against.\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_peft_available():\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPEFT is not installed. Please install it with `pip install peft`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    117\u001b[0m is_peft_version_compatible \u001b[38;5;241m=\u001b[39m version\u001b[38;5;241m.\u001b[39mparse(importlib\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mversion(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpeft\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m version\u001b[38;5;241m.\u001b[39mparse(min_version)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_peft_version_compatible:\n",
      "\u001b[0;31mValueError\u001b[0m: PEFT is not installed. Please install it with `pip install peft`"
     ]
    }
   ],
   "source": [
    "# using load_adapter\n",
    "\n",
    "model.load_adapter(adapter1, adapter_name = 'adapter1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e365bedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_adapter(adapter2, adapter_name = 'adapter2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "45604988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 ms, sys: 2.63 ms, total: 4.64 ms\n",
      "Wall time: 12.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model.set_adapter('adapter1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01a36a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.05 s, sys: 0 ns, total: 1.05 s\n",
      "Wall time: 376 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_to_merge = PeftModel.from_pretrained(model,adapter1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb748ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9452b260",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.1 s, sys: 4.36 ms, total: 1.11 s\n",
      "Wall time: 403 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): MistralForCausalLM(\n",
       "      (model): MistralModel(\n",
       "        (embed_tokens): Embedding(32000, 4096)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x MistralDecoderLayer(\n",
       "            (self_attn): MistralAttention(\n",
       "              (q_proj): Linear4bit(\n",
       "                in_features=4096, out_features=4096, bias=False\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "              (v_proj): Linear4bit(\n",
       "                in_features=4096, out_features=1024, bias=False\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "              (rotary_emb): MistralRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): MistralMLP(\n",
       "              (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "              (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "              (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "              (act_fn): SiLUActivation()\n",
       "            )\n",
       "            (input_layernorm): MistralRMSNorm()\n",
       "            (post_attention_layernorm): MistralRMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (norm): MistralRMSNorm()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_to_merge2 = PeftModel.from_pretrained(model,adapter2)\n",
    "model_to_merge2.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6e5aed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e4232e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_template_query_v1(user_query):\n",
    "    inp = query_template_v1.format(context=context,\n",
    "                                   user_query=user_query,\n",
    "                                  date_input=date_input)\n",
    "    _inputs = tokenizer.encode(inp, return_tensors=\"pt\").to('cuda')\n",
    "    outputs = model.generate(input_ids=_inputs, max_length= 1200, pad_token_id=tokenizer.eos_token_id)\n",
    "    output = tokenizer.decode(outputs[0])\n",
    "    output_new = output.split('[MQL]\\n')[1]\n",
    "    return output_new.split('\\n[/MQL]')[0], output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "74998d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1ea3dbb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user query:  what is purchase across segments\n",
      "----------------------------------------------------------------------------------------------------\n",
      "time taken :  482.13821148872375\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "user_query = 'what is purchase across segments'\n",
    "print('user query: ', user_query)\n",
    "print('-'*100)\n",
    "output, raw = predict_template_query_v1(user_query=user_query)\n",
    "print(\"time taken : \", time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "346df33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'DIMENSION': {'segments': [{'ENTITY': 'Segment', 'RANK': [{'RANK ADJECTIVE': '', 'RANK VALUE': ''}]}]}, 'MEASURE': {'purchase': [{'ENTITY': 'Purchase Vol', 'MEASURE CONSTRAINT': [{'COMPARISON VALUE': '', 'COMPARSION OPERATOR': ''}]}]}}\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b82c65a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"{\n",
    "    \"MEASURE\": [{\"ENTITY\": \"Discount\", \"other names\": [\"discount\", \"discount rate\", \"discount value\", \"deduction\"]},\n",
    "                {\"ENTITY\": \"Purchase Vol\", \"other names\": [\"purchase\", \"purchase value\", \"purchase model\"]},\n",
    "                {\"ENTITY\": \"Quantity\", \"other names\": [\"quantity\", \"volume\"]},\n",
    "                {\"ENTITY\": \"Sales\", \"other names\": [\"sales\", \"sale\"]}],\n",
    "    \"DIMENSION\": [{\"ENTITY\": \"Sub-Category\", \"other names\": [\"sub-category\", \"sub category\", \"categories\", \"section\"]},\n",
    "                  {\"ENTITY\": \"Segment\", \"other names\": [\"segment\", \"segments\", \"units\", \"divisions\"]},\n",
    "                  {\"ENTITY\": \"Parts\", \"other names\": [\"parts\", \"part\", \"section\", \"divisions\"]},\n",
    "                  {\"ENTITY\": \"Country\", \"other names\": [\"country\", \"countries\"]}],\n",
    "    \"FILTER\": [{\"ENTITY\": \"Consumer\", \"other names\": [\"consumers\", \"consumer\"], \"parent\": \"Segment\"},\n",
    "               {\"ENTITY\": \"Phone\", \"other names\": [\"phone\", \"phones\", \"mobile phones\"], \"parent\": \"Sub-Category\"},\n",
    "               {\"ENTITY\": \"Binder\", \"other names\": [\"binders\", \"binder\"], \"parent\": \"Sub-Category\"},\n",
    "               {\"ENTITY\": \"Corporate\", \"other names\": [\"corporates\", \"corporate\"], \"parent\": \"Segment\"},\n",
    "               {\"ENTITY\": \"India\", \"other names\": [\"india\"], \"parent\": \"Country\"},\n",
    "               {\"ENTITY\": \"Dubai\", \"other names\": [\"dubai\"], \"parent\": \"Country\"}],\n",
    "    \"DERIVED MEASURE\": [{\"ENTITY\": \"Ratio\",\n",
    "             \"other names\": [\"ratio\", \"share\", \"contribution\", \"percentage\", \"proportion\", \"contributing\"]},\n",
    "            {\"ENTITY\": \"Why\", \"other names\": [\"why\", \"cause of\", \"reason for\", \"diagnose\"]},\n",
    "            {\"ENTITY\": \"contribution_to_growth\", \"other names\": [\"contribution to growth\", \"growth\", \"grown\"]},\n",
    "            {\"ENTITY\": \"kda_transactional\", \"other names\": [\"kda\", \"key drivers\", \"key driver\", \"drivers\", \"driver\"]},\n",
    "            {\"ENTITY\": \"Growth Rate\", \"other names\": [\"growth rate\", \"growth\", \"grown\"]},\n",
    "            {\"ENTITY\": \"correlation\",\n",
    "             \"other names\": [\"associate\", \"associated\", \"association\", \"associations\", \"correlate\", \"correlated\",\n",
    "                             \"correlation\", \"correlations\", \"relate\", \"related\", \"relation\", \"relations\",\n",
    "                             \"relationship\",\n",
    "                             \"relationships\"]}\n",
    "            ],\n",
    "    \"DATE VARIABLE\": [{\"ENTITY\": \"Order Date\", \"other names\": [\"order date\", \"date\", \"trend\", \"time\", \"when\", \"mom\", \"yoy\"]}]\n",
    "    }\"\"\"\n",
    "\n",
    "date_input = {\n",
    "    \"start_date\": \"01/01/2020\",\n",
    "    \"end_date\": \"15/09/2023\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24477f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_template_v1 = \"\"\"Given the context : {context} and date reference: {date_input}, the query: {user_query}, is converted into below shown structured output.\n",
    "[MQL]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83e8902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = AutoAdapterModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "\n",
    "model.load_adapter(\"AdapterHub/roberta-base-pf-imdb\", source=\"hf\", set_active=True)\n",
    "\n",
    "print(model(**tokenizer(\"This works great!\", return_tensors=\"pt\")).logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81afbc4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c5a283",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7863ff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efc8830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86b39c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc51a585",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
