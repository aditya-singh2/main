{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fea6c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo pip install -q transformers --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f36caa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo pip install -q autoawq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02094fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "472f24a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = '/data/mistral/query-to-mql/exp-10/nov-20/merged-model'\n",
    "tokenizer = '/data/mistral/query-to-mql/exp-10/nov-20/merged-model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58734136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cc5ef90a64f4d8898570935b74fa2a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_model_name = \"/data/mistral/query-to-mql/exp-10/nov-20/checkpoint-8000\"\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(new_model_name, device_map=\"auto\", torch_dtype=torch.bfloat16)\n",
    "model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1fa3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "# model = AutoModelForCausalLM.from_pretrained(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b5a67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load LLaMA tokenizer\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True,\n",
    "                                          # add_eos_token=True,\n",
    "                                          use_fast=False)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a255b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d8a240",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoawq import AWQQuantizer\n",
    "    quantizer = AWQQuantizer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        bnb_config=bnb_config,\n",
    "        quant_method=\"awq\",\n",
    "        num_epochs=10,\n",
    "        lr=1e-4,\n",
    "        batch_size=1,\n",
    "        eval_batch_size=1,\n",
    "        max_length=2048,\n",
    "        device=\"cuda\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5152745",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02628af",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantizer.quantize(\n",
    "        input_file=\"input.txt\",\n",
    "        valid_file=\"valid.txt\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542ca962",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0f644c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
