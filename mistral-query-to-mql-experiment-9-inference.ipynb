{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73377c2e",
   "metadata": {},
   "source": [
    "### Distill step by step finetuning approach - trying enhanced rationale with specific reasoning for date conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baff667f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06dcc636",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!sudo pip install -q transformers --upgrade\n",
    "!sudo pip install -q peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1b437fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.35.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57fbc6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig, PeftModel\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c37f45b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model that you want to train from the Hugging Face hub\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47730f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_ecom = \"\"\"{\n",
    "    \"MEASURE\": [{\"ENTITY\": \"Discount\", \"other names\": [\"discount\", \"discount rate\", \"discount value\", \"deduction\"]},\n",
    "                {\"ENTITY\": \"Purchase Vol\", \"other names\": [\"purchase\", \"purchase value\", \"purchase model\"]},\n",
    "                {\"ENTITY\": \"Quantity\", \"other names\": [\"quantity\", \"volume\"]},\n",
    "                {\"ENTITY\": \"Sales\", \"other names\": [\"sales\", \"sale\"]}],\n",
    "    \"DIMENSION\": [{\"ENTITY\": \"Sub-Category\", \"other names\": [\"sub-category\", \"sub category\", \"categories\", \"section\"]},\n",
    "                  {\"ENTITY\": \"Segment\", \"other names\": [\"segment\", \"segments\", \"units\", \"divisions\"]},\n",
    "                  {\"ENTITY\": \"Parts\", \"other names\": [\"parts\", \"part\", \"section\", \"divisions\"]},\n",
    "                  {\"ENTITY\": \"Country\", \"other names\": [\"country\", \"countries\"]}],\n",
    "    \"FILTER\": [{\"ENTITY\": \"Consumer\", \"other names\": [\"consumers\", \"consumer\"], \"parent\": \"Segment\"},\n",
    "               {\"ENTITY\": \"Phone\", \"other names\": [\"phone\", \"phones\", \"mobile phones\"], \"parent\": \"Sub-Category\"},\n",
    "               {\"ENTITY\": \"Binder\", \"other names\": [\"binders\", \"binder\"], \"parent\": \"Sub-Category\"},\n",
    "               {\"ENTITY\": \"Corporate\", \"other names\": [\"corporates\", \"corporate\"], \"parent\": \"Segment\"},\n",
    "               {\"ENTITY\": \"India\", \"other names\": [\"india\"], \"parent\": \"Country\"},\n",
    "               {\"ENTITY\": \"Dubai\", \"other names\": [\"dubai\"], \"parent\": \"Country\"}],\n",
    "    \"DERIVED MEASURE\": [{\"ENTITY\": \"Ratio\",\n",
    "             \"other names\": [\"ratio\", \"share\", \"contribution\", \"percentage\", \"proportion\", \"contributing\"]},\n",
    "            {\"ENTITY\": \"Why\", \"other names\": [\"why\", \"cause of\", \"reason for\", \"diagnose\"]},\n",
    "            {\"ENTITY\": \"contribution_to_growth\", \"other names\": [\"contribution to growth\", \"growth\", \"grown\"]},\n",
    "            {\"ENTITY\": \"kda_transactional\", \"other names\": [\"kda\", \"key drivers\", \"key driver\", \"drivers\", \"driver\"]},\n",
    "            {\"ENTITY\": \"Growth Rate\", \"other names\": [\"growth rate\", \"growth\", \"grown\"]},\n",
    "            {\"ENTITY\": \"correlation\",\n",
    "             \"other names\": [\"associate\", \"associated\", \"association\", \"associations\", \"correlate\", \"correlated\",\n",
    "                             \"correlation\", \"correlations\", \"relate\", \"related\", \"relation\", \"relations\",\n",
    "                             \"relationship\",\n",
    "                             \"relationships\"]}\n",
    "            ],\n",
    "    \"DATE VARIABLE\": [{\"ENTITY\": \"Order Date\", \"other names\": [\"order date\", \"date\", \"trend\", \"time\", \"when\", \"mom\", \"yoy\"]}]\n",
    "    }\"\"\"\n",
    "context = \"\"\"{\n",
    "    \"MEASURE\": [{\"ENTITY\": \"TRx\", \"other names\": [\"total_prescriptions\", \"overall_rx\", \"complete_rx_count\", \"full_prescription_volume\", \"entire_rx_number\"]},\n",
    "                {\"ENTITY\": \"NRx\", \"other names\": [\"new_prescriptions\", \"fresh_rx\", \"recent_rx_count\", \"initial_prescription_volume\", \"first_rx_number\"]},\n",
    "                {\"ENTITY\": \"NBRx\", \"other names\": [\"new_to_brand_prescriptions\", \"fresh_brand_rx\", \"recent_brand_rx_count\", \"initial_brand_prescription_volume\", \"first_brand_rx_number\"]},\n",
    "                {\"ENTITY\": \"NTS\", \"other names\": [\"new_to_specialty\", \"fresh_specialty_patients\", \"recent_specialty_count\", \"initial_specialty_volume\", \"first_specialty_number\"]},\n",
    "                {\"ENTITY\": \"Switch\", \"other names\": [\"transition\", \"change\", \"shift\", \"swap\", \"alteration\"]}],\n",
    "    \"DIMENSION\": [{\"ENTITY\": \"Physician ID\", \"other names\": [\"doctor_identifier\", \"medical_practitioner_id\", \"healthcare_provider_id\", \"doc_id\", \"practitioner_code\"]},\n",
    "                  {\"ENTITY\": \"IMS_ID\", \"other names\": [\"ims_identifier\", \"ims_code\", \"ims_number\", \"ims_reference\", \"ims_key\"]},\n",
    "                  {\"ENTITY\": \"NPI ID\", \"other names\": [\"national_provider_id\", \"npi_number\", \"npi_code\", \"npi_identifier\", \"npi_key\"]},\n",
    "                  {\"ENTITY\": \"Address\", \"other names\": [\"location\", \"street\", \"residence\", \"place\", \"site\"]},\n",
    "                  {\"ENTITY\": \"State\", \"other names\": [\"province\", \"region\", \"territory\", \"district\", \"area\"]},\n",
    "                  {\"ENTITY\": \"City\", \"other names\": [\"town\", \"municipality\", \"urban_area\", \"locality\", \"metropolis\"]},\n",
    "                  {\"ENTITY\": \"Zip_Code\", \"other names\": [\"postal_code\", \"zipcode\", \"post_code\", \"mailing_code\", \"zip\"]},\n",
    "                  {\"ENTITY\": \"Physician Name\", \"other names\": [\"doctor_name\", \"medical_practitioner\", \"healthcare_provider\", \"doc_fullname\", \"practitioner\"]},\n",
    "                  {\"ENTITY\": \"Specialty\", \"other names\": [\"expertise\", \"medical_field\", \"healthcare_area\", \"practice_focus\", \"specialization\"]},\n",
    "                  {\"ENTITY\": \"Specialty Group\", \"other names\": [\"expertise_group\", \"medical_field_category\", \"healthcare_area_group\", \"practice_focus_group\", \"specialization_group\"]},\n",
    "                  {\"ENTITY\": \"Brand\", \"other names\": [\"product\", \"trademark\", \"label\", \"make\", \"marque\"]},\n",
    "                  {\"ENTITY\": \"Therapy Area\", \"other names\": [\"treatment_field\", \"therapy_domain\", \"care_area\", \"intervention_zone\", \"healing_sector\"]},\n",
    "                  {\"ENTITY\": \"Market\", \"other names\": [\"industry\", \"sector\", \"commerce\", \"trade\", \"business_area\"]},\n",
    "                  {\"ENTITY\": \"Payer Channel\", \"other names\": [\"payment_method\", \"insurance_type\", \"reimbursement_channel\", \"coverage_mode\", \"financial_route\"]},\n",
    "                  {\"ENTITY\": \"Payer\", \"other names\": [\"insurer\", \"payment_provider\", \"coverage_source\", \"financial_institution\", \"insurance_company\"]},\n",
    "                  {\"ENTITY\": \"Zip Code\", \"other names\": [\"postal_code\", \"zipcode\", \"post_code\", \"mailing_code\", \"zip\"]},\n",
    "                  {\"ENTITY\": \"Territory\", \"other names\": [\"domain\", \"area\", \"zone\", \"region\", \"expanse\"]},\n",
    "                  {\"ENTITY\": \"Region\", \"other names\": [\"geographical_area\", \"locale\", \"district\", \"sector\", \"division\"]},\n",
    "                  {\"ENTITY\": \"District\", \"other names\": [\"administrative_area\", \"territory\", \"region\", \"zone\", \"jurisdiction\"]},\n",
    "                  {\"ENTITY\": \"Sales Force\", \"other names\": [\"sales_team\", \"sales_representatives\", \"sales_agents\", \"sales_personnel\", \"sales_staff\"]}],\n",
    "    \"FILTER\": [{\"ENTITY\": \"Healdsburg\", \"other names\": [], \"parent\": \"State\"},\n",
    "               {\"ENTITY\": \"Brownsville\", \"other names\": [], \"parent\": \"State\"},\n",
    "               {\"ENTITY\": \"Oncology\", \"other names\": [], \"parent\": \"Specialty\"},\n",
    "               {\"ENTITY\": \"Pulmonary Disease\", \"other names\": [], \"parent\": \"Specialty\"},\n",
    "               {\"ENTITY\": \"Cardiovascular Diseases\", \"other names\": [], \"parent\": \"Specialty\"}],\n",
    "    \"DERIVED MEASURE\": [{\"ENTITY\": \"Ratio\",\n",
    "             \"other names\": [\"ratio\", \"share\", \"contribution\", \"percentage\", \"proportion\", \"contributing\"]},\n",
    "            {\"ENTITY\": \"Why\", \"other names\": [\"why\", \"cause of\", \"reason for\", \"diagnose\"]},\n",
    "            {\"ENTITY\": \"contribution_to_growth\", \"other names\": [\"contribution to growth\", \"growth\", \"grown\"]},\n",
    "            {\"ENTITY\": \"kda_transactional\", \"other names\": [\"kda\", \"key drivers\", \"key driver\", \"drivers\", \"driver\"]},\n",
    "            {\"ENTITY\": \"Growth Rate\", \"other names\": [\"growth rate\", \"growth\", \"grown\"]},\n",
    "            {\"ENTITY\": \"correlation\",\n",
    "             \"other names\": [\"associate\", \"associated\", \"association\", \"associations\", \"correlate\", \"correlated\",\n",
    "                             \"correlation\", \"correlations\", \"relate\", \"related\", \"relation\", \"relations\",\n",
    "                             \"relationship\",\n",
    "                             \"relationships\"]}\n",
    "            ],\n",
    "    \"DATE VARIABLE\": [{\"ENTITY\": \"Data Date\", \"other names\": [\"data date\", \"date\", \"trend\", \"time\", \"when\", \"mom\", \"yoy\"]}]\n",
    "    }\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78a95227",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_input = {\n",
    "    \"start_date\": \"01/01/2020\",\n",
    "    \"end_date\": \"15/09/2023\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "202bb865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef60f964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load LLaMA tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True,\n",
    "                                          # add_eos_token=True,\n",
    "                                          use_fast=False)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84916548",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel, PeftConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3ad3884",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model_name = \"/data/mistral/query-to-mql/exp-9/nov-01/checkpoint-4000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e10ab609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0f0d034a51544d1be3759612d7bdcd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpeft\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoPeftModelForCausalLM\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoPeftModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_model_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfloat16\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mmerge_and_unload()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/peft/auto.py:101\u001b[0m, in \u001b[0;36m_BaseAutoPeftModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, adapter_name, is_trainable, config, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot infer the auto class from the config, please make sure that you are loading the correct model for your task type.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     99\u001b[0m     )\n\u001b[0;32m--> 101\u001b[0m base_model \u001b[38;5;241m=\u001b[39m \u001b[43mtarget_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_model_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_target_peft_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    104\u001b[0m     base_model,\n\u001b[1;32m    105\u001b[0m     pretrained_model_name_or_path,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    110\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py:566\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    565\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 566\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    572\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/modeling_utils.py:3480\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3471\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3472\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   3473\u001b[0m     (\n\u001b[1;32m   3474\u001b[0m         model,\n\u001b[1;32m   3475\u001b[0m         missing_keys,\n\u001b[1;32m   3476\u001b[0m         unexpected_keys,\n\u001b[1;32m   3477\u001b[0m         mismatched_keys,\n\u001b[1;32m   3478\u001b[0m         offload_index,\n\u001b[1;32m   3479\u001b[0m         error_msgs,\n\u001b[0;32m-> 3480\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[1;32m   3484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3485\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3486\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3487\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3488\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3491\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3492\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_quantized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquantization_method\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mQuantizationMethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBITS_AND_BYTES\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3496\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3498\u001b[0m model\u001b[38;5;241m.\u001b[39mis_loaded_in_4bit \u001b[38;5;241m=\u001b[39m load_in_4bit\n\u001b[1;32m   3499\u001b[0m model\u001b[38;5;241m.\u001b[39mis_loaded_in_8bit \u001b[38;5;241m=\u001b[39m load_in_8bit\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/modeling_utils.py:3856\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, is_quantized, keep_in_fp32_modules)\u001b[0m\n\u001b[1;32m   3854\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shard_file \u001b[38;5;129;01min\u001b[39;00m disk_only_shard_files:\n\u001b[1;32m   3855\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m-> 3856\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshard_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3858\u001b[0m \u001b[38;5;66;03m# Mistmatched keys contains tuples key/shape1/shape2 of weights in the checkpoint that have a shape not\u001b[39;00m\n\u001b[1;32m   3859\u001b[0m \u001b[38;5;66;03m# matching the weights in the model.\u001b[39;00m\n\u001b[1;32m   3860\u001b[0m mismatched_keys \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m _find_mismatched_keys(\n\u001b[1;32m   3861\u001b[0m     state_dict,\n\u001b[1;32m   3862\u001b[0m     model_state_dict,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3866\u001b[0m     ignore_mismatched_sizes,\n\u001b[1;32m   3867\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/modeling_utils.py:484\u001b[0m, in \u001b[0;36mload_state_dict\u001b[0;34m(checkpoint_file)\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    483\u001b[0m         map_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 484\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_location\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/serialization.py:809\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    808\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 809\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[1;32m    811\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/serialization.py:1172\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1170\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1171\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1172\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1174\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/serialization.py:1142\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1141\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1142\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/serialization.py:1112\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_tensor\u001b[39m(dtype, numel, key, location):\n\u001b[1;32m   1110\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m-> 1112\u001b[0m     storage \u001b[38;5;241m=\u001b[39m \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_storage_from_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUntypedStorage\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_untyped_storage\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   1114\u001b[0m     \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[1;32m   1116\u001b[0m         wrap_storage\u001b[38;5;241m=\u001b[39mrestore_location(storage, location),\n\u001b[1;32m   1117\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1118\u001b[0m         _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from peft import AutoPeftModelForCausalLM\n",
    "\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(new_model_name, device_map=\"auto\", torch_dtype=torch.bfloat16)\n",
    "model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be81f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_template_v1 = \"\"\"Given the context : {context} and date reference: {date_input}, the query: {user_query}, is converted into below shown structured output.\n",
    "[MQL]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a9a2513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_template_query_v1(user_query):\n",
    "    inp = query_template_v1.format(context=context,\n",
    "                                   user_query=user_query,\n",
    "                                  date_input=date_input)\n",
    "    _inputs = tokenizer.encode(inp, return_tensors=\"pt\")\n",
    "    outputs = model.generate(input_ids=_inputs.to('cuda'), max_length= 1600, pad_token_id=tokenizer.eos_token_id)\n",
    "    output = tokenizer.decode(outputs[0])\n",
    "    output_new = output.split('[MQL]\\n')[1]\n",
    "    return output_new.split('\\n[/MQL]')[0], output\n",
    "#     return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc44339e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(user_query):\n",
    "    output, raw = predict_template_query_v1(user_query=user_query)\n",
    "    mql = eval(output)\n",
    "    steps = 'Step 1:' +raw.split('\\nStep 1:')[1]\n",
    "    return mql, steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b503a1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query_list = ['how have the full_prescription_volume trended', 'what is the monthly trend of TRx and full_prescription_volume', 'what is the average overall_rx offered across change', 'complete_rx_count vs entire_rx_number over the last 6 months', 'Which are the top 5 entire_rx_number making therapy_domain', 'Which TRx has given most percentage Sales Force', 'first_brand_rx_number in march 2020 ', 'Zip Code in 20 April  2021', 'territory in 20 April 2020 ', 'Territory of art MOM ', 'initial_prescription_volume of art YOY ', 'What is the growth rate of specialization_group', 'what Zip_Code are contributing to growth for initial_brand_prescription_volume in p3m', 'mtd growth rate', 'ytd growth rate', 'How many initial_specialty_volume have  new_prescriptions more than 10k', 'what is the contribution of expanse by Physician ID in US', 'zipcode in jan 2022 vs  year ago', 'first_brand_rx_number in 2020 compared to prior year', 'total_prescriptions in 2021 vs 2020', 'growth rate of Zip Code MOM in 2020', 'Switch in 2021', 'npi_key in 2022', 'what is th growth rate of make across years', 'what is the growth of overall_rx across years', 'What is the growth rate of fresh_rx', 'what complete_rx_count are contributing to growth for NTS in p3m', 'growth rate of ims_key across month', 'what Switch are contributing to growth for recent_specialty_count in p3m for top 50%', 'How many Switch are there', 'How many NTS are there with doctor_identifier more than 35k', 'How many entire_rx_number are contributing to 50% of npi_key', 'How many municipality are contributing to growth to 50% of domain in p3m vs pp', 'ytd Payer Channel by month', 'ytd complete_rx_count  by quarter', 'mtd Switch', 'full_prescription_volume in 2020 YTD vs YA', 'How have the District trended by Specialty ?', 'what is the monthly trend of entire_rx_number and recent_specialty_count by state?', 'domain vs healthcare_provider_id over the last 6 months by sector', 'What is the complete_rx_count trend of treatment_field', 'What is the first_rx_number trend of swap and geographical_area', 'what is the ims_key across months', 'how have doc_fullname trended', 'Which full_prescription_volume has site greater than fifty thousand in 2020', 'Which metropolis has ims_identifier more than 50000 in 2020', 'Which zone has first_specialty_number above 50K in 2020', 'Which specialization_group has make greater than 400K in 2019', 'Which Switch has ims_number more than 20k in February 2019', 'Which zipcode has Physician ID above 1K in india in 2019', 'Which post_code has residence greater than 55.82 K in 2020', 'Which total_prescriptions has medical_practitioner_id more than 4k in December 2019 in india', 'Which doctor_identifier has fresh_rx greater than 3K in 2019 in india', 'which month has zip greater than five hundred thousand in 2020', 'Which region has change greater than 2K for territory February 2019', 'Which month has fresh_rx above 50K for locality in 2019', 'Which month has Therapy Area less than 200K in india in 2019', 'which medical_practitioner has first_rx_number more than 10k in March 2019', 'which month has ims_code trend for new_to_specialty greater than 50K in 2019', 'Which jurisdiction has change above 20K in february 2019', 'Which place has Switch less than 50K in previous  month', 'Which coverage_mode has recent_specialty_count more  than  300000 in p6m', 'Which practitioner_code has  initial_specialty_volume above 20k in february 2019', 'which coverage_mode has sales_personnel below four thousand in february 2019', 'Which Specialty has Switch below 10k in 2019', 'Which new_to_specialty has TRx between 300k and 400k', 'Which TRx has medical_field between 300k & 400k', 'Which Specialty has healthcare_provider_id from 300k to 400k', 'Which insurance_type has jurisdiction from 300k-400k', 'when was npi_identifier the highest ', 'when was the NRx of total_prescriptions was highest', 'when was the Switch the highest', 'when was growth in Switch the highest', 'Top 3 Brand by alteration', 'Top 3 mailing_code by new_to_brand_prescriptions across overall_rx', 'Top 3 months by trade', 'Top 3 practitioner_code by fresh_specialty_patients across months', 'Lindia profiswap postal_code across healthcare_provider_id', 'Top 3 first_brand_rx_number by doc_id across first_brand_rx_number and months', 'Most profidomain initial_prescription_volume across months', 'Lindia profioverall_rx initial_prescription_volume across initial_prescription_volume', 'Bottom 3 initial_prescription_volume by sales_personnel', 'Bottom 3 complete_rx_count by doctor_name across Brownsville', 'Bottom 3 months by first_brand_rx_number', 'Bottom 3 recent_specialty_count by shift across months', 'Bottom 3 entire_rx_number by doctor_identifier across Physician ID and months', 'top 3 total_prescriptions basis  growth in rate', 'top 5 contibuting Brand to rate', 'top 3 initial_prescription_volume contributing to growth of rate in rolling 3', 'when was the first time complete_rx_count of NRx was more than 40K', 'when was the last time fresh_rx of alteration was less than 40K', 'When was the NBRx of total_prescriptionss was more than 600', 'in which month healthcare_provider_id of province in india was more than 1.5K', 'In which quarter practitioner_code of swap in india was above 2.5 k', 'In which year commerce of change was more than 450 K', 'when was the full_prescription_volume of first_specialty_number was less than 10K first time', 'when was the swap of treatment_field was more than 35K last time', 'when was the first time Physician ID of complete_rx_count was more than 20K in 2019', 'In which month first_brand_rx_number of specialization in india was more than 800 in 2018', 'In which quarter full_prescription_volume of change in india was above 2.5 k in 2019', 'when was the last time trend of City of new_prescriptions was more than 5K in last 3 months', 'when was the first time trend of region of npi_key was less than 10K in last 3 months', 'correlation between municipality and medical_practitioner_id', 'correlation between ims_key and NTS in india', 'correlation between zone and Physician Name in india and dubai', 'correlation between ims_identifier of ims_identifier and place', 'What is the correlation between municipality volume of all new_to_specialty', 'What is the division and division correlation across Physician Name', 'What is the correlation of transition and Payer across years', 'Correlation between medical_practitioner_id and region in medical_field and india across Switch', 'Correlation between doc_id and change in india and india across NBRx', 'correlation between complete_rx_count and Territory  across financial_institution', 'Correlation between alteration and NRx  across doctor_name exclude US', 'Correlation between area and reimbursement_channel in india and india across territory', 'medical_practitioner in rolling 3 months', 'which District has most specialization in rolling 5 months', 'top 3 total_prescriptions by Therapy Area in rolling 7 months in canada', 'new_prescriptions of entire_rx_number in rolling 13 months across marque', 'Which expertise has the most percentage full_prescription_volume in rolling 10 months', 'when was the trend of Switch of industry was more than 40K in rolling 6 months', 'when was the first time trend of Sales Force of medical_field was more than 40K in rolling 6 months', 'municipality of locality in last 10 weeks', 'coverage_source by NTS  in last 2 weeks', 'which geographical_area has most trade in india in last 20 weeks', 'ims_identifier of all fresh_specialty_patients in basic in last 35 weeks', 'zipcode of ims_key in Canada in last 13 weeks', 'What is the Cardiovascular Diseases of fresh_specialty_patients geographical_area', 'place of doctor_identifier in last month', 'What is the NBRx of initial_brand_prescription_volume in india zone', 'what is the doctor_identifier of doctor_identifier fresh_brand_rx', 'which state has most intervention_zone in this year', 'industry per State in this year', 'which product has the most fresh_brand_rx in this year', 'expertise_group by doc_id in this year', 'doc_id in this year', 'transition by product more than 500 in US in this year', 'City of recent_brand_rx_count in this quarter', 'Brand of entire_rx_number in india zone in current quarter', 'overall_rx in previous quarter', 'town by NBRx in quarter2', 'which care_area has highest marque in q3 2018', 'top 3 healing_sector by metropolis  in q-4 2017', 'bottom 2 TRx by full_prescription_volume  in q 1 2019', 'which entire_rx_number has healthcare_provider in india  above 2.5 k in quarter 4 2019', 'practitioner by product in quarter-1 2017', 'doc_id across shift in present quarter', 'what will be the npi_key of make  in q1 2020', 'mailing_code in q1 2020 vs q2 2020', 'healthcare_area_group of specialization_group in this month vs last month', 'State by Payer in last 2 months', 'new_prescriptions across sales_team in this month', 'which NBRx has most percentage practice_focus_group in last 1 month', 'ims_code in this month', 'product by percentage complete_rx_count in last 5 months', 'Top 3 sales_team by shift in last 13 months', 'Forecast of healthcare_provider_id intervention_zone', 'forecast of urban_area for 2021', 'Forecast of entire_rx_number of financial_route in next 3 months', 'Forecast of fresh_brand_rx for the next quarter', 'What would be the initial_prescription_volume of territory in 2022', 'what will be the trademark in next 3 months', 'what will the overall_rx in next 3 months', 'Address in next 2 quarters', 'expertise in next year', 'Zip_Code of NBRx', 'fresh_specialty_patients of new_prescriptions', 'kda of insurance_type in india', 'kda of sales_representatives in india', 'why Payer of zipcode changed', 'why is commerce intervention_zone changing', 'why is my sector changing in p3m', 'diagnose the increase in shift zipcode in last month', 'why has the NBRx of sales_staff increased in 2019 over 2018', 'Sales Force in Q1 2020 vs Q1 2019', 'total_prescriptions in Q1 2019 vs Q2 2020', 'Payer in Q1 2020 vs year ago', 'region in p3m vs past period', 'State in p3m vs year ago', 'overall_rx in rolling 6 months vs pp', 'initial_specialty_volume in rolling 3 months vs year ago', 'ims_code on this month vs last month', 'transition in 2020 YTD vs YA', 'healthcare_area_group of change except china', 'fresh_specialty_patients of NBRx without africa and EU', 'medical_practitioner_id of location across medical_field other than india', 'medical_field_category of region across new_prescriptions not india & dubai', 'marque of TRx across recent_rx_count excluding india , india , Central and india', 'which sub-sales_agents has location greater than 200k without Territory and Region', 'What is the initial_prescription_volume trend not for Sales Force', 'Which label has recent_rx_count less than 4k in December 2019 not in india', 'Top 3 ims_key by practitioner_code except india', 'Top 3 new_prescriptions by territory not including india and india', 'Bottom 3 Healdsburg by payment_method except labels', 'when was the first time City of sector was more than 40K eliminate india', 'when was the last time ims_reference of total_prescriptions was more than 40K eliminate india', 'when was the  site of fresh_brand_rx was less than 40K eliminate india and india', 'correlation between recent_rx_count and district beside india', 'correlation between make and npi_number  beside india', 'correlation between zip and urban_area beside india and india', 'correlation between mailing_code and site across trade beside india', 'Physician ID of new_to_brand_prescriptions across Payer Channel without india in last 3 months', 'Zip Code of new_to_specialty across npi_key without india in this year', 'administrative_area of alteration across IMS_ID without india in 2020', 'care_area of initial_prescription_volume in rolling 3 months across Physician ID exclusion of india', 'healthcare_area of district in Q1 across business_area exclusion of india and Central', 'kda of npi_key not in india', 'kda of expertise_group not in india & dubai', 'fresh_brand_rx not in Central Asia and Central ', 'Physician ID across product not  in india  and Central Asia', 'how many new_to_brand_prescriptions have ims_code greater than 10k barring india', 'what is the ratio of region to region except Central', 'what is the ratio of residence to residence across healthcare_area_group except Central', 'what is the contribution to growth of all Specialty except US to overall insurance_company', 'growth rate in all healthcare_provider_id except india', 'growth rate of zip across month except US', 'what is the number of administrative_area across administrative_area except china', 'distinct medical_practitioner_id id across complete_rx_count except india and dubai', 'count of state across coverage_mode except US and Africa', 'NBRx in Fy 2020 ', 'sales_representatives in 2020 fiscal', 'recent_specialty_count in 2021 fiscal year', 'what is fresh_rx in 2019', 'Trend of area in last 3 quarter of 2021 fiscal', 'payment_method across quarters in 21Fy', 'fresh_rx across financial years', 'location across financial quarters', 'geographical_area in last 2 quarters of fy2020']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a87b6abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user query:  sales in jan 2020 versus year ago\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'DATE VARIABLE': {'jan 2020': [{'CONVERTED TIME ELEMENT': 'january 2020', 'DATE RANGE': '2020/01/01 - 2020/01/31', 'ENTITY': 'Order Date'}]}, 'MEASURE': {'sales': [{'ENTITY': 'Sales'}]}}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step 1: Identify the components in the query\n",
      "- The query mentions \"sales\" which is a measure.\n",
      "- The query mentions \"jan 2020\" which is a date component.\n",
      "\n",
      "Step 2: Match the components to the context\n",
      "- \"sales\" can be matched to the \"Sales\" entity in the context under MEASURE.\n",
      "- \"jan 2020\" needs to be converted to a date range using the date reference provided.\n",
      "\n",
      "Step 3: Convert the date component\n",
      "- The query mentions \"year ago\" which needs to be calculated using the date reference.\n",
      "- The date reference has a start_date of '01/01/2020' and an end_date of '15/09/2023'.\n",
      "- Since the query asks for sales in Jan 2020, we don't need to consider the end_date for this calculation.\n",
      "- To calculate \"year ago\", we need to subtract one year from the date component.\n",
      "- So, Jan 2020 - 1 year = Jan 2019.\n",
      "- Therefore, the date range for Jan 2020 is '2020/01/01 - 2020/01/31'.\n",
      "\n",
      "Step 4: Create the structured output\n",
      "- The structured output should include the identified measure \"Sales\" and the converted date component \"Jan 2020\" with the date range '2020/01/01 - 2020/01/31' under \"DATE VARIABLE\".\n",
      "\n",
      "Rationale:\n",
      "- The query asks for sales in Jan 2020 versus year ago, so we need to identify the measure \"Sales\" and convert the date component \"Jan 2020\" to a date range using the date reference provided.\n",
      "- The date reference is used to calculate the date range for Jan 2020 by subtracting one year from the date component.\n",
      "- The structured output is created by including the identified measure and the converted date component with the date range.\n",
      "\n",
      "Note: The date reference is utilized in the conversion of the date component to a date range. The structured output is created by including the identified measure and the converted date component with the date range.\n",
      "\n",
      "[MQL]\n",
      "the output is in the format of structured query language (SQL) that is used to manage and query data in relational databases. The structured output includes the identified measure and the converted date component with the date range.\n",
      "\n",
      "[/MQL]\n",
      "the structured output is a representation of the query in a format that can be easily understood and processed by a computer system. The output includes the identified measure and the converted date component with the date range, which are the key components of the query.\n",
      "\n",
      "[MQL]\n",
      "the structured output is a crucial component of natural language processing (NLP\n",
      "----------------------------------------------------------------------------------------------------\n",
      "CPU times: user 53.1 s, sys: 1.14 s, total: 54.3 s\n",
      "Wall time: 54.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "data_fin = []\n",
    "for user_query in list_1:\n",
    "    print('user query: ', user_query)\n",
    "    print('-'*100)\n",
    "    output, raw = predict_template_query_v1(user_query=user_query)\n",
    "    print(eval(output))\n",
    "    print('-'*100)\n",
    "    steps = 'Step 1:' +raw.split('\\nStep 1:')[1]\n",
    "    print('Step 1:' +raw.split('\\nStep 1:')[1])\n",
    "    print('-'*100)\n",
    "    data_fin.append([user_query,eval(output)])\n",
    "import csv\n",
    "with open('data_1.csv', 'a', newline='') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow([\"Query\", \"Intermediate MQL\"])\n",
    "\n",
    "# Write data iteratively\n",
    "    for row in data_fin[0:]:\n",
    "        csvwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "684c9003",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-17-c3698c5997bd>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[17], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(eval(outut))print('-'*100)\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "user_query = \"sales in jan 2020 versus year ago\"\n",
    "print('user query: ', user_query)\n",
    "print('-'*100)\n",
    "output, raw = predict_template_query_v1(user_query=user_query)\n",
    "print(eval(outut))print('-'*100)\n",
    "steps = 'Step 1:' +raw.split('\\nStep 1:')[1]\n",
    "print('Step 1:' +raw.split('\\nStep 1:')[1])\n",
    "print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e28a654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cc52e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb8c7cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
