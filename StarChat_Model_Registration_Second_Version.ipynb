{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adf64300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/mosaic-ai/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mWARNING: The directory '/home/mosaic-ai/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/dd/f17b11a93a9ca27728e12512d167eb1281c151c4c6881d3ab59eb58f4127/transformers-4.35.2-py3-none-any.whl (7.9MB)\n",
      "\u001b[K     |████████████████████████████████| 7.9MB 5.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting safetensors>=0.3.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/ae/ef743263a42e21e3722845678c809e3962b6f886453431e847d520839bf0/safetensors-0.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3MB 107.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading https://files.pythonhosted.org/packages/81/54/84d42a0bee35edba99dee7b59a8d4970eccdd44b99fe728ed912106fc781/filelock-3.13.1-py3-none-any.whl\n",
      "Collecting huggingface-hub<1.0,>=0.16.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/09/1945ca6ba3ad8ad6e2872ba682ce8d68c5e63c8e55458ed8ab4885709f1d/huggingface_hub-0.19.4-py3-none-any.whl (311kB)\n",
      "\u001b[K     |████████████████████████████████| 317kB 123.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting packaging>=20.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/1a/610693ac4ee14fcdf2d9bf3c493370e4f2ef7ae2e19217d7a237ff42367d/packaging-23.2-py3-none-any.whl (53kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 89.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/8e/0e2d847013cb52cd35b38c009bb167a1a26b2ce6cd6965bf26b47bc0bf44/requests-2.31.0-py3-none-any.whl (62kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 85.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyyaml>=5.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/6b/6600ac24725c7388255b2f5add93f91e58a5d7efaf4af244fdbcc11a541b/PyYAML-6.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (736kB)\n",
      "\u001b[K     |████████████████████████████████| 737kB 103.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy>=1.17\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/5d/5738903efe0ecb73e51eb44feafba32bdba2081263d40c5043568ff60faf/numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3MB)\n",
      "\u001b[K     |████████████████████████████████| 17.3MB 118.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting regex!=2019.12.17\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/33/67c4ed826f5227655225c3feaaecd15afb8453e827334ddae95a7fba07ac/regex-2023.10.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (776kB)\n",
      "\u001b[K     |████████████████████████████████| 778kB 105.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm>=4.27\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/e5/f12a80907d0884e6dff9c16d0c0114d81b8cd07dc3ae54c5e962cc83037e/tqdm-4.66.1-py3-none-any.whl (78kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 114.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tokenizers<0.19,>=0.14\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/75/56230c5c65b226e707e1adbc759c19fdf1b20bb02c0276796b132c97118a/tokenizers-0.15.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8MB)\n",
      "\u001b[K     |████████████████████████████████| 3.9MB 124.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting typing-extensions>=3.7.4.3\n",
      "  Downloading https://files.pythonhosted.org/packages/24/21/7d397a4b7934ff4028987914ac1044d3b7d52712f30e2ac7a2ae5bc86dd0/typing_extensions-4.8.0-py3-none-any.whl\n",
      "Collecting fsspec>=2023.5.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/0e/2be9b5a2e3f736577e749bbdf27a1e7e965041e1c908d49dedf56eeb2b8a/fsspec-2023.12.1-py3-none-any.whl (168kB)\n",
      "\u001b[K     |████████████████████████████████| 174kB 109.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting idna<4,>=2.5\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c2/e7/a82b05cf63a603df6e68d59ae6a68bf5064484a0718ea5033660af4b54a9/idna-3.6-py3-none-any.whl (61kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 110.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting urllib3<3,>=1.21.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/94/c31f58c7a7f470d5665935262ebd7455c7e4c7782eb525658d3dbf4b9403/urllib3-2.1.0-py3-none-any.whl (104kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 111.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting certifi>=2017.4.17\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/62/428ef076be88fa93716b576e4a01f919d25968913e817077a386fcbe4f42/certifi-2023.11.17-py3-none-any.whl (162kB)\n",
      "\u001b[K     |████████████████████████████████| 163kB 109.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting charset-normalizer<4,>=2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/09/d82fe4a34c5f0585f9ea1df090e2a71eb9bb1e469723053e1ee9f57c16f3/charset_normalizer-3.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141kB)\n",
      "\u001b[K     |████████████████████████████████| 143kB 114.3MB/s eta 0:00:01\n",
      "\u001b[31mERROR: torchvision 0.15.2+cpu has requirement torch==2.0.1, but you'll have torch 2.1.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: torchaudio 2.0.2+cpu has requirement torch==2.0.1, but you'll have torch 2.1.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: refractml 1.0.3 has requirement PyYAML==6.0, but you'll have pyyaml 6.0.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: refractml 1.0.3 has requirement urllib3==1.26.15, but you'll have urllib3 2.1.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: jupyterlab 3.2.4 has requirement jupyter-server~=1.4, but you'll have jupyter-server 2.0.0a1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: jupyterlab-server 2.23.0 has requirement jsonschema>=4.17.3, but you'll have jsonschema 3.2.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: google-auth 2.22.0 has requirement urllib3<2.0, but you'll have urllib3 2.1.0 which is incompatible.\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, filelock, typing-extensions, fsspec, idna, urllib3, certifi, charset-normalizer, requests, packaging, pyyaml, tqdm, huggingface-hub, numpy, regex, tokenizers, transformers\n",
      "Successfully installed certifi-2023.11.17 charset-normalizer-3.3.2 filelock-3.13.1 fsspec-2023.12.1 huggingface-hub-0.19.4 idna-3.6 numpy-1.24.4 packaging-23.2 pyyaml-6.0.1 regex-2023.10.3 requests-2.31.0 safetensors-0.4.1 tokenizers-0.15.0 tqdm-4.66.1 transformers-4.35.2 typing-extensions-4.8.0 urllib3-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1267c336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/mosaic-ai/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mWARNING: The directory '/home/mosaic-ai/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Collecting refractml\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/0d/023d845cf453feb632b08435c91f7e5d050c0df73c5be66bdbbca2f6ba87/refractml-1.0.3-py2.py3-none-any.whl (42kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 7.3MB/s eta 0:00:011\n",
      "\u001b[?25hProcessing /home/mosaic-ai/.cache/pip/wheels/ab/d0/0e/613976a1b51b5654859e2a82ade64329859bce431e280f2a39/shutils-0.1.0-cp38-none-any.whl\n",
      "Collecting mosaic-utils\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/d7/8424b1dcaa5b1a2f824fc440aa1c4ef45e0bf6593d11b37962311614f365/mosaic_utils-1.0.2-py2.py3-none-any.whl (70kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 14.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting urllib3==1.26.15\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/f5/890a0baca17a61c1f92f72b81d3c31523c99bec609e60c292ea55b387ae8/urllib3-1.26.15-py2.py3-none-any.whl (140kB)\n",
      "\u001b[K     |████████████████████████████████| 143kB 16.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting PyYAML==6.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/42/7ad4b6d67a16229496d4f6e74201bdbebcf4bc1e87d5a70c9297d4961bd2/PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701kB)\n",
      "\u001b[K     |████████████████████████████████| 706kB 17.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cloudpickle==1.6.0\n",
      "  Downloading https://files.pythonhosted.org/packages/e7/e3/898487e5dbeb612054cf2e0c188463acb358167fef749c53c8bb8918cea1/cloudpickle-1.6.0-py3-none-any.whl\n",
      "Collecting requests-toolbelt==0.9.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/ef/7681134338fc097acef8d9b2f8abe0458e4d87559c689a8c306d0957ece5/requests_toolbelt-0.9.1-py2.py3-none-any.whl (54kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 39.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pymysql\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/30/20467e39523d0cfc2b6227902d3687a16364307260c75e6a1cb4422b0c62/PyMySQL-1.1.0-py3-none-any.whl (44kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 66.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting configparser\n",
      "  Downloading https://files.pythonhosted.org/packages/81/a3/0e5ed11da4b7770c15f6f319abf053f46b5a06c7d4273c48469b7899bd89/configparser-6.0.0-py3-none-any.whl\n",
      "Collecting scikit-learn==1.2.1; python_version >= \"3.8\"\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/95/0ea0a2412e33080a47ec02802210c008a7a540471581c95145f030d304b4/scikit_learn-1.2.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8MB)\n",
      "\u001b[K     |████████████████████████████████| 9.8MB 43.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests<3.0.0,>=2.0.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/8e/0e2d847013cb52cd35b38c009bb167a1a26b2ce6cd6965bf26b47bc0bf44/requests-2.31.0-py3-none-any.whl (62kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 91.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading https://files.pythonhosted.org/packages/81/12/fd4dea011af9d69e1cad05c75f3f7202cdcbeac9b712eea58ca779a72865/threadpoolctl-3.2.0-py3-none-any.whl\n",
      "Collecting joblib>=1.1.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/40/d551139c85db202f1f384ba8bcf96aca2f329440a844f924c8a0040b6d02/joblib-1.3.2-py3-none-any.whl (302kB)\n",
      "\u001b[K     |████████████████████████████████| 307kB 87.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy>=1.17.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/5d/5738903efe0ecb73e51eb44feafba32bdba2081263d40c5043568ff60faf/numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3MB)\n",
      "\u001b[K     |████████████████████████████████| 17.3MB 91.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=1.3.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/f0/fb07a9548e48b687b8bf2fa81d71aba9cfc548d365046ca1c791e24db99d/scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5MB)\n",
      "\u001b[K     |████████████████████████████████| 34.5MB 78.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting idna<4,>=2.5\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c2/e7/a82b05cf63a603df6e68d59ae6a68bf5064484a0718ea5033660af4b54a9/idna-3.6-py3-none-any.whl (61kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 116.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting charset-normalizer<4,>=2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/09/d82fe4a34c5f0585f9ea1df090e2a71eb9bb1e469723053e1ee9f57c16f3/charset_normalizer-3.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141kB)\n",
      "\u001b[K     |████████████████████████████████| 143kB 132.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting certifi>=2017.4.17\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/62/428ef076be88fa93716b576e4a01f919d25968913e817077a386fcbe4f42/certifi-2023.11.17-py3-none-any.whl (162kB)\n",
      "\u001b[K     |████████████████████████████████| 163kB 91.2MB/s eta 0:00:01\n",
      "\u001b[31mERROR: torchvision 0.15.2+cpu has requirement torch==2.0.1, but you'll have torch 2.1.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: jupyterlab-server 2.23.0 has requirement jsonschema>=4.17.3, but you'll have jsonschema 3.2.0 which is incompatible.\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pymysql, configparser, shutils, threadpoolctl, joblib, numpy, scipy, scikit-learn, mosaic-utils, urllib3, PyYAML, cloudpickle, idna, charset-normalizer, certifi, requests, requests-toolbelt, refractml\n",
      "Successfully installed PyYAML-6.0 certifi-2023.11.17 charset-normalizer-3.3.2 cloudpickle-1.6.0 configparser-6.0.0 idna-3.6 joblib-1.3.2 mosaic-utils-1.0.2 numpy-1.24.4 pymysql-1.1.0 refractml-1.0.3 requests-2.31.0 requests-toolbelt-0.9.1 scikit-learn-1.2.1 scipy-1.10.1 shutils-0.1.0 threadpoolctl-3.2.0 urllib3-1.26.15\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/__pycache__ already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/requests-2.31.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/numpy already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/urllib3 already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/numpy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/_yaml already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/numpy-1.24.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/certifi already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/yaml already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/idna-3.6.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/idna already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/charset_normalizer-3.3.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/certifi-2023.11.17.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/requests already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/charset_normalizer already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/bin already exists. Specify --upgrade to force replacement.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install refractml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0b5c6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/mosaic-ai/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\r\n",
      "Uninstalling urllib3-2.1.0:\r\n",
      "  Successfully uninstalled urllib3-2.1.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall urllib3 -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a1c4d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/mosaic-ai/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mWARNING: The directory '/home/mosaic-ai/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Collecting urllib3==1.26.15\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/f5/890a0baca17a61c1f92f72b81d3c31523c99bec609e60c292ea55b387ae8/urllib3-1.26.15-py2.py3-none-any.whl (140kB)\n",
      "\u001b[K     |████████████████████████████████| 143kB 7.6MB/s eta 0:00:01\n",
      "\u001b[31mERROR: refractml 1.0.3 has requirement PyYAML==6.0, but you'll have pyyaml 6.0.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: torchvision 0.15.2+cpu has requirement torch==2.0.1, but you'll have torch 2.1.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: jupyterlab-server 2.23.0 has requirement jsonschema>=4.17.3, but you'll have jsonschema 3.2.0 which is incompatible.\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: urllib3\n",
      "Successfully installed urllib3-1.26.15\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/urllib3-1.26.15.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install urllib3==1.26.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4b281d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff5453fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "from refractml import *\n",
    "from refractml.constants import MLModelFlavours\n",
    "\n",
    "# # new score functions\n",
    "from mosaic_utils.ai.score.base import ScoreBase\n",
    "from typing import Tuple, Union, List, Any\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fffd92ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################\n",
    "# Model Registration\n",
    "\n",
    "from refractml import *\n",
    "from refractml.constants import MLModelFlavours\n",
    "\n",
    "# new score functions\n",
    "from mosaic_utils.ai.score.base import ScoreBase\n",
    "from typing import Tuple, Union, List, Any\n",
    "class ScoreTemplateExample(ScoreBase):\n",
    "    \"\"\"\n",
    "    This Class Demonstrate How To Implements ScoreBase Interface Class And It Basic Usage.\n",
    "    \"\"\"    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        import os\n",
    "        os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:512\"\n",
    "        from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "        import torch\n",
    "        from torch import cuda\n",
    "        self.model_loaded = None\n",
    "        self.tokenizer = None\n",
    "#        self.token_path = '/data/models/mistralai_base/token.pkl'\n",
    "#        self.model_path = '/data/models/mistralai_base/qa.pkl'\n",
    "        if self.model_loaded is None:\n",
    "            print(\"Load Model From Data Volume\")\n",
    "            self.model_loaded = AutoModelForCausalLM.from_pretrained(\"/data/huggingface/cache/models--HuggingFaceH4--starchat-beta/snapshots/b1bcda690655777373f57ea6614eb095ec2c886f\",device_map = 'cpu',torch_dtype=torch.bfloat16)\n",
    "#             self.model_loaded =torch.load(self.model_path)\n",
    "\n",
    "        if self.tokenizer is None:\n",
    "            print(\"tokenizer object is loading from data section\")\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(\"/data/huggingface/cache/models--HuggingFaceH4--starchat-beta/snapshots/b1bcda690655777373f57ea6614eb095ec2c886f\")\n",
    "#             self.tokenizer = torch.load(self.token_path)\n",
    "        \n",
    "        print(\"model and tokens are loaded\")\n",
    "    def request_processing_fn(self, request) :\n",
    "        \"\"\"\n",
    "        Processes Request Object -> List[Input data, ..]. It could be:\n",
    "               A List Mapping of All Value Can Be one of : \n",
    "                   - List[ [Feature_Value1, Feature_Value2, ...], [...] ]\n",
    "                   - List[numpy.array(), numpy.array(), ...]\n",
    "                   - List[tf.Tensor, tf.Tensor, tf.Tensor, ...]\n",
    "                   - List[ SingleSample, SingleSample]\n",
    "                   \n",
    "        :return: (n_inputs, payload's)\n",
    "        \n",
    "        Warnings:\n",
    "        1. Do not reshape your final output for single sample here, do it in prediction.\n",
    "           Else payloads will be invalidated for extraction at raw and extraction level.\n",
    "        \"\"\"\n",
    "        final_payload = []\n",
    "        raw_payload = request.json[\"payload\"]\n",
    "        return (1, raw_payload) \n",
    "    \n",
    "    def pre_processing_fn(self,payload):\n",
    "        # All preprocessing step must occur in this section\n",
    "        # Takes Single Sample -> Returns Single Sample\n",
    "        \n",
    "        # Not Doing Any Preprocessing Hence Returned payload\n",
    "        print(\"payload is \", payload)\n",
    "        \n",
    "        return payload\n",
    "\n",
    "    def prediction_fn(self,\n",
    "                      model: Any,\n",
    "                      pre_processed_input \n",
    "                      ):\n",
    "        \"\"\"\n",
    "                Does the main prediction on pre_processed_input(Single Sample) using supplied model .\n",
    "\n",
    "                :param model: Supported Model\n",
    "                :param pre_processed_input: Single Preprocessed Payload\n",
    "                :return: Prediction Value From the model\n",
    "                \n",
    "                Important Notes:\n",
    "                - Reshape your data array.reshape(1, -1) before predictions as it contains a single sample.\n",
    "                    \n",
    "        \"\"\"\n",
    "#         device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "#         print(f'Device: ------------- {device}')\n",
    "        input_data = pre_processed_input\n",
    "        print(type(input_data))\n",
    "        print(input_data)\n",
    "        prompt = input_data\n",
    "        pipe = pipeline(\n",
    "        \"text-generation\", \n",
    "        model= self.model_loaded, \n",
    "        tokenizer = self.tokenizer, \n",
    "        torch_dtype=torch.bfloat16\n",
    "    )\n",
    "        print(\"pipe object is loaded\")\n",
    "        sequences = pipe(\n",
    "            prompt,\n",
    "            do_sample=True,\n",
    "            max_new_tokens=100, \n",
    "            temperature=0.7, \n",
    "            top_k=50, \n",
    "            top_p=0.95,\n",
    "            num_return_sequences=1,\n",
    "        )\n",
    "        print(sequences[0]['generated_text'])\n",
    "        print(\"inference generated\")\n",
    "        return sequences[0]['generated_text']\n",
    "\n",
    "    class Meta:    \n",
    "        # List of Callables() can be attached For Calling After AnSd Before Scoring\n",
    "        def __init__(self):\n",
    "            self.name = \"Pre Hooked Me !\"\n",
    "            self.pre_call_hooks.append(self.print_)\n",
    "        def print_(self):\n",
    "            print(self.name)\n",
    "        pre_call_hooks = []\n",
    "        post_call_hooks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ff982b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"How to reverse a string in python?\"\n",
    "import requests\n",
    "req = requests.Request()\n",
    "req.json = {\"payload\":prompt\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05d4b93d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Model From Data Volume\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "413eac3f76d74764b6a62fc34093b263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer object is loading from data section\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model and tokens are loaded\n"
     ]
    }
   ],
   "source": [
    "score_ = ScoreTemplateExample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6711dff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "print(\"Today's date:\", datetime.now())\n",
    "t1 = time.time()\n",
    "print(t1)\n",
    "model_predictions = score_.score(None, req, dry_run=True)\n",
    "print(\"Strachat Beta Notebook Testing\")\n",
    "t2 = time.time()\n",
    "t2-t1\n",
    "print(\"Today's date:\", datetime.now())\n",
    "print(\"ended the pipe\")\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4590e224",
   "metadata": {},
   "outputs": [],
   "source": [
    "register_model(None,\n",
    "               ScoreTemplateExample,\n",
    "               \"Starchat_Beta_Second_Version\",\n",
    "               \"Starchat_Beta_for_code_Generation\",\n",
    "               MLModelFlavours.pytorch,\n",
    "               init_script=\"pip install SentencePiece \\\\n pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\"\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c9d796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fc1026",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
