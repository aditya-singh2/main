{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57fbc6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02bb11f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('template_and_user_query.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56a6d654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>user query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the sales in 2020</td>\n",
       "      <td>What were the 2020 sales figures?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the sales in 2020</td>\n",
       "      <td>How much were the sales in 2020?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the sales in 2020</td>\n",
       "      <td>What was the sales volume in 2020?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the sales in 2020</td>\n",
       "      <td>What did the 2020 sales amount to?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the sales in 2020</td>\n",
       "      <td>What were the total sales for 2020?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    question                           user query\n",
       "0  What is the sales in 2020    What were the 2020 sales figures?\n",
       "1  What is the sales in 2020     How much were the sales in 2020?\n",
       "2  What is the sales in 2020   What was the sales volume in 2020?\n",
       "3  What is the sales in 2020   What did the 2020 sales amount to?\n",
       "4  What is the sales in 2020  What were the total sales for 2020?"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9060e905",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1de447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c37f45b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model that you want to train from the Hugging Face hub\n",
    "model_name = \"NousResearch/llama-2-7b-chat-hf\"\n",
    "\n",
    "# The instruction dataset to use\n",
    "#dataset_name = \"\"\n",
    "\n",
    "# Fine-tuned model name\n",
    "new_model = \"llama-2-7b-fine-tuned-peft-on-template_and_user_query-data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f2ceeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# QLoRA parameters\n",
    "################################################################################\n",
    "\n",
    "# LoRA attention dimension\n",
    "lora_r = 8\n",
    "\n",
    "# Alpha parameter for LoRA scaling\n",
    "lora_alpha = 16\n",
    "\n",
    "# Dropout probability for LoRA layers\n",
    "lora_dropout = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f83e1317",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# bitsandbytes parameters\n",
    "################################################################################\n",
    "\n",
    "# Activate 4-bit precision base model loading\n",
    "use_4bit = True\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "bnb_4bit_compute_dtype = \"float16\"\n",
    "\n",
    "# Quantization type (fp4 or nf4)\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "# Activate nested quantization for 4-bit base models (double quantization)\n",
    "use_nested_quant = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b95b0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# TrainingArguments parameters\n",
    "################################################################################\n",
    "\n",
    "# Output directory where the model predictions and checkpoints will be stored\n",
    "output_dir = \"/data/sept-22\"\n",
    "\n",
    "# Number of training epochs\n",
    "num_train_epochs = 15\n",
    "\n",
    "# Enable fp16/bf16 training (set bf16 to True with an A100)\n",
    "fp16 = False\n",
    "bf16 = False\n",
    "\n",
    "# Batch size per GPU for training\n",
    "per_device_train_batch_size = 4\n",
    "\n",
    "# Batch size per GPU for evaluation\n",
    "per_device_eval_batch_size = 4\n",
    "\n",
    "# Number of update steps to accumulate the gradients for\n",
    "gradient_accumulation_steps = 2\n",
    "\n",
    "# Enable gradient checkpointing\n",
    "gradient_checkpointing = True\n",
    "\n",
    "\n",
    "# Maximum gradient normal (gradient clipping)\n",
    "max_grad_norm = 0.3\n",
    "\n",
    "# Initial learning rate (AdamW optimizer)\n",
    "learning_rate = 2e-4\n",
    "\n",
    "# Weight decay to apply to all layers except bias/LayerNorm weights\n",
    "weight_decay = 0.001\n",
    "\n",
    "# Optimizer to use\n",
    "optim = \"paged_adamw_32bit\"\n",
    "\n",
    "# Learning rate schedule (constant a bit better than cosine)\n",
    "lr_scheduler_type = \"constant\"\n",
    "\n",
    "# Number of training steps (overrides num_train_epochs)\n",
    "max_steps = 10\n",
    "\n",
    "# Ratio of steps for a linear warmup (from 0 to learning rate)\n",
    "warmup_ratio = 0.03\n",
    "\n",
    "# Group sequences into batches with same length\n",
    "# Saves memory and speeds up training considerably\n",
    "group_by_length = True\n",
    "\n",
    "# Save checkpoint every X updates steps\n",
    "save_steps = 30\n",
    "\n",
    "# Log every X updates steps\n",
    "logging_steps = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd83a980",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# SFT parameters\n",
    "################################################################################\n",
    "\n",
    "# Maximum sequence length to use\n",
    "max_seq_length = None\n",
    "\n",
    "# Pack multiple short examples in the same input sequence to increase efficiency\n",
    "packing = False\n",
    "\n",
    "# Load the entire model on the GPU 0\n",
    "device_map = {\"\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0e97220",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template1 = \"\"\"### _LUMIN_ Question:\n",
    "{question}\n",
    "### Context: {context}\n",
    "### _LUMIN_ Answer: {answer}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7eec8c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"### Question:\n",
    "{user_query}\n",
    "\n",
    "### Context:\n",
    "Converting above _LUMIN_ Question to LUMIN specific template _LUMIN_ Answer.\n",
    "\n",
    "### Answer:\n",
    "{template_query}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f215307a",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"Converting above _LUMIN_ Question to LUMIN specific template _LUMIN_ Answer.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50d534e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['question', 'user query'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78a95227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fine_tuning_dataset(row):\n",
    "    user_query = row['user query']\n",
    "    template_query = row['question']\n",
    "    formated = prompt_template.format(user_query=user_query,\n",
    "                                      template_query=template_query)\n",
    "    data_point = str({'question': formated, \"answer\":template_query})\n",
    "    return data_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6859de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fine_tuning_dataset']=df.apply(create_fine_tuning_dataset, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8af15320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'question': '### Question:\\\\nMonthly distribution of sales contributions in subcategories?\\\\n\\\\n### Context:\\\\nConverting above _LUMIN_ Question to LUMIN specific template _LUMIN_ Answer.\\\\n\\\\n### Answer:\\\\nWhat is the contribution of sales for sub category across months', 'answer': 'What is the contribution of sales for sub category across months'}\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['fine_tuning_dataset'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1650ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['question','user query'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5f60dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2380, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f4c4086",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(df[:2100])\n",
    "val_dataset = Dataset.from_pandas(df[2100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "555e910f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['fine_tuning_dataset'],\n",
       "    num_rows: 280\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68cc3cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer and model with QLoRA configuration\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed25c775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nf4'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb_4bit_quant_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6664ecee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e2c3788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU compatibility with bfloat16\n",
    "if compute_dtype == torch.float16 and use_4bit:\n",
    "    major, _ = torch.cuda.get_device_capability()\n",
    "    if major >= 8:\n",
    "        print(\"=\" * 80)\n",
    "        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n",
    "        print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba0a15e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43bb227ac5c145208d6e1a2e4552b079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load base model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=device_map\n",
    ")\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef60f964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load LLaMA tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True,\n",
    "                                          # add_eos_token=True,\n",
    "                                          use_fast=False)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a6716c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(tokenizer.encode(df['fine_tuning_dataset'][i])) for i in range(2380)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5fc5bf25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.encode(df['fine_tuning_dataset'][30]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "92a7efe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s>'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "75ffc6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA configuration\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    r=lora_r,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e30b281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training parameters\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    optim=optim,\n",
    "    save_steps=save_steps,\n",
    "    eval_steps=30,\n",
    "    per_device_eval_batch_size=1, # Batch size for evaluation\n",
    "    evaluation_strategy=\"steps\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=1,\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    fp16=fp16,\n",
    "    bf16=bf16,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    #max_steps=300,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    group_by_length=group_by_length,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    report_to=\"tensorboard\",\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=1,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "de52effd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['fine_tuning_dataset'],\n",
       "    num_rows: 2100\n",
       "})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f8bf5981",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/peft/utils/other.py:122: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bb8cdf431274d4daacdca3baf29d5e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd90f3f9701443c96e1c8afb81c591e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/280 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set supervised fine-tuning parameters\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"fine_tuning_dataset\",\n",
    "    max_seq_length=256,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing=packing,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d942d91c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fine_tuning_dataset': \"{'question': '### Question:\\\\nMonthly distribution of sales contributions in subcategories?\\\\n\\\\n### Context:\\\\nConverting above _LUMIN_ Question to LUMIN specific template _LUMIN_ Answer.\\\\n\\\\n### Answer:\\\\nWhat is the contribution of sales for sub category across months', 'answer': 'What is the contribution of sales for sub category across months'}\"}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5769042",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2693' max='3930' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2693/3930 13:46:40 < 6:20:00, 0.05 it/s, Epoch 10.26/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.595000</td>\n",
       "      <td>0.584195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.318600</td>\n",
       "      <td>0.335287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.340400</td>\n",
       "      <td>0.287619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.240500</td>\n",
       "      <td>0.268605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.235100</td>\n",
       "      <td>0.256675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.245800</td>\n",
       "      <td>0.235366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.196000</td>\n",
       "      <td>0.237285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.216900</td>\n",
       "      <td>0.222574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.198500</td>\n",
       "      <td>0.218432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.190800</td>\n",
       "      <td>0.215737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.204500</td>\n",
       "      <td>0.213609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.220800</td>\n",
       "      <td>0.216444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.160400</td>\n",
       "      <td>0.206863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.165600</td>\n",
       "      <td>0.205813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.215400</td>\n",
       "      <td>0.194284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.184000</td>\n",
       "      <td>0.199127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.172500</td>\n",
       "      <td>0.196355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.142500</td>\n",
       "      <td>0.197327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.181600</td>\n",
       "      <td>0.193128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.178900</td>\n",
       "      <td>0.190865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.164600</td>\n",
       "      <td>0.196088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.143900</td>\n",
       "      <td>0.188838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.168100</td>\n",
       "      <td>0.193590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.213400</td>\n",
       "      <td>0.192342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.164300</td>\n",
       "      <td>0.188792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.170600</td>\n",
       "      <td>0.188473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>0.146100</td>\n",
       "      <td>0.186532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.160300</td>\n",
       "      <td>0.190835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>0.139400</td>\n",
       "      <td>0.185930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.150700</td>\n",
       "      <td>0.181790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.181512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.172900</td>\n",
       "      <td>0.183345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>0.181600</td>\n",
       "      <td>0.191822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.147000</td>\n",
       "      <td>0.178160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.166600</td>\n",
       "      <td>0.178839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.127600</td>\n",
       "      <td>0.184289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1110</td>\n",
       "      <td>0.142900</td>\n",
       "      <td>0.178189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.177400</td>\n",
       "      <td>0.184878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1170</td>\n",
       "      <td>0.129400</td>\n",
       "      <td>0.180682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.175400</td>\n",
       "      <td>0.186400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1230</td>\n",
       "      <td>0.134000</td>\n",
       "      <td>0.179060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.160400</td>\n",
       "      <td>0.182709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1290</td>\n",
       "      <td>0.208700</td>\n",
       "      <td>0.178900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.119400</td>\n",
       "      <td>0.176605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.145100</td>\n",
       "      <td>0.182215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.128200</td>\n",
       "      <td>0.182751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1410</td>\n",
       "      <td>0.140400</td>\n",
       "      <td>0.182647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.127300</td>\n",
       "      <td>0.182189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1470</td>\n",
       "      <td>0.145800</td>\n",
       "      <td>0.185150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.141400</td>\n",
       "      <td>0.178363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1530</td>\n",
       "      <td>0.127700</td>\n",
       "      <td>0.174367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.143000</td>\n",
       "      <td>0.176693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1590</td>\n",
       "      <td>0.117800</td>\n",
       "      <td>0.183660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.128500</td>\n",
       "      <td>0.182159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.137900</td>\n",
       "      <td>0.176290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.122000</td>\n",
       "      <td>0.183669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1710</td>\n",
       "      <td>0.125300</td>\n",
       "      <td>0.180264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.121100</td>\n",
       "      <td>0.179288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1770</td>\n",
       "      <td>0.139200</td>\n",
       "      <td>0.180956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.129900</td>\n",
       "      <td>0.181002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1830</td>\n",
       "      <td>0.134300</td>\n",
       "      <td>0.181317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.113300</td>\n",
       "      <td>0.196684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1890</td>\n",
       "      <td>0.132400</td>\n",
       "      <td>0.199066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.127300</td>\n",
       "      <td>0.195055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.114400</td>\n",
       "      <td>0.182935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980</td>\n",
       "      <td>0.129000</td>\n",
       "      <td>0.183030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2010</td>\n",
       "      <td>0.114200</td>\n",
       "      <td>0.181150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2040</td>\n",
       "      <td>0.108500</td>\n",
       "      <td>0.187049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2070</td>\n",
       "      <td>0.123000</td>\n",
       "      <td>0.186266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.137600</td>\n",
       "      <td>0.179460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2130</td>\n",
       "      <td>0.116200</td>\n",
       "      <td>0.192724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2160</td>\n",
       "      <td>0.104900</td>\n",
       "      <td>0.191804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2190</td>\n",
       "      <td>0.116300</td>\n",
       "      <td>0.191645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2220</td>\n",
       "      <td>0.117300</td>\n",
       "      <td>0.187972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.132600</td>\n",
       "      <td>0.190306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2280</td>\n",
       "      <td>0.129300</td>\n",
       "      <td>0.180849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2310</td>\n",
       "      <td>0.101300</td>\n",
       "      <td>0.190020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2340</td>\n",
       "      <td>0.140100</td>\n",
       "      <td>0.187756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2370</td>\n",
       "      <td>0.089000</td>\n",
       "      <td>0.192478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.128800</td>\n",
       "      <td>0.194164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2430</td>\n",
       "      <td>0.102800</td>\n",
       "      <td>0.195783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2460</td>\n",
       "      <td>0.128400</td>\n",
       "      <td>0.195267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2490</td>\n",
       "      <td>0.121300</td>\n",
       "      <td>0.193006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2520</td>\n",
       "      <td>0.103400</td>\n",
       "      <td>0.196558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.192465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2580</td>\n",
       "      <td>0.114600</td>\n",
       "      <td>0.193554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2610</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.198199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2640</td>\n",
       "      <td>0.104800</td>\n",
       "      <td>0.207990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2670</td>\n",
       "      <td>0.120800</td>\n",
       "      <td>0.206141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f0633f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuned model name\n",
    "new_model = \"llama-2-7b-fine-tuned-peft-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5c3526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "trainer.model.save_pretrained(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cbfc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "84916548",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel, PeftConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "99617b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_merge = PeftModel.from_pretrained(\n",
    "    model,\n",
    "    'llama-2-7b-fine-tuned-peft-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4d7fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "670ccb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_template = \"\"\"### Instruction:\n",
    "# Converting below input to LUMIN understandable format.\n",
    "# ### Input:\n",
    "# {user_query}\n",
    "# ### Response:\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb61f802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load LLaMA tokenizer\n",
    "# query_tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True,\n",
    "#                                           add_eos_token=False,\n",
    "#                                           use_fast=True)\n",
    "# #tokenizer.pad_token = tokenizer.eos_token\n",
    "# query_tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "196a3d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict_template_query(user_query):\n",
    "#     question = query_template.format(user_query=user_query)\n",
    "#     _input = str({'question': question})\n",
    "#     print(_input)\n",
    "#     _inputs = tokenizer.encode(_input, return_tensors=\"pt\")\n",
    "#     print(_inputs)\n",
    "#     print(type(_inputs))\n",
    "#     outputs = model_to_merge.generate(input_ids=_inputs.to('cuda'), max_length= 200)\n",
    "#     output = tokenizer.decode(outputs[0])\n",
    "#     # print(output)\n",
    "#     # a = output.split(\"_LUMIN_ Answer\",1)[1]\n",
    "#     #print(a)\n",
    "#     return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f69bfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inp = 'What were the 2020 sales figures?'\n",
    "# predict_template_query(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a1a7769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inp = \"why production dropped for bikes in 1st quarter 2022\"\n",
    "# predict_template_query(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac29f8f8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# inp = 'why sales of texas increase in 1st quarter 2023'\n",
    "# a = predict_template_query(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83e75fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e6bd05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e68c1d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# inp = 'drivers of profit'\n",
    "# predict_template_query(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1023e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inp = \"why sales dropped for bikes in 1st quarter 2022\"\n",
    "# predict_template_query(inp).split('\\n')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba9f621",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912f2759",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
