{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0305521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer,BitsAndBytesConfig\n",
    "import json\n",
    "from query_to_mql_tt_integrated import system_msg,context,postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cdcb45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Tesla T4\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3957d714",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# bitsandbytes parameters\n",
    "################################################################################\n",
    "\n",
    "# Activate 4-bit precision base model loading\n",
    "use_4bit = True\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "bnb_4bit_compute_dtype = \"float16\"\n",
    "\n",
    "# Quantization type (fp4 or nf4)\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "\n",
    "# Activate nested quantization for 4-bit base models (double quantization)\n",
    "use_nested_quant = False\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")\n",
    "# Load the entire model on the GPU 0\n",
    "device_map = {\"\": 0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e6d6830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1970747df7ea4c7b9982fc9f605f9d22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"NousResearch/llama-2-7b-chat-hf\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name,quantization_config=bnb_config,\n",
    "    device_map=device_map)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a7a18d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing prompt\n",
    "\n",
    "# question = \"what are the sales in africa\"\n",
    "# prompt = f\"\"\"[INST]<<SYS>>\n",
    "# Assume you are a system that detects the month and year in the given secentance, user will give only provide the input in english.\n",
    "# For example if user gives \"top  orders in march 2020\", you should only return march 2020.\n",
    "\n",
    "# <</SYS>>\n",
    "# {question}\n",
    "# [/INST]\n",
    "# [END]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "121ba1af",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def gereneate_output_llama2(prompt):\n",
    "    #prompt = json.dumps(prompt)\n",
    "    model_input = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    #model.eval()\n",
    "    response = tokenizer.decode(model.generate(**model_input, max_length=4096)[0], skip_special_tokens=True)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3891448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_question(question):\n",
    "    return \"Based on the following context:\\n\" + str(context) + \"\\n return a response for the question:\\n\" + question + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "642d98be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compose_prompt(question):\n",
    "    return f\"\"\"[INST]<<SYS>>\n",
    "            {system_msg}\n",
    "            <</SYS>>\n",
    "            {get_user_question(question)}\n",
    "            [/INST]\n",
    "            [END]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d3fe4923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(output):\n",
    "    mql = output.split(\"[END]\")[1].split(\"\\n\\nReasoning:\\n\\n\")[0]\n",
    "    reason = output.split(\"[END]\")[1].split(\"\\n\\nReasoning:\\n\\n\")[1]\n",
    "    print(\"*\"*50+\"MQL\"+\"*\"*50)\n",
    "    print(mql)\n",
    "    print(\"\\n\"+\"*\"*50+\"Reason\"+\"*\"*50)\n",
    "    print(reason)\n",
    "    #return mql,reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f63e799a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************MQL**************************************************\n",
      "\n",
      "\n",
      "The response for the question \"top 5 segments basis discount\" is as follows:\n",
      "\n",
      "{\n",
      "\"MEASURE\": {\n",
      "\"n-gram matched to MEASURE\": [\n",
      "{\n",
      "\"ENTITY\": \"Matched MEASURE\",\n",
      "\"MEASURE CONSTRAINT\": [\n",
      "{\n",
      "\"COMPARISON VALUE\": \"top 5\",\n",
      "\"COMPARISION OPERATOR\": \"=\"\n",
      "}\n",
      "],\n",
      "\"ADJECTIVE\": [],\n",
      "\"TONE\": \"\"\n",
      "}\n",
      "],\n",
      "\"DIMENSION\": {\n",
      "\"n-gram matched to DIMENSION\": [\n",
      "{\n",
      "\"ENTITY\": \"Matched DIMENSION\",\n",
      "\"RANK\": [\n",
      "{\n",
      "\"RANK ADJECTIVE\": \"top\",\n",
      "\"RANK VALUE\": \"5\"\n",
      "}\n",
      "],\n",
      "\"ADJECTIVE\": [],\n",
      "\"TONE\": \"\"\n",
      "}\n",
      "],\n",
      "\"FILTER\": {\n",
      "\"n-gram matched to FILTER\": [\n",
      "{\n",
      "\"ENTITY\": \"Matched FILTER\",\n",
      "\"PARENT\": \"Segment\",\n",
      "\"EXCLUDE\": \"\"\n",
      "}\n",
      "],\n",
      "\"DERIVED MEASURE\": {\n",
      "\"n-gram matched to DERIVED MEASURE\": [\n",
      "{\n",
      "\"ENTITY\": \"Matched DERIVED MEASURE\",\n",
      "\"RATIO FILTER\": [\n",
      "{}\n",
      "],\n",
      "\"APPLIED MEASURE\": [\n",
      "{\n",
      "\"n-gram matched to MEASURE\": [\n",
      "{\n",
      "\"ENTITY\": \"Discount\",\n",
      "\"RANK\": [\n",
      "{\n",
      "\"RANK ADJECTIVE\": \"top\",\n",
      "\"RANK VALUE\": \"5\"\n",
      "}\n",
      "]\n",
      "}\n",
      "],\n",
      "\"ADJECTIVE\": [],\n",
      "\"TONE\": \"\"\n",
      "}\n",
      "],\n",
      "\"DATE VARIABLE\": {\n",
      "\"asked time element\": [\n",
      "{\n",
      "\"ENTITY\": \"Matched DATE VARIABLE\",\n",
      "\"DATE RANGE\": \"last 3 months\",\n",
      "\"CONVERTED TIME ELEMENT\": \"01/01/2020 - 15/09/2023\"\n",
      "}\n",
      "]\n",
      "}\n",
      "}\n",
      "\n",
      "**************************************************Reason**************************************************\n",
      "Based on the context provided, the top 5 segments basis discount are:\n",
      "\n",
      "1. Segment - Top 5 segments with high discount\n",
      "2. Sub-Category - Top 5 sub-categories with high discount\n",
      "3. Country - Top 5 countries with high discount\n",
      "4. Date - Last 3 months with high discount\n",
      "5. Corporate - Top 5 corporates with high discount\n",
      "\n",
      "The response provides the measured entity \"Discount\" with a rank of \"top 5\" and a rank value of \"5\", indicating that the top 5 segments, sub-categories, countries, dates, or corporates have high discount. The response also includes the date range for the last 3 months, which is from 01/01/2020 to 15/09/2023.\n",
      "\n",
      "The reasoning for the response is as follows:\n",
      "\n",
      "* The question is asking for the top 5 segments basis discount, so the response provides the measured entity \"Discount\" with a rank of \"top 5\" and a rank value of \"5\".\n",
      "* The response includes the date range for the last 3 months, which is the time frame requested in the question.\n",
      "* The response provides the measured entity \"Discount\" with a rank of \"top 5\" and a rank value of \"5\", indicating that the top 5 segments, sub-categories, countries, dates, or corporates have high discount.\n",
      "\n",
      "The response is based on the context provided and the information available in the question.\n",
      "CPU times: user 54.6 s, sys: 784 ms, total: 55.4 s\n",
      "Wall time: 55.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "question = \"top 5 segments basis discount\"\n",
    "output=gereneate_output_llama2(compose_prompt(question))\n",
    "post_process(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8420e2c2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************MQL**************************************************\n",
      "\n",
      "\n",
      "The response for the question \"discount rate of phone and binders\" is:\n",
      "\n",
      "{\n",
      "\"MEASURE\": [\n",
      "{\n",
      "\"ENTITY\": \"Discount\",\n",
      "\"other names\": [\"discount\", \"discount rate\", \"discount value\", \"deduction\"]\n",
      "},\n",
      "{\n",
      "\"ENTITY\": \"Purchase Vol\",\n",
      "\"other names\": [\"purchase\", \"purchase value\", \"purchase model\"]\n",
      "},\n",
      "{\n",
      "\"ENTITY\": \"Quantity\",\n",
      "\"other names\": [\"quantity\", \"volume\"]\n",
      "},\n",
      "{\n",
      "\"ENTITY\": \"Sales\",\n",
      "\"other names\": [\"sales\", \"sale\"]\n",
      "}\n",
      "],\n",
      "\"DIMENSION\": [\n",
      "{\n",
      "\"ENTITY\": \"Sub-Category\",\n",
      "\"other names\": [\"sub-category\", \"sub category\", \"categories\", \"section\"]\n",
      "},\n",
      "{\n",
      "\"ENTITY\": \"Segment\",\n",
      "\"other names\": [\"segment\", \"segments\", \"units\", \"divisions\"]\n",
      "},\n",
      "{\n",
      "\"ENTITY\": \"Parts\",\n",
      "\"other names\": [\"parts\", \"part\", \"section\", \"divisions\"]\n",
      "},\n",
      "{\n",
      "\"ENTITY\": \"Country\",\n",
      "\"other names\": [\"country\", \"countries\"]\n",
      "}\n",
      "],\n",
      "\"FILTER\": [\n",
      "{\n",
      "\"ENTITY\": \"Consumer\",\n",
      "\"other names\": [\"consumers\", \"consumer\"],\n",
      "\"parent\": \"Segment\"\n",
      "},\n",
      "{\n",
      "\"ENTITY\": \"Phone\",\n",
      "\"other names\": [\"phone\", \"phones\", \"mobile phones\"],\n",
      "\"parent\": \"Sub-Category\"\n",
      "},\n",
      "{\n",
      "\"ENTITY\": \"Binder\",\n",
      "\"other names\": [\"binders\", \"binder\"],\n",
      "\"parent\": \"Sub-Category\"\n",
      "},\n",
      "{\n",
      "\"ENTITY\": \"Corporate\",\n",
      "\"other names\": [\"corporates\", \"corporate\"],\n",
      "\"parent\": \"Segment\"\n",
      "},\n",
      "{\n",
      "\"ENTITY\": \"India\",\n",
      "\"other names\": [\"india\"],\n",
      "\"parent\": \"Country\"\n",
      "},\n",
      "{\n",
      "\"ENTITY\": \"Dubai\",\n",
      "\"other names\": [\"dubai\"],\n",
      "\"parent\": \"Country\"\n",
      "}\n",
      "],\n",
      "\"DERIVED MEASURE\": [\n",
      "{\n",
      "\"ENTITY\": \"Ratio\",\n",
      "\"other names\": [\"ratio\", \"share\", \"contribution\", \"percentage\", \"proportion\", \"contributing\"]\n",
      "},\n",
      "{\n",
      "\"ENTITY\": \"Why\",\n",
      "\"other names\": [\"why\", \"cause of\", \"reason for\", \"diagnose\"]\n",
      "},\n",
      "{\n",
      "\"ENTITY\": \"contribution_to_growth\",\n",
      "\"other names\": [\"contribution to growth\", \"growth\", \"grown\"]\n",
      "},\n",
      "{\n",
      "\"ENTITY\": \"kda_transactional\",\n",
      "\"other names\": [\"kda\", \"key drivers\", \"key driver\", \"drivers\", \"driver\"]\n",
      "},\n",
      "{\n",
      "\"ENTITY\": \"Growth Rate\",\n",
      "\"other names\": [\"growth rate\", \"growth\", \"grown\"]\n",
      "},\n",
      "{\n",
      "\"ENTITY\": \"correlation\",\n",
      "\"other names\": [\"associate\", \"associated\", \"association\", \"associations\", \"correlate\", \"correlated\", \"correlation\", \"correlations\", \"relate\", \"related\", \"relation\", \"relations\", \"relationship\", \"relationships\"]\n",
      "}\n",
      "],\n",
      "\"DATE VARIABLE\": [\n",
      "{\n",
      "\"ENTITY\": \"Order Date\",\n",
      "\"other names\": [\"order date\", \"date\", \"trend\", \"time\", \"when\", \"mom\", \"yoy\"]\n",
      "}\n",
      "]\n",
      "}\n",
      "\n",
      "**************************************************Reason**************************************************\n",
      "Based on the input question, the following entities match:\n",
      "\n",
      "* Discount (ENTITY: \"Discount\")\n",
      "* Purchase Vol (ENTITY: \"Purchase Vol\")\n",
      "* Quantity (ENTITY: \"Quantity\")\n",
      "* Sales (ENTITY: \"Sales\")\n",
      "\n",
      "The following dimensions match:\n",
      "\n",
      "* Sub-Category (ENTITY: \"Sub-Category\")\n",
      "* Segment (ENTITY: \"Segment\")\n",
      "* Parts (ENTITY: \"Parts\")\n",
      "* Country (ENTITY: \"Country\")\n",
      "\n",
      "The following filters match:\n",
      "\n",
      "* Consumer (ENTITY: \"Consumer\")\n",
      "* Phone (ENTITY: \"Phone\")\n",
      "* Binder (ENTITY: \"Binder\")\n",
      "* Corporate (ENTITY: \"Corporate\")\n",
      "* India (ENTITY: \"India\")\n",
      "* Dubai (ENTITY: \"Dubai\")\n",
      "\n",
      "The following derived measures match:\n",
      "\n",
      "* Ratio (ENTITY: \"Ratio\")\n",
      "* Why (ENTITY: \"Why\")\n",
      "* contribution_to_growth (ENTITY: \"contribution_to_growth\")\n",
      "* kda_transactional (ENTITY: \"kda_transactional\")\n",
      "* Growth Rate (ENTITY: \"Growth Rate\")\n",
      "* correlation (ENTITY: \"correlation\")\n",
      "\n",
      "The following date variables match:\n",
      "\n",
      "* Order Date (ENTITY: \"Order Date\")\n",
      "\n",
      "The response provides the identified entities, dimensions, filters, derived measures, and date variables for the input question.\n",
      "CPU times: user 1min 20s, sys: 1.47 s, total: 1min 21s\n",
      "Wall time: 1min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "question = \"discount rate of phone and binders\"\n",
    "output=gereneate_output_llama2(compose_prompt(question))\n",
    "post_process(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "519c441c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/mosaic-ai/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mWARNING: The directory '/home/mosaic-ai/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Collecting ipywidgets\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/0e/57ed498fafbc60419a9332d872e929879ceba2d73cb11d284d7112472b3e/ipywidgets-8.1.1-py3-none-any.whl (139kB)\n",
      "\u001b[K     |████████████████████████████████| 143kB 6.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting traitlets>=4.3.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/e9/d82415708306eb348fb16988c4697076119dfbfa266f17f74e514a23a723/traitlets-5.11.2-py3-none-any.whl (83kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 18.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting comm>=0.1.3\n",
      "  Downloading https://files.pythonhosted.org/packages/fe/47/0133ac1b7dc476ed77710715e98077119b3d9bae56b13f6f9055e7da1c53/comm-0.1.4-py3-none-any.whl\n",
      "Collecting jupyterlab-widgets~=3.0.9\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/05/0ebab152288693b5ec7b339aab857362947031143b282853b4c2dd4b5b40/jupyterlab_widgets-3.0.9-py3-none-any.whl (214kB)\n",
      "\u001b[K     |████████████████████████████████| 215kB 17.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting widgetsnbextension~=4.0.9\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/03/107d96077c4befed191f7ad1a12c7b52a8f9d2778a5836d59f9855c105f6/widgetsnbextension-4.0.9-py3-none-any.whl (2.3MB)\n",
      "\u001b[K     |████████████████████████████████| 2.3MB 21.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting ipython>=6.1.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8d/97/8fe103906cd81bc42d3b0175b5534a9f67dccae47d6451131cf8d0d70bb2/ipython-8.12.3-py3-none-any.whl (798kB)\n",
      "\u001b[K     |████████████████████████████████| 798kB 66.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting backcall\n",
      "  Downloading https://files.pythonhosted.org/packages/4c/1c/ff6546b6c12603d8dd1070aa3c3d273ad4c07f5771689a7b69a550e8c951/backcall-0.2.0-py2.py3-none-any.whl\n",
      "Collecting pexpect>4.3; sys_platform != \"win32\"\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/39/7b/88dbb785881c28a102619d46423cb853b46dbccc70d3ac362d99773a78ce/pexpect-4.8.0-py2.py3-none-any.whl (59kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 90.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting decorator\n",
      "  Downloading https://files.pythonhosted.org/packages/d5/50/83c593b07763e1161326b3b8c6686f0f4b0f24d5526546bee538c89837d6/decorator-5.1.1-py3-none-any.whl\n",
      "Collecting typing-extensions; python_version < \"3.10\"\n",
      "  Downloading https://files.pythonhosted.org/packages/24/21/7d397a4b7934ff4028987914ac1044d3b7d52712f30e2ac7a2ae5bc86dd0/typing_extensions-4.8.0-py3-none-any.whl\n",
      "Collecting pickleshare\n",
      "  Downloading https://files.pythonhosted.org/packages/9a/41/220f49aaea88bc6fa6cba8d05ecf24676326156c23b991e80b3f2fc24c77/pickleshare-0.7.5-py2.py3-none-any.whl\n",
      "Collecting pygments>=2.4.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/88/29adf0b44ba6ac85045e63734ae0997d3c58d8b1a91c914d240828d0d73d/Pygments-2.16.1-py3-none-any.whl (1.2MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2MB 101.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting matplotlib-inline\n",
      "  Downloading https://files.pythonhosted.org/packages/f2/51/c34d7a1d528efaae3d8ddb18ef45a41f284eacf9e514523b191b7d0872cc/matplotlib_inline-0.1.6-py3-none-any.whl\n",
      "Collecting jedi>=0.16\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/9f/bc63f0f0737ad7a60800bfd472a4836661adae21f9c2535f3957b1e54ceb/jedi-0.19.1-py2.py3-none-any.whl (1.6MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6MB 88.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/b4/ba77c84edf499877317225d7b7bc047a81f7c2eed9628eeb6bab0ac2e6c9/prompt_toolkit-3.0.39-py3-none-any.whl (385kB)\n",
      "\u001b[K     |████████████████████████████████| 389kB 94.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting stack-data\n",
      "  Downloading https://files.pythonhosted.org/packages/f1/7b/ce1eafaf1a76852e2ec9b22edecf1daa58175c090266e9f6c64afcd81d91/stack_data-0.6.3-py3-none-any.whl\n",
      "Collecting ptyprocess>=0.5\n",
      "  Downloading https://files.pythonhosted.org/packages/22/a6/858897256d0deac81a172289110f31629fc4cee19b6f01283303e18c8db3/ptyprocess-0.7.0-py2.py3-none-any.whl\n",
      "Collecting parso<0.9.0,>=0.8.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/63/8011bd08a4111858f79d2b09aad86638490d62fbf881c44e434a6dfca87b/parso-0.8.3-py2.py3-none-any.whl (100kB)\n",
      "\u001b[K     |████████████████████████████████| 102kB 101.5MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting wcwidth\n",
      "  Downloading https://files.pythonhosted.org/packages/58/19/a9ce39f89cf58cf1e7ce01c8bb76ab7e2c7aadbc5a2136c3e192097344f5/wcwidth-0.2.8-py2.py3-none-any.whl\n",
      "Collecting pure-eval\n",
      "  Downloading https://files.pythonhosted.org/packages/2b/27/77f9d5684e6bce929f5cfe18d6cfbe5133013c06cb2fbf5933670e60761d/pure_eval-0.2.2-py3-none-any.whl\n",
      "Collecting asttokens>=2.1.0\n",
      "  Downloading https://files.pythonhosted.org/packages/4f/25/adda9979586d9606300415c89ad0e4c5b53d72b92d2747a3c634701a6a02/asttokens-2.4.0-py2.py3-none-any.whl\n",
      "Collecting executing>=1.2.0\n",
      "  Downloading https://files.pythonhosted.org/packages/bb/3f/748594706233e45fd0e6fb57a2fbfe572485009c52b19919d161a0ae5d52/executing-2.0.0-py2.py3-none-any.whl\n",
      "Collecting six>=1.12.0\n",
      "  Downloading https://files.pythonhosted.org/packages/d9/5a/e7c31adbe875f2abbb91bd84cf2dc52d792b5a01506781dbcf25c91daf11/six-1.16.0-py2.py3-none-any.whl\n",
      "\u001b[31mERROR: jupyterlab 3.2.4 has requirement jupyter-server~=1.4, but you'll have jupyter-server 2.0.0a1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: traitlets, comm, jupyterlab-widgets, widgetsnbextension, backcall, ptyprocess, pexpect, decorator, typing-extensions, pickleshare, pygments, matplotlib-inline, parso, jedi, wcwidth, prompt-toolkit, pure-eval, six, asttokens, executing, stack-data, ipython, ipywidgets\n",
      "Successfully installed asttokens-2.4.0 backcall-0.2.0 comm-0.1.4 decorator-5.1.1 executing-2.0.0 ipython-8.12.3 ipywidgets-8.1.1 jedi-0.19.1 jupyterlab-widgets-3.0.9 matplotlib-inline-0.1.6 parso-0.8.3 pexpect-4.8.0 pickleshare-0.7.5 prompt-toolkit-3.0.39 ptyprocess-0.7.0 pure-eval-0.2.2 pygments-2.16.1 six-1.16.0 stack-data-0.6.3 traitlets-5.11.2 typing-extensions-4.8.0 wcwidth-0.2.8 widgetsnbextension-4.0.9\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d1d9bc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "input_widget = widgets.Text(placeholder='Type your message and press Enter', description='User Input:')\n",
    "chat_output = widgets.Output()\n",
    "def generate_response(user_input):\n",
    "    # Replace this with actual code to interact with your LLM\n",
    "    response = \"Chatbot: Thanks for your message - \" + user_input\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "de52c9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_enter_key_change(change):\n",
    "    if change['new']:\n",
    "        with chat_output:\n",
    "            user_input = input_widget.value\n",
    "            response = generate_response(user_input)\n",
    "            print(response)\n",
    "        input_widget.value = ''\n",
    "\n",
    "input_widget.observe(on_enter_key_change, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "34896d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "487b50015c484fd3a73a3323cd6520b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='User Input:', placeholder='Type your message and press Enter')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10b1049e4dab4f8992beb9f8809341fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Thanks for your message - hoi\n"
     ]
    }
   ],
   "source": [
    "display(input_widget, chat_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
