{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47e8ffdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67a47dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.34.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer,BitsAndBytesConfig\n",
    "import json\n",
    "#from Gpt4_OpenAI_Prompt import system_msg,context,postprocess\n",
    "#from prompt1 import system_msg\n",
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d492d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Tesla T4\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614fe881",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = {\n",
    "    \"MEASURE\": [{\"ENTITY\": \"Discount\", \"other names\": [\"discount\", \"discount rate\", \"discount value\", \"deduction\"]},\n",
    "                {\"ENTITY\": \"Purchase Vol\", \"other names\": [\"purchase\", \"purchase value\", \"purchase model\"]},\n",
    "                {\"ENTITY\": \"Quantity\", \"other names\": [\"quantity\", \"volume\"]},\n",
    "                {\"ENTITY\": \"Sales\", \"other names\": [\"sales\", \"sale\"]}],\n",
    "    \"DIMENSION\": [{\"ENTITY\": \"Sub-Category\", \"other names\": [\"sub-category\", \"sub category\", \"categories\", \"section\"]},\n",
    "                  {\"ENTITY\": \"Segment\", \"other names\": [\"segment\", \"segments\", \"units\", \"divisions\"]},\n",
    "                  {\"ENTITY\": \"Parts\", \"other names\": [\"parts\", \"part\", \"section\", \"divisions\"]},\n",
    "                  {\"ENTITY\": \"Country\", \"other names\": [\"country\", \"countries\"]}],\n",
    "    \"FILTER\": [{\"ENTITY\": \"Consumer\", \"other names\": [\"consumers\", \"consumer\"], \"parent\": \"Segment\"},\n",
    "               {\"ENTITY\": \"Phone\", \"other names\": [\"phone\", \"phones\", \"mobile phones\"], \"parent\": \"Sub-Category\"},\n",
    "               {\"ENTITY\": \"Binder\", \"other names\": [\"binders\", \"binder\"], \"parent\": \"Sub-Category\"},\n",
    "               {\"ENTITY\": \"Corporate\", \"other names\": [\"corporates\", \"corporate\"], \"parent\": \"Segment\"},\n",
    "               {\"ENTITY\": \"India\", \"other names\": [\"india\"], \"parent\": \"Country\"},\n",
    "               {\"ENTITY\": \"Dubai\", \"other names\": [\"dubai\"], \"parent\": \"Country\"}],\n",
    "    \"DERIVED MEASURE\": [{\"ENTITY\": \"Ratio\",\n",
    "                         \"other names\": [\"ratio\", \"share\", \"contribution\", \"percentage\", \"proportion\", \"contributing\"]},\n",
    "                        {\"ENTITY\": \"Why\", \"other names\": [\"why\", \"cause of\", \"reason for\", \"diagnose\"]},\n",
    "                        {\"ENTITY\": \"contribution_to_growth\",\n",
    "                         \"other names\": [\"contribution to growth\", \"growth\", \"grown\"]},\n",
    "                        {\"ENTITY\": \"kda_transactional\",\n",
    "                         \"other names\": [\"kda\", \"key drivers\", \"key driver\", \"drivers\", \"driver\"]},\n",
    "                        {\"ENTITY\": \"Growth Rate\", \"other names\": [\"growth rate\", \"growth\", \"grown\"]},\n",
    "                        {\"ENTITY\": \"correlation\",\n",
    "                         \"other names\": [\"associate\", \"associated\", \"association\", \"associations\", \"correlate\",\n",
    "                                         \"correlated\",\n",
    "                                         \"correlation\", \"correlations\", \"relate\", \"related\", \"relation\", \"relations\",\n",
    "                                         \"relationship\",\n",
    "                                         \"relationships\"]}\n",
    "                        ],\n",
    "    \"DATE VARIABLE\": [\n",
    "        {\"ENTITY\": \"Order Date\", \"other names\": [\"order date\", \"date\", \"trend\", \"time\", \"when\", \"mom\", \"yoy\"]}]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b74f54c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# bitsandbytes parameters\n",
    "################################################################################\n",
    "\n",
    "# Activate 4-bit precision base model loading\n",
    "use_4bit = True\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "bnb_4bit_compute_dtype = \"float32\"\n",
    "\n",
    "# Quantization type (fp4 or nf4)\n",
    "bnb_4bit_quant_type = \"fp4\"\n",
    "\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "\n",
    "# Activate nested quantization for 4-bit base models (double quantization)\n",
    "use_nested_quant = False\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")\n",
    "# Load the entire model on the GPU 0\n",
    "device_map = {\"\": 0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b77484d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e7f81e88f25442d89482b6b84f2b0a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "# model_mistral = AutoModelForCausalLM.from_pretrained(model_name,quantization_config=bnb_config,\n",
    "#     device_map=device_map)\n",
    "model_mistral = AutoPeftModelForCausalLM.from_pretrained(new_model_name, device_map=\"auto\", torch_dtype=torch.bfloat16)\n",
    "tokenizer_mistral = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a34dbf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gereneate_output_mistral(prompt):\n",
    "    #prompt = json.dumps(prompt)\n",
    "    model_input = tokenizer_mistral(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    #model.eval()\n",
    "    response = tokenizer_mistral.decode(model_mistral.generate(**model_input, max_length=4069*2)[0], skip_special_tokens=True)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef73bafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Setting the same prompt which is used for GPT4 open AI\n",
    "################################################################################\n",
    "\n",
    "def get_user_question_for_open_ai_prompt(question):\n",
    "    #return \"\"\"Now Based on this following \"CONTEXT\" data lookup:\\n\"\"\" + str(context) + \"\\n return a response for the question:\\n\" + question + \"\\n\"\n",
    "    return \"\\n Now detect from this question:\\n\" + question + \"\\n\"\n",
    "\n",
    "def compose_prompt_open_ai_prompt(question,base_prompt):\n",
    "    return f\"\"\"[INST]<<SYS>>\n",
    "            {base_prompt}\n",
    "            <</SYS>>\n",
    "            {get_user_question_for_open_ai_prompt(question)}\n",
    "            [/INST]\n",
    "            [_separator_]\"\"\"\n",
    "\n",
    "def post_process_open_ai_prompt_response(output):\n",
    "    mql = output.split(\"[END]\")[1].split(\"\\n\\nReasoning:\\n\\n\")[0]\n",
    "    reason = output.split(\"[END]\")[1].split(\"\\n\\nReasoning:\\n\\n\")[1]\n",
    "    print(\"*\"*50+\"MQL\"+\"*\"*50)\n",
    "    print(mql)\n",
    "    print(\"\\n\"+\"*\"*50+\"Reason\"+\"*\"*50)\n",
    "    print(reason)\n",
    "    #return mql,reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0c79c552",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRIC_CONSTRAINT= \"\"\"\n",
    "\n",
    "**Task**: Extract \"COMPARISON OPERATOR,\" \"COMPARISON VALUE,\" and the Targeted ENTITY\n",
    "\n",
    "**Instructions**:\n",
    "\n",
    "1. Read the input question carefully.\n",
    "2. Determine if there is a comparison intent present, such as \"greater than,\" \"less than,\" or \"equals to.\" etc, If there is a comparison intent, please proceed to extract the relevant information.\n",
    "3. Extract the \"COMPARISON OPERATOR\" based on the detected intent. Examples of \"COMPARISON OPERATORS\" include \"greater than,\" \"less than,\" and \"equals to.\"\n",
    "4. Identify and extract the \"COMPARISON VALUE\" from the sentence. This should be a numerical or scalar value.\n",
    "5. Detect the ENTITY (e.g., \"Sales\") on which these comparisons are applied. Please extract the relevant entity.\n",
    "6. Provide the following information:\n",
    "   - COMPARISON OPERATOR: (If detected else None) \n",
    "   - COMPARISON VALUE: (If detected else None)\n",
    "   - ENTITY: (If detected else None)\n",
    "\n",
    "**Input Sentence**: \"When was the first time sales of segments was 0\"\n",
    "\n",
    "**Output**:\n",
    "- COMPARISON OPERATOR: (If detected else None)\n",
    "- COMPARISON VALUE: (If detected else None)\n",
    "- ENTITY: Sales (If detected else None)\n",
    "\n",
    "*Note*: If the input question does not contain any comparison intent or the entity, you can indicate that they were not detected.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ce69adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADJECTIVE_and_TONE = \"\"\"\n",
    "**Task**: Extract Adjectives, Determine Intent (TONE), Identify Entity, Return RANK ADJECTIVE, and Scalar (RANK)\n",
    "\n",
    "**Instructions**:\n",
    "\n",
    "1. Carefully read the user question to identify any adjectives present. Adjectives can include terms like \"least,\" \"highest performing,\" etc.\n",
    "2. Determine the intent (TONE) of the adjective. The intent can be either positive or negative.\n",
    "   - If the adjective intent is negative, always set RANK ADJECTIVE to \"BOTTOM\" and TONE to \"negative.\"\n",
    "   - If the adjective intent is positive, always  set RANK ADJECTIVE to \"TOP\" and TONE to \"positive.\"\n",
    "3. If the adjective implies a quantity (e.g., \"how many,\" \"top 3\"), extract that scalar value as RANK.\n",
    "4. Identify the entity (e.g., \"Segment\") on which the detected adjective should be applied.\n",
    "\n",
    "**Input Question**: \"How many top 3 segments are performing well?\"\n",
    "\n",
    "**Output**:\n",
    "- ADJECTIVE: top\n",
    "- TONE: positive\n",
    "- ENTITY: Segment\n",
    "- RANK ADJECTIVE: TOP\n",
    "- TONE: positive\n",
    "- RANK: 3\n",
    "\n",
    "**Note**: If the input question doesn't contain an adjective, doesn't imply a quantity, or if it's not clear which entity the adjective should be applied to, you can indicate that they were not detected.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4a040e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**Task**: Extract \"COMPARISON OPERATOR,\" \"COMPARISON VALUE,\" and the Targeted ENTITY\n",
      "\n",
      "**Instructions**:\n",
      "\n",
      "1. Read the input question carefully.\n",
      "2. Determine if there is a comparison intent present, such as \"greater than,\" \"less than,\" or \"equals to.\" etc, If there is a comparison intent, please proceed to extract the relevant information.\n",
      "3. Extract the \"COMPARISON OPERATOR\" based on the detected intent. Examples of \"COMPARISON OPERATORS\" include \"greater than,\" \"less than,\" and \"equals to.\"\n",
      "4. Identify and extract the \"COMPARISON VALUE\" from the sentence. This should be a numerical or scalar value.\n",
      "5. Detect the ENTITY (e.g., \"Sales\") on which these comparisons are applied. Please extract the relevant entity.\n",
      "6. Provide the following information:\n",
      "   - COMPARISON OPERATOR: (If detected else None) \n",
      "   - COMPARISON VALUE: (If detected else None)\n",
      "   - ENTITY: (If detected else None)\n",
      "\n",
      "**Input Sentence**: \"show me quantities > 100K\"\n",
      "\n",
      "**Output**:\n",
      "- COMPARISON OPERATOR: greater than\n",
      "- COMPARISON VALUE: 100K\n",
      "- ENTITY: quantities\n",
      "CPU times: user 26.8 s, sys: 765 ms, total: 27.5 s\n",
      "Wall time: 27.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "question = \"show me quantities > 100K\"\n",
    "output=gereneate_output_mistral(compose_prompt_open_ai_prompt(question,METRIC_CONSTRAINT))\n",
    "#post_process_open_ai_prompt_response(output)\n",
    "print(output.split(\"[_separator_]\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9b151726",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**Task**: Extract \"COMPARISON OPERATOR,\" \"COMPARISON VALUE,\" and the Targeted ENTITY\n",
      "\n",
      "**Instructions**:\n",
      "\n",
      "1. Read the input question carefully.\n",
      "2. Determine if there is a comparison intent present, such as \"greater than,\" \"less than,\" or \"equals to.\" etc, If there is a comparison intent, please proceed to extract the relevant information.\n",
      "3. Extract the \"COMPARISON OPERATORS\" based on the detected intent. Examples of \"COMPARISON OPERATORS\" include \"greater than,\" \"less than,\" and \"equals to.\"\n",
      "4. Identify and extract the \"COMPARISON VALUE\" from the sentence. This should be a numerical or scalar value.\n",
      "5. Detect the ENTITY (e.g., \"Sales\") on which these comparisons are applied. Please extract the relevant entity.\n",
      "6. Provide the following information:\n",
      "   - COMPARISON OPERATOR: (If detected else None) \n",
      "   - COMPARISON VALUE: (If detected else None)\n",
      "   - ENTITY: (If detected else None)\n",
      "\n",
      "**Input Sentence**: \"When is first time discount of phone is lesser than 0\"\n",
      "\n",
      "**Output**:\n",
      "- COMPARISON OPERATOR: less than\n",
      "- COMPARISON VALUE: 0\n",
      "- ENTITY: discount (phone)\n",
      "\n",
      "*Note*: If the input question does not contain any comparison intent or the entity, you can indicate that they were not detected.\n",
      "CPU times: user 29.4 s, sys: 708 ms, total: 30.1 s\n",
      "Wall time: 30.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "question = \"When is first time discount of phone is lesser than 0\"\n",
    "output=gereneate_output_mistral(compose_prompt_open_ai_prompt(question,METRIC_CONSTRAINT))\n",
    "#post_process_open_ai_prompt_response(output)\n",
    "print(output.split(\"[_separator_]\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74a3128b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**Task**: Extract Adjectives, Determine Intent (TONE), Identify Entity, Return RANK ADJECTIVE, and Scalar (RANK)\n",
      "\n",
      "**Instructions**:\n",
      "\n",
      "1. Carefully read the user question to identify any adjectives present. Adjectives can include terms like \"least,\" \"highest performing,\" etc.\n",
      "2. Determine the intent (TONE) of the adjective. The intent can be either positive or negative.\n",
      "   - If the adjective intent is negative, always set RANK ADJECTIVE to \"BOTTOM\" and TONE to \"negative.\"\n",
      "   - If the adjective intent is positive, always  set RANK ADJECTIVE to \"TOP\" and TONE to \"positive.\"\n",
      "3. If the adjective implies a quantity (e.g., \"how many,\" \"top 3\"), extract that scalar value as RANK.\n",
      "4. Identify the entity (e.g., \"Segment\") on which the detected adjective should be applied.\n",
      "\n",
      "**Input Question**: \"show me the 2 top segments basis sales\"\n",
      "\n",
      "**Output**:\n",
      "- ADJECTIVE: top\n",
      "- TONE: positive\n",
      "- ENTITY: Segment\n",
      "- RANK ADJECTIVE: TOP\n",
      "- TONE: positive\n",
      "- RANK: 2\n",
      "CPU times: user 24.9 s, sys: 744 ms, total: 25.6 s\n",
      "Wall time: 25.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "question = \"show me the 2 top segments basis sales\"\n",
    "output=gereneate_output_mistral(compose_prompt_open_ai_prompt(question,ADJECTIVE_and_TONE))\n",
    "#post_process_open_ai_prompt_response(output)\n",
    "print(output.split(\"[_separator_]\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a77f292",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "/opt/conda/lib/python3.8/site-packages/bitsandbytes/nn/modules.py:224: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_type=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(f'Input type into Linear4bit is torch.float16, but bnb_4bit_compute_type=torch.float32 (default). This will lead to slow inference or training speed.')\n",
      "/opt/conda/lib/python3.8/site-packages/transformers/generation/utils.py:2507: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /home/mosaic-ai/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1442.)\n",
      "  next_tokens.tile(eos_token_id_tensor.shape[0], 1).ne(eos_token_id_tensor.unsqueeze(1)).prod(dim=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**Task**: Extract Adjectives, Determine Intent (TONE), Identify Entity, Return RANK ADJECTIVE, and Scalar (RANK)\n",
      "\n",
      "**Instructions**:\n",
      "\n",
      "1. Carefully read the user question to identify any adjectives present. Adjectives can include terms like \"top,\" \"bottom,\" \"best,\" \"worst,\" etc.\n",
      "2. Determine the intent (TONE) of the adjective. The intent can be either positive or negative.\n",
      "   - If the adjective intent is negative, always set RANK ADJECTIVE to \"BOTTOM\" and TONE to \"negative.\"\n",
      "   - If the adjective intent is positive, always  set RANK ADJECTIVE to \"TOP\" and TONE to \"positive.\"\n",
      "3. If the adjective implies a quantity (e.g., \"how many,\" \"top 3\"), extract that scalar value as RANK.\n",
      "4. Identify the entity (e.g., \"Segment\") on which the detected adjective should be applied.\n",
      "\n",
      "**Input Question**: \"top 2 segments and bottom 3 sub-category basis quantity\"\n",
      "\n",
      "**Output**:\n",
      "- ADJECTIVE: top, bottom\n",
      "- TONE: mixed (positive and negative)\n",
      "- ENTITY: Segment, sub-category\n",
      "- RANK ADJECTIVE: TOP, BOTTOM\n",
      "- TONE: positive, negative\n",
      "- RANK: 2, 3\n",
      "\n",
      "            \n",
      "CPU times: user 14min 14s, sys: 47.1 s, total: 15min 1s\n",
      "Wall time: 15min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "question = \"top 2 segments and bottom 3 sub-category basis quantity\"\n",
    "output=gereneate_output_mistral(compose_prompt_open_ai_prompt(question,ADJECTIVE_and_TONE))\n",
    "#post_process_open_ai_prompt_response(output)\n",
    "print(output.split(\"[_separator_]\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693b1d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "question = \"sales from 2021 to 2023\"\n",
    "output=gereneate_output_mistral(compose_prompt_open_ai_prompt(question,ADJECTIVE_and_TONE))\n",
    "#post_process_open_ai_prompt_response(output)\n",
    "print(output.split(\"[_separator_]\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc236a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "question = \"show me the 2 top segments basis sales\"\n",
    "output=gereneate_output_mistral(compose_prompt_open_ai_prompt(question,ADJECTIVE_and_TONE))\n",
    "#post_process_open_ai_prompt_response(output)\n",
    "print(output.split(\"[_separator_]\")[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
