{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13adff45",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ref : https://github.com/philschmid/deep-learning-pytorch-huggingface/blob/main/training/optimize-llama-2-gptq.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "669fcd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo pip install -q transformers --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "add5cdb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting auto-gptq\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/ad/6811dc63a4b51ad23c6e5547f1622fe433c50d3ed6f254674f7fc51178d5/auto_gptq-0.6.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8MB)\n",
      "\u001b[K     |████████████████████████████████| 4.8MB 6.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting accelerate>=0.22.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/fc/c55e5a2da345c9a24aa2e1e0f60eb2ca290b6a41be82da03a6d4baec4f99/accelerate-0.25.0-py3-none-any.whl (265kB)\n",
      "\u001b[K     |████████████████████████████████| 266kB 116.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: datasets in /opt/conda/lib/python3.8/site-packages (from auto-gptq) (2.14.4)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from auto-gptq) (4.65.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from auto-gptq) (1.21.1)\n",
      "Collecting gekko\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/d1/cdb977d024b2d7212bea0d6aa939dfdd15c6fb22deacbfb07fd9d8a77734/gekko-1.0.6-py3-none-any.whl (12.2MB)\n",
      "\u001b[K     |████████████████████████████████| 12.2MB 52.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: peft>=0.5.0 in /opt/conda/lib/python3.8/site-packages (from auto-gptq) (0.6.0.dev0)\n",
      "Collecting rouge\n",
      "  Downloading https://files.pythonhosted.org/packages/32/7c/650ae86f92460e9e8ef969cc5008b24798dcf56a9a8947d04c78f550b3f5/rouge-1.0.1-py3-none-any.whl\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.8/site-packages (from auto-gptq) (0.3.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.8/site-packages (from auto-gptq) (2.0.1)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.8/site-packages (from auto-gptq) (0.1.99)\n",
      "Requirement already satisfied: transformers>=4.31.0 in /opt/conda/lib/python3.8/site-packages (from auto-gptq) (4.36.2)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.8/site-packages (from accelerate>=0.22.0->auto-gptq) (0.20.1)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.8/site-packages (from accelerate>=0.22.0->auto-gptq) (6.0.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.8/site-packages (from accelerate>=0.22.0->auto-gptq) (5.9.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from accelerate>=0.22.0->auto-gptq) (23.0)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.8/site-packages (from datasets->auto-gptq) (3.3.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.8/site-packages (from datasets->auto-gptq) (2.29.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.8/site-packages (from datasets->auto-gptq) (12.0.1)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.8/site-packages (from datasets->auto-gptq) (0.3.7)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.8/site-packages (from datasets->auto-gptq) (0.70.15)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.8/site-packages (from datasets->auto-gptq) (3.8.5)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.8/site-packages (from datasets->auto-gptq) (2023.6.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from datasets->auto-gptq) (2.0.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from rouge->auto-gptq) (1.16.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->auto-gptq) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->auto-gptq) (8.5.0.96)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->auto-gptq) (3.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->auto-gptq) (11.7.99)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->auto-gptq) (1.12)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->auto-gptq) (11.7.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->auto-gptq) (2.14.3)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->auto-gptq) (10.9.0.58)\n",
      "Requirement already satisfied: triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->auto-gptq) (2.0.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->auto-gptq) (4.1.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->auto-gptq) (11.7.101)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->auto-gptq) (10.2.10.91)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->auto-gptq) (3.1.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->auto-gptq) (3.12.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->auto-gptq) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->auto-gptq) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->auto-gptq) (11.7.4.91)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.8/site-packages (from transformers>=4.31.0->auto-gptq) (0.15.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers>=4.31.0->auto-gptq) (2023.8.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets->auto-gptq) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets->auto-gptq) (2023.5.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets->auto-gptq) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets->auto-gptq) (2.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets->auto-gptq) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets->auto-gptq) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets->auto-gptq) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets->auto-gptq) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets->auto-gptq) (6.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets->auto-gptq) (23.1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets->auto-gptq) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets->auto-gptq) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets->auto-gptq) (2.8.2)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch>=1.13.0->auto-gptq) (0.38.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch>=1.13.0->auto-gptq) (67.8.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.8/site-packages (from sympy->torch>=1.13.0->auto-gptq) (1.3.0)\n",
      "Requirement already satisfied: lit in /opt/conda/lib/python3.8/site-packages (from triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch>=1.13.0->auto-gptq) (16.0.6)\n",
      "Requirement already satisfied: cmake in /opt/conda/lib/python3.8/site-packages (from triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch>=1.13.0->auto-gptq) (3.27.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2->torch>=1.13.0->auto-gptq) (2.1.3)\n",
      "Installing collected packages: accelerate, gekko, rouge, auto-gptq\n",
      "  Found existing installation: accelerate 0.21.0\n",
      "    Uninstalling accelerate-0.21.0:\n",
      "      Successfully uninstalled accelerate-0.21.0\n",
      "Successfully installed accelerate-0.25.0 auto-gptq-0.6.0 gekko-1.0.6 rouge-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!sudo -H pip install auto-gptq --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0807a555",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optimum\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/03/df00e4553653ae038e8869e1bd6999398112be41f50b19acf999d7c706c0/optimum-1.16.1-py3-none-any.whl (403kB)\n",
      "\u001b[K     |████████████████████████████████| 409kB 7.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: coloredlogs in /opt/conda/lib/python3.8/site-packages (from optimum) (15.0.1)\n",
      "Requirement already satisfied, skipping upgrade: transformers[sentencepiece]>=4.26.0 in /opt/conda/lib/python3.8/site-packages (from optimum) (4.36.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /opt/conda/lib/python3.8/site-packages (from optimum) (1.21.1)\n",
      "Requirement already satisfied, skipping upgrade: torch>=1.9 in /opt/conda/lib/python3.8/site-packages (from optimum) (2.0.1)\n",
      "Requirement already satisfied, skipping upgrade: packaging in /opt/conda/lib/python3.8/site-packages (from optimum) (23.0)\n",
      "Requirement already satisfied, skipping upgrade: sympy in /opt/conda/lib/python3.8/site-packages (from optimum) (1.12)\n",
      "Requirement already satisfied, skipping upgrade: datasets in /opt/conda/lib/python3.8/site-packages (from optimum) (2.14.4)\n",
      "Requirement already satisfied, skipping upgrade: huggingface-hub>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from optimum) (0.20.1)\n",
      "Requirement already satisfied, skipping upgrade: humanfriendly>=9.1 in /opt/conda/lib/python3.8/site-packages (from coloredlogs->optimum) (10.0)\n",
      "Requirement already satisfied, skipping upgrade: filelock in /opt/conda/lib/python3.8/site-packages (from transformers[sentencepiece]>=4.26.0->optimum) (3.12.2)\n",
      "Requirement already satisfied, skipping upgrade: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers[sentencepiece]>=4.26.0->optimum) (4.65.0)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers[sentencepiece]>=4.26.0->optimum) (6.0.1)\n",
      "Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers[sentencepiece]>=4.26.0->optimum) (2023.8.8)\n",
      "Requirement already satisfied, skipping upgrade: safetensors>=0.3.1 in /opt/conda/lib/python3.8/site-packages (from transformers[sentencepiece]>=4.26.0->optimum) (0.3.2)\n",
      "Requirement already satisfied, skipping upgrade: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.8/site-packages (from transformers[sentencepiece]>=4.26.0->optimum) (0.15.0)\n",
      "Requirement already satisfied, skipping upgrade: requests in /opt/conda/lib/python3.8/site-packages (from transformers[sentencepiece]>=4.26.0->optimum) (2.29.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf; extra == \"sentencepiece\" in /opt/conda/lib/python3.8/site-packages (from transformers[sentencepiece]>=4.26.0->optimum) (4.24.0)\n",
      "Requirement already satisfied, skipping upgrade: sentencepiece!=0.1.92,>=0.1.91; extra == \"sentencepiece\" in /opt/conda/lib/python3.8/site-packages (from transformers[sentencepiece]>=4.26.0->optimum) (0.1.99)\n",
      "Requirement already satisfied, skipping upgrade: nvidia-cuda-runtime-cu11==11.7.99; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=1.9->optimum) (11.7.99)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch>=1.9->optimum) (4.1.1)\n",
      "Requirement already satisfied, skipping upgrade: triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=1.9->optimum) (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: networkx in /opt/conda/lib/python3.8/site-packages (from torch>=1.9->optimum) (3.1)\n",
      "Requirement already satisfied, skipping upgrade: nvidia-cufft-cu11==10.9.0.58; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=1.9->optimum) (10.9.0.58)\n",
      "Requirement already satisfied, skipping upgrade: nvidia-cusparse-cu11==11.7.4.91; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=1.9->optimum) (11.7.4.91)\n",
      "Requirement already satisfied, skipping upgrade: nvidia-cuda-nvrtc-cu11==11.7.99; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=1.9->optimum) (11.7.99)\n",
      "Requirement already satisfied, skipping upgrade: nvidia-cuda-cupti-cu11==11.7.101; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=1.9->optimum) (11.7.101)\n",
      "Requirement already satisfied, skipping upgrade: nvidia-nvtx-cu11==11.7.91; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=1.9->optimum) (11.7.91)\n",
      "Requirement already satisfied, skipping upgrade: jinja2 in /opt/conda/lib/python3.8/site-packages (from torch>=1.9->optimum) (3.1.2)\n",
      "Requirement already satisfied, skipping upgrade: nvidia-cublas-cu11==11.10.3.66; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=1.9->optimum) (11.10.3.66)\n",
      "Requirement already satisfied, skipping upgrade: nvidia-cusolver-cu11==11.4.0.1; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=1.9->optimum) (11.4.0.1)\n",
      "Requirement already satisfied, skipping upgrade: nvidia-cudnn-cu11==8.5.0.96; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=1.9->optimum) (8.5.0.96)\n",
      "Requirement already satisfied, skipping upgrade: nvidia-nccl-cu11==2.14.3; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=1.9->optimum) (2.14.3)\n",
      "Requirement already satisfied, skipping upgrade: nvidia-curand-cu11==10.2.10.91; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=1.9->optimum) (10.2.10.91)\n",
      "Requirement already satisfied, skipping upgrade: mpmath>=0.19 in /opt/conda/lib/python3.8/site-packages (from sympy->optimum) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.8/site-packages (from datasets->optimum) (0.3.7)\n",
      "Requirement already satisfied, skipping upgrade: pandas in /opt/conda/lib/python3.8/site-packages (from datasets->optimum) (2.0.2)\n",
      "Requirement already satisfied, skipping upgrade: pyarrow>=8.0.0 in /opt/conda/lib/python3.8/site-packages (from datasets->optimum) (12.0.1)\n",
      "Requirement already satisfied, skipping upgrade: multiprocess in /opt/conda/lib/python3.8/site-packages (from datasets->optimum) (0.70.15)\n",
      "Requirement already satisfied, skipping upgrade: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.8/site-packages (from datasets->optimum) (2023.6.0)\n",
      "Requirement already satisfied, skipping upgrade: aiohttp in /opt/conda/lib/python3.8/site-packages (from datasets->optimum) (3.8.5)\n",
      "Requirement already satisfied, skipping upgrade: xxhash in /opt/conda/lib/python3.8/site-packages (from datasets->optimum) (3.3.0)\n",
      "Requirement already satisfied, skipping upgrade: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers[sentencepiece]>=4.26.0->optimum) (3.4)\n",
      "Requirement already satisfied, skipping upgrade: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests->transformers[sentencepiece]>=4.26.0->optimum) (2.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers[sentencepiece]>=4.26.0->optimum) (1.26.15)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers[sentencepiece]>=4.26.0->optimum) (2023.5.7)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /opt/conda/lib/python3.8/site-packages (from nvidia-cuda-runtime-cu11==11.7.99; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch>=1.9->optimum) (67.8.0)\n",
      "Requirement already satisfied, skipping upgrade: wheel in /opt/conda/lib/python3.8/site-packages (from nvidia-cuda-runtime-cu11==11.7.99; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch>=1.9->optimum) (0.38.1)\n",
      "Requirement already satisfied, skipping upgrade: cmake in /opt/conda/lib/python3.8/site-packages (from triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch>=1.9->optimum) (3.27.1)\n",
      "Requirement already satisfied, skipping upgrade: lit in /opt/conda/lib/python3.8/site-packages (from triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch>=1.9->optimum) (16.0.6)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2->torch>=1.9->optimum) (2.1.3)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.8.2 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets->optimum) (2.8.2)\n",
      "Requirement already satisfied, skipping upgrade: tzdata>=2022.1 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets->optimum) (2023.3)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets->optimum) (2023.3)\n",
      "Requirement already satisfied, skipping upgrade: frozenlist>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets->optimum) (1.4.0)\n",
      "Requirement already satisfied, skipping upgrade: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets->optimum) (4.0.2)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets->optimum) (23.1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied, skipping upgrade: aiosignal>=1.1.2 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets->optimum) (1.3.1)\n",
      "Requirement already satisfied, skipping upgrade: yarl<2.0,>=1.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets->optimum) (1.9.2)\n",
      "Requirement already satisfied, skipping upgrade: multidict<7.0,>=4.5 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets->optimum) (6.0.4)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas->datasets->optimum) (1.16.0)\n",
      "Installing collected packages: optimum\n",
      "Successfully installed optimum-1.16.1\n"
     ]
    }
   ],
   "source": [
    "!sudo -H pip install --upgrade optimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a70204a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/pip_packages/transformers/utils/hub.py:123: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from optimum.gptq import GPTQQuantizer, load_quantized_model\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "991f18c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mistralai/Mistral-7B-v0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f22c8368",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15ae68bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3df845625382427f9eccb8cebec29e59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d0c9548a2d74a6394e60538858a6434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacty of 15.60 GiB of which 13.00 MiB is free. Process 2680851 has 7.00 GiB memory in use. Process 3703291 has 8.58 GiB memory in use. Of the allocated memory 7.95 GiB is allocated by PyTorch, and 137.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat16\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/tmp/pip_packages/transformers/models/auto/auto_factory.py:566\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    565\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 566\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    572\u001b[0m )\n",
      "File \u001b[0;32m/tmp/pip_packages/transformers/modeling_utils.py:3773\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3771\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_keys\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(dispatch_model)\u001b[38;5;241m.\u001b[39mparameters:\n\u001b[1;32m   3772\u001b[0m         device_map_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_keys\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39m_skip_keys_device_placement\n\u001b[0;32m-> 3773\u001b[0m     \u001b[43mdispatch_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdevice_map_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3775\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m quantization_method_from_args \u001b[38;5;241m==\u001b[39m QuantizationMethod\u001b[38;5;241m.\u001b[39mGPTQ:\n\u001b[1;32m   3776\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m quantization_config\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/tmp/pip_packages/accelerate/big_modeling.py:396\u001b[0m, in \u001b[0;36mdispatch_model\u001b[0;34m(model, device_map, main_device, state_dict, offload_dir, offload_index, offload_buffers, skip_keys, preload_module_classes, force_hooks)\u001b[0m\n\u001b[1;32m    393\u001b[0m     weights_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    395\u001b[0m tied_params \u001b[38;5;241m=\u001b[39m find_tied_parameters(model)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mattach_align_device_hook_on_blocks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecution_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecution_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m    \u001b[49m\u001b[43moffload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m    \u001b[49m\u001b[43moffload_buffers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_buffers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_module_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_module_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;66;03m# warn if there is any params on the meta device\u001b[39;00m\n\u001b[1;32m    407\u001b[0m offloaded_devices_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m    408\u001b[0m     [device \u001b[38;5;28;01mfor\u001b[39;00m device \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mset\u001b[39m(device_map\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisk\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m    409\u001b[0m )\n",
      "File \u001b[0;32m/tmp/pip_packages/accelerate/hooks.py:547\u001b[0m, in \u001b[0;36mattach_align_device_hook_on_blocks\u001b[0;34m(module, execution_device, offload, weights_map, offload_buffers, module_name, skip_keys, preload_module_classes)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m child_name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39mnamed_children():\n\u001b[1;32m    546\u001b[0m     child_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchild_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(module_name) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m child_name\n\u001b[0;32m--> 547\u001b[0m     \u001b[43mattach_align_device_hook_on_blocks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecution_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecution_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_buffers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_buffers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchild_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_module_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_module_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskip_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/tmp/pip_packages/accelerate/hooks.py:547\u001b[0m, in \u001b[0;36mattach_align_device_hook_on_blocks\u001b[0;34m(module, execution_device, offload, weights_map, offload_buffers, module_name, skip_keys, preload_module_classes)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m child_name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39mnamed_children():\n\u001b[1;32m    546\u001b[0m     child_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchild_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(module_name) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m child_name\n\u001b[0;32m--> 547\u001b[0m     \u001b[43mattach_align_device_hook_on_blocks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecution_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecution_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_buffers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_buffers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchild_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_module_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_module_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskip_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/tmp/pip_packages/accelerate/hooks.py:547\u001b[0m, in \u001b[0;36mattach_align_device_hook_on_blocks\u001b[0;34m(module, execution_device, offload, weights_map, offload_buffers, module_name, skip_keys, preload_module_classes)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m child_name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39mnamed_children():\n\u001b[1;32m    546\u001b[0m     child_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchild_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(module_name) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m child_name\n\u001b[0;32m--> 547\u001b[0m     \u001b[43mattach_align_device_hook_on_blocks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecution_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecution_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_buffers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_buffers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchild_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_module_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_module_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskip_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/tmp/pip_packages/accelerate/hooks.py:517\u001b[0m, in \u001b[0;36mattach_align_device_hook_on_blocks\u001b[0;34m(module, execution_device, offload, weights_map, offload_buffers, module_name, skip_keys, preload_module_classes)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m module_name \u001b[38;5;129;01min\u001b[39;00m execution_device \u001b[38;5;129;01mand\u001b[39;00m module_name \u001b[38;5;129;01min\u001b[39;00m offload \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m offload[module_name]:\n\u001b[1;32m    510\u001b[0m     hook \u001b[38;5;241m=\u001b[39m AlignDevicesHook(\n\u001b[1;32m    511\u001b[0m         execution_device\u001b[38;5;241m=\u001b[39mexecution_device[module_name],\n\u001b[1;32m    512\u001b[0m         offload_buffers\u001b[38;5;241m=\u001b[39moffload_buffers,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    515\u001b[0m         skip_keys\u001b[38;5;241m=\u001b[39mskip_keys,\n\u001b[1;32m    516\u001b[0m     )\n\u001b[0;32m--> 517\u001b[0m     \u001b[43madd_hook_to_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m     attach_execution_device_hook(module, execution_device[module_name])\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m module_name \u001b[38;5;129;01min\u001b[39;00m execution_device \u001b[38;5;129;01mand\u001b[39;00m module_name \u001b[38;5;129;01min\u001b[39;00m offload:\n",
      "File \u001b[0;32m/tmp/pip_packages/accelerate/hooks.py:156\u001b[0m, in \u001b[0;36madd_hook_to_module\u001b[0;34m(module, hook, append)\u001b[0m\n\u001b[1;32m    153\u001b[0m     old_forward \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39mforward\n\u001b[1;32m    154\u001b[0m     module\u001b[38;5;241m.\u001b[39m_old_forward \u001b[38;5;241m=\u001b[39m old_forward\n\u001b[0;32m--> 156\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[43mhook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m module\u001b[38;5;241m.\u001b[39m_hf_hook \u001b[38;5;241m=\u001b[39m hook\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_forward\u001b[39m(module, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n",
      "File \u001b[0;32m/tmp/pip_packages/accelerate/hooks.py:254\u001b[0m, in \u001b[0;36mAlignDevicesHook.init_hook\u001b[0;34m(self, module)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moffload \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, _ \u001b[38;5;129;01min\u001b[39;00m named_module_tensors(module, recurse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplace_submodules):\n\u001b[0;32m--> 254\u001b[0m         \u001b[43mset_module_tensor_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_device\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moffload:\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moriginal_devices \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    257\u001b[0m         name: param\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m named_module_tensors(module, recurse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplace_submodules)\n\u001b[1;32m    258\u001b[0m     }\n",
      "File \u001b[0;32m/tmp/pip_packages/accelerate/utils/modeling.py:311\u001b[0m, in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, dtype, fp16_statistics)\u001b[0m\n\u001b[1;32m    309\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 311\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m \u001b[43mold_value\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m device \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta\u001b[39m\u001b[38;5;124m\"\u001b[39m)]:\n\u001b[1;32m    313\u001b[0m         new_value \u001b[38;5;241m=\u001b[39m new_value\u001b[38;5;241m.\u001b[39mto(dtype)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacty of 15.60 GiB of which 13.00 MiB is free. Process 2680851 has 7.00 GiB memory in use. Process 3703291 has 8.58 GiB memory in use. Of the allocated memory 7.95 GiB is allocated by PyTorch, and 137.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16,device_map='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fae541b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantizer = GPTQQuantizer(bits=4, dataset=\"wikitext2\")\n",
    "quantizer.quant_method = \"gptq\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9195933b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cee3e458900f413cab5e6a99c82a7b58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/8.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e8a925d98584173ade27ecbe39f5e27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/6.84k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00a327c83a6442aa86faff2c70530fa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/9.62k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9321c8f487d8488d98924d82a319d1b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/4.72M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e5c485481a2461ebf43159f0df47bf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/4358 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aba9eee2771941af953b86b72c5d1a1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/36718 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3395ebc15e2410a961540dd3b0089f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/3760 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "quantized_model = quantizer.quantize_model(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e07f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_path = \"/data/quantization-trials/GPTQ-quantized/ravi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "890c000c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the quantize model to disk\n",
    "\n",
    "quantized_model.save_pretrained(quant_path, safe_serialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d1c26e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed91b14b",
   "metadata": {},
   "source": [
    "### Inference on quantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f83ca527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GPTQConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bddca22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `disable_exllama` is deprecated and will be removed in version 4.37. Use `use_exllama` instead and specify the version with `exllama_config`.The value of `use_exllama` will be overwritten by `disable_exllama` passed in `GPTQConfig` or stored in your config file.\n"
     ]
    }
   ],
   "source": [
    "gptq_config = GPTQConfig(bits=4, use_exllama=True)\n",
    "\n",
    "model_id = \"/data/quantization-trials/GPTQ-quantized\"\n",
    "quant_model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"cuda\", torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99bf71c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_quant(user_query):\n",
    "    _inputs = tokenizer.encode(user_query, return_tensors=\"pt\").to('cuda')\n",
    "    outputs = quant_model.generate(input_ids=_inputs, max_length= 1000, pad_token_id=tokenizer.eos_token_id)\n",
    "    output = tokenizer.decode(outputs[0])\n",
    "    return output\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bec86999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken is : 133.77150201797485\n"
     ]
    }
   ],
   "source": [
    "# Using quant model\n",
    "start = time.time()\n",
    "output1 = predict_from_quant(\"what is science\")\n",
    "print(\"time taken is :\", time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1656bd41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</s>what is science?\n",
      "\n",
      "Science is the study of the world around us. It is the study of the physical, chemical, and biological world around us. It is the study of the world around us.\n",
      "\n",
      "What is the world around us?\n",
      "\n",
      "The world around us is made up of the physical, chemical, and biological world around us. The world around us is made up of the physical, chemical, and biological world around us.\n",
      "\n",
      "What is the world around us made of?\n",
      "\n",
      "The world around us is made up of the physical, chemical, and biological world around us. The world around us is made up of the physical, chemical, and biological world around us.\n",
      "\n",
      "What is the world around us made of?\n",
      "\n",
      "The world around us is made up of the physical, chemical, and biological world around us. The world around us is made up of the physical, chemical, and biological world around us.\n",
      "\n",
      "What is the world around us made of?\n",
      "\n",
      "The world around us is made up of the physical, chemical, and biological world around us. The world around us is made up of the physical, chemical, and biological world around us.\n",
      "\n",
      "What is the world around us made of?\n",
      "\n",
      "The world around us is made up of the physical, chemical, and biological world around us. The world around us is made up of the physical, chemical, and biological world around us.\n",
      "\n",
      "What is the world around us made of?\n",
      "\n",
      "The world around us is made up of the physical, chemical, and biological world around us. The world around us is made up of the physical, chemical, and biological world around us.\n",
      "\n",
      "What is the world around us made of?\n",
      "\n",
      "The world around us is made up of the physical, chemical, and biological world around us. The world around us is made up of the physical, chemical, and biological world around us.\n",
      "\n",
      "What is the world around us made of?\n",
      "\n",
      "The world around us is made up of the physical, chemical, and biological world around us. The world around us is made up of the physical, chemical, and biological world around us.\n",
      "\n",
      "What is the world around us made of?\n",
      "\n",
      "The world around us is made up of the physical, chemical, and biological world around us. The world around us is made up of the physical, chemical, and biological world around us.\n",
      "\n",
      "What is the world around us made of?\n",
      "\n",
      "The world around us is made up of the physical, chemical, and biological world around us. The world around us is made up of the physical, chemical, and biological world around us.\n",
      "\n",
      "What is the world around us made of?\n",
      "\n",
      "The world around us is made up of the physical, chemical, and biological world around us. The world around us is made up of the physical, chemical, and biological world around us.\n",
      "\n",
      "What is the world around us made of?\n",
      "\n",
      "The world around us is made up of the physical, chemical, and biological world around us. The world around us is made up of the physical, chemical, and biological world around us.\n",
      "\n",
      "What is the world around us made of?\n",
      "\n",
      "The world around us is made up of the physical, chemical, and biological world around us. The world around us is made up of the physical, chemical, and biological world around us.\n",
      "\n",
      "What is the world around us made of?\n",
      "\n",
      "The world around us is made up of the physical, chemical, and biological world around us. The world around us is made up of the physical, chemical, and biological world around us.\n",
      "\n",
      "What is the world around us made of?\n",
      "\n",
      "The world around us is made up of the physical, chemical, and biological world around us. The world around us is made up of the physical, chemical, and biological world around us.\n",
      "\n",
      "What is the world around us made of?\n",
      "\n",
      "The world around us is made up of the physical, chemical, and biological world around us. The world around us is made up of the physical, chemical, and biological world around us.\n",
      "\n",
      "What is the world around us made of?\n",
      "\n",
      "The world around us is made up of the physical, chemical, and biological world around us. The world around us is made up of the physical, chemical, and biological world around us.\n",
      "\n",
      "What is the world around us made of?\n",
      "\n",
      "The world around us is made up of the physical, chemical, and biological world around us. The world around us is made up of the physical, chemical, and biological world around us.\n",
      "\n",
      "What is the world around us made of?\n",
      "\n",
      "The world around us is made up of the physical, chemical, and biological world around us. The world around us is made up of the\n"
     ]
    }
   ],
   "source": [
    "print(output1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84539d4",
   "metadata": {},
   "source": [
    "### Inference on un-quantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bd366b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"/data/quantization-trials/merged-model\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"cuda\", torch_dtype=torch.float16)\n",
    "\n",
    "def predict_from_normal(user_query):\n",
    "    _inputs = tokenizer.encode(user_query, return_tensors=\"pt\").to('cuda')\n",
    "    outputs = model.generate(input_ids=_inputs, max_length= 1000, pad_token_id=tokenizer.eos_token_id)\n",
    "    output = tokenizer.decode(outputs[0])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6eb090b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "586d4b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken is : 23.793633222579956\n"
     ]
    }
   ],
   "source": [
    "# Using unquant model\n",
    "start = time.time()\n",
    "output2 = predict_from_normal(\"what is science\")\n",
    "print(\"time taken is :\", time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efb75d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</s>what is science?\n",
      "\n",
      "The word \"science\" is used to describe a variety of fields of study, including:\n",
      "\n",
      "biology\n",
      "\n",
      "chemistry\n",
      "\n",
      "biology of the brain\n",
      "\n",
      "biology of the immune system\n",
      "\n",
      "biology of the nervous system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the immune system\n",
      "\n",
      "biology of the nervous system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the immune system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the nervous system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the immune system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology\n"
     ]
    }
   ],
   "source": [
    "print(output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c5dd80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f572c6b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8158b28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
