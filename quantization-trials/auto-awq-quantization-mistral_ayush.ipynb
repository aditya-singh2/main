{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6091516f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install -U datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc95442a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !sudo -H pip install -q transformers --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc01db12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall autoawq -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc12a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install autoawq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7c4a3ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !sudo -H pip install https://github.com/casper-hansen/AutoAWQ/releases/download/v0.1.7/autoawq-0.1.7+cu118-cp38-cp38-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "779984ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install transformers==4.35.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f29fd336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\"\n",
    "from awq import AutoAWQForCausalLM\n",
    "from transformers import AutoTokenizer,AutoModelForCausalLM\n",
    "import torch\n",
    "quant_path = '/llmmodels/quantized_model/awq_mistral'\n",
    "model_path='mistralai/Mistral-7B-v0.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f89d01c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_config = {\"zero_point\":True,\n",
    "               \"q_group_size\": 128,\n",
    "               \"w_bit\": 4,\n",
    "               \"version\": \"GEMM\"\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f853010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0cca17da3c34fb38c633751336968bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 11 files:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd7da91af68417e95b99f533793dd5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load model\n",
    "# model = AutoAWQForCausalLM.from_pretrained(model_path, **{\"low_cpu_mem_usage\":True})\n",
    "model = AutoAWQForCausalLM.from_pretrained(model_path, device_map='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e50621ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21ffa0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8fa7742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636aa93d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# torch.cuda.memory_summary(device=None, abbreviated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48e2dc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/pip_packages/huggingface_hub/repocard.py:105: UserWarning: Repo card metadata block was not found. Setting CardData to empty.\n",
      "  warnings.warn(\"Repo card metadata block was not found. Setting CardData to empty.\")\n",
      "AWQ: 100%|██████████| 32/32 [41:02<00:00, 76.96s/it]\n"
     ]
    }
   ],
   "source": [
    "#Quantize\n",
    "# dont run it again\n",
    "model.quantize(tokenizer, quant_config=quant_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21de8591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_quantized = AutoModelForCausalLM.from_pretrained(\n",
    "#     model,\n",
    "#     torch_dtype=torch.float16,\n",
    "#     device_map=\"auto\",\n",
    "#     quantization_config=quant_config\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb126257",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:`quant_config.json` is being deprecated in the future in favor of quantization_config in config.json.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/llmmodels/quantized_model/awq_mistral/tokenizer_config.json',\n",
       " '/llmmodels/quantized_model/awq_mistral/special_tokens_map.json',\n",
       " '/llmmodels/quantized_model/awq_mistral/tokenizer.model',\n",
       " '/llmmodels/quantized_model/awq_mistral/added_tokens.json',\n",
       " '/llmmodels/quantized_model/awq_mistral/tokenizer.json')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_quantized(quant_path)\n",
    "tokenizer.save_pretrained(quant_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac71427",
   "metadata": {},
   "source": [
    "### Inference on quantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2fc875c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "quant_path = '/llmmodels/quantized_model/awq_mistral'\n",
    "model_path='mistralai/Mistral-7B-v0.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ed7b2db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_id = quant_path\n",
    "pipe = pipeline(\"text-generation\", model=model_id, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ace8938",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken is : 21.161255836486816\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "output2 = pipe(\"\",\n",
    "               max_new_tokens=500,\n",
    "               num_return_sequences=1,\n",
    "               do_sample=True,\n",
    "               top_k=50,\n",
    "               top_p=0.95)[0][\"generated_text\"]\n",
    "print(\"time taken is :\", time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "484f1d27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I dont know my name.\" It was like... \"Hey, I'm sorry man, but I've gotta go do a thing now. Maybe I'll see you at the show.\"\n",
      "\n",
      "Congrats to all of the WILDERUN staff who made it to our second gig ever and I hope that you'll be a part of the next, whenever that is.\n",
      "\n",
      "*  *  *  *  *\n",
      "\n",
      "Anyway, our opening act was this little band called HUNTRESS, whom you may have heard of. We weren't necessarily too familiar with them before we met them, but it turns out that I'd heard their cover of MORBID ANGEL'S \"Rapture\" on one of the many metal podcasts that I listen to and absolutely loved it. The guitar solo is phenomenal, and I can never quite decide if it's better than the original or not. If you haven't heard it, I highly recommend that you check it out, if only to hear some of the best growls in heavy metal. It's certainly up there with HATEBREED's cover of CRUNCHY BREAKDOWN.\n",
      "\n",
      "So, I go backstage to say hello, and I'm greeted by Jill Janus. She's not tall, so maybe she's shorter than me, but she's definitely not short. She's got big hair, a big personality, and big tits. I'm thinking, \"Wow, this lady's really quite stacked for her size.\" Then, I look to her left and see a much taller woman with much bigger hair who is clearly a badass. That's when I realize that she's Jill. Jill is kind of famous for having big tits, even when she's wearing a band shirt that isn't cut the right way.\n",
      "\n",
      "Jill's a really great person. She's so nice, and so funny, and has so much talent, and just kind of comes off like a person who you instantly take a liking to. I'm not sure what it is about people like that, but she's got a great personality. It's almost like she could do no wrong, and I can see why. She made a joke about a girl throwing her panties on stage earlier in their set\n"
     ]
    }
   ],
   "source": [
    "print(output2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3fee82",
   "metadata": {},
   "source": [
    "### Inference on un-quantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdf676e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "# do_sample=True,\n",
    "# top_k=50,\n",
    "# top_p=0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4a6c0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be055b0910884674829969a9fa4b37f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = model_path\n",
    "pipe = pipeline(\"text-generation\", model=model_id, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "010b00db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken is : 50.3744170665741\n"
     ]
    }
   ],
   "source": [
    "# Using unquant model\n",
    "import time\n",
    "start = time.time()\n",
    "output1 = pipe(\"what is art\",\n",
    "               max_new_tokens=500,\n",
    "               num_return_sequences=1)[0][\"generated_text\"]\n",
    "print(\"time taken is :\", time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b5b6f9c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is art?\n",
      "\n",
      "Art is a form of expression. It is a way to communicate ideas, emotions, and experiences through various mediums such as painting, sculpture, music, dance, and literature. Art can be created for a variety of reasons, including personal expression, social commentary, or simply for aesthetic pleasure.\n",
      "\n",
      "## What is the purpose of art?\n",
      "\n",
      "The purpose of art is to express the artist’s emotions, ideas, and experiences. It can also be used to communicate with others, to tell a story, or to simply make something beautiful. Art can be a form of self-expression, a way to connect with others, or a way to explore the world around us.\n",
      "\n",
      "## What is the importance of art?\n",
      "\n",
      "Art is important because it allows us to express ourselves in ways that words cannot. It can be a form of self-expression, a way to communicate with others, or a way to explore the world around us. Art can also be a form of therapy, helping us to process our emotions and experiences.\n",
      "\n",
      "## What is the role of art in society?\n",
      "\n",
      "Art plays an important role in society by providing a way for people to express themselves and communicate with others. It can also be used to educate, inspire, and entertain. Art can help us to understand different cultures and perspectives, and it can be a way to bring people together.\n",
      "\n",
      "## What is the role of art in education?\n",
      "\n",
      "Art plays an important role in education by providing a way for students to express themselves and communicate their ideas. It can also be used to teach students about different cultures and perspectives, and to help them develop critical thinking and problem-solving skills.\n",
      "\n",
      "## What is the role of art in the economy?\n",
      "\n",
      "Art plays an important role in the economy by providing jobs for artists and supporting the creative industries. It can also be a source of revenue for businesses and organizations, and it can help to attract tourists and visitors to a region.\n",
      "\n",
      "## What is the role of art in the environment?\n",
      "\n",
      "Art can play an important role in the environment by raising awareness about environmental issues and promoting sustainable practices. It can also be used to inspire people to take action and make a difference.\n",
      "\n",
      "## What is the role of art in politics?\n",
      "\n",
      "Art can play an important role in politics by providing a way for people to express their opinions and ideas. It can\n"
     ]
    }
   ],
   "source": [
    "print(output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f139bb23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output1 == output2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
