{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6091516f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install -U datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc95442a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !sudo -H pip install -q transformers --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc01db12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall autoawq -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bc12a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install autoawq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7c4a3ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !sudo -H pip install https://github.com/casper-hansen/AutoAWQ/releases/download/v0.1.7/autoawq-0.1.7+cu118-cp38-cp38-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "779984ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers==4.35.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f29fd336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:512\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "603676d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from awq import AutoAWQForCausalLM\n",
    "from transformers import AutoTokenizer,AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffccfab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1+cu117'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1aee117f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_path = '/data/mistral/query-to-mql/exp-10/nov-20/merged-model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08c42249",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_path = '/llmmodels/quantized_model/mistral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca1e26cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39e46e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path='/data/huggingface/cache/models--mistralai--Mistral-7B-v0.1/snapshots/5e9c98b96d071dce59368012254c55b0ec6f8658'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f89d01c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_config = {\"zero_point\":True,\n",
    "               \"q_group_size\": 128,\n",
    "               \"w_bit\": 4,\n",
    "               \"version\": \"GEMM\"\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f853010",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Can't load the configuration of '/data/huggingface/cache/models--mistralai--Mistral-7B-v0.1/snapshots/5e9c98b96d071dce59368012254c55b0ec6f8658'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/data/huggingface/cache/models--mistralai--Mistral-7B-v0.1/snapshots/5e9c98b96d071dce59368012254c55b0ec6f8658' is the correct path to a directory containing a config.json file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/tmp/pip_packages/transformers/configuration_utils.py:677\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfiguration_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    691\u001b[0m     commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n",
      "File \u001b[0;32m/tmp/pip_packages/transformers/utils/hub.py:430\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/tmp/pip_packages/huggingface_hub/utils/_validators.py:110\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 110\u001b[0m     \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/tmp/pip_packages/huggingface_hub/utils/_validators.py:158\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m repo_id\u001b[38;5;241m.\u001b[39mcount(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must be in the form \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrepo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnamespace/repo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Use `repo_type` argument if needed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX\u001b[38;5;241m.\u001b[39mmatch(repo_id):\n",
      "\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/data/huggingface/cache/models--mistralai--Mistral-7B-v0.1/snapshots/5e9c98b96d071dce59368012254c55b0ec6f8658'. Use `repo_type` argument if needed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#load model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# model = AutoAWQForCausalLM.from_pretrained(model_path, **{\"low_cpu_mem_usage\":True})\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoAWQForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/awq/models/auto.py:37\u001b[0m, in \u001b[0;36mAutoAWQForCausalLM.from_pretrained\u001b[0;34m(self, model_path, trust_remote_code, safetensors, device_map, **model_init_kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_pretrained\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_path, trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, safetensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     36\u001b[0m                           device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_init_kwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseAWQForCausalLM:\n\u001b[0;32m---> 37\u001b[0m     model_type \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_and_get_model_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m AWQ_CAUSAL_LM_MODEL_MAP[model_type]\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m     40\u001b[0m         model_path, model_type, trust_remote_code\u001b[38;5;241m=\u001b[39mtrust_remote_code, safetensors\u001b[38;5;241m=\u001b[39msafetensors,\n\u001b[1;32m     41\u001b[0m         device_map\u001b[38;5;241m=\u001b[39mdevice_map, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_init_kwargs\n\u001b[1;32m     42\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/awq/models/auto.py:23\u001b[0m, in \u001b[0;36mcheck_and_get_model_type\u001b[0;34m(model_dir, trust_remote_code)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_and_get_model_type\u001b[39m(model_dir, trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 23\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[43mAutoConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mmodel_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m AWQ_CAUSAL_LM_MODEL_MAP\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported yet.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/tmp/pip_packages/transformers/models/auto/configuration_auto.py:1048\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1045\u001b[0m trust_remote_code \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrust_remote_code\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1046\u001b[0m code_revision \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_revision\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1048\u001b[0m config_dict, unused_kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mPretrainedConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1049\u001b[0m has_remote_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1050\u001b[0m has_local_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m CONFIG_MAPPING\n",
      "File \u001b[0;32m/tmp/pip_packages/transformers/configuration_utils.py:622\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    620\u001b[0m original_kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[1;32m    621\u001b[0m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[0;32m--> 622\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict:\n\u001b[1;32m    624\u001b[0m     original_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/tmp/pip_packages/transformers/configuration_utils.py:698\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    696\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    697\u001b[0m         \u001b[38;5;66;03m# For any other exception, we throw a generic error.\u001b[39;00m\n\u001b[0;32m--> 698\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    699\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt load the configuration of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. If you were trying to load it\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    700\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m from \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, make sure you don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt have a local directory with the same\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    701\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name. Otherwise, make sure \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is the correct path to a directory\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    702\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m containing a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfiguration_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m file\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    703\u001b[0m         )\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;66;03m# Load config dict\u001b[39;00m\n\u001b[1;32m    707\u001b[0m     config_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_dict_from_json_file(resolved_config_file)\n",
      "\u001b[0;31mOSError\u001b[0m: Can't load the configuration of '/data/huggingface/cache/models--mistralai--Mistral-7B-v0.1/snapshots/5e9c98b96d071dce59368012254c55b0ec6f8658'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/data/huggingface/cache/models--mistralai--Mistral-7B-v0.1/snapshots/5e9c98b96d071dce59368012254c55b0ec6f8658' is the correct path to a directory containing a config.json file"
     ]
    }
   ],
   "source": [
    "#load model\n",
    "# model = AutoAWQForCausalLM.from_pretrained(model_path, **{\"low_cpu_mem_usage\":True})\n",
    "model = AutoAWQForCausalLM.from_pretrained(model_path, device_map='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e50621ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21ffa0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8fa7742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "636aa93d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 1            |        cudaMalloc retries: 4         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |   6216 MiB |  13428 MiB |  74259 MiB |  68043 MiB |\\n|       from large pool |   6184 MiB |  13396 MiB |  74165 MiB |  67981 MiB |\\n|       from small pool |     32 MiB |     34 MiB |     94 MiB |     62 MiB |\\n|---------------------------------------------------------------------------|\\n| Active memory         |   6216 MiB |  13428 MiB |  74259 MiB |  68043 MiB |\\n|       from large pool |   6184 MiB |  13396 MiB |  74165 MiB |  67981 MiB |\\n|       from small pool |     32 MiB |     34 MiB |     94 MiB |     62 MiB |\\n|---------------------------------------------------------------------------|\\n| Requested memory      |   6216 MiB |  13428 MiB |  74259 MiB |  68043 MiB |\\n|       from large pool |   6184 MiB |  13396 MiB |  74165 MiB |  67981 MiB |\\n|       from small pool |     32 MiB |     34 MiB |     94 MiB |     62 MiB |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |  13230 MiB |  15116 MiB |  28032 MiB |  14802 MiB |\\n|       from large pool |  13196 MiB |  15080 MiB |  27988 MiB |  14792 MiB |\\n|       from small pool |     34 MiB |     36 MiB |     44 MiB |     10 MiB |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory | 427640 KiB |   2237 MiB |  28587 MiB |  28169 MiB |\\n|       from large pool | 425856 KiB |   2235 MiB |  28504 MiB |  28089 MiB |\\n|       from small pool |   1784 KiB |      3 MiB |     82 MiB |     80 MiB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |     193    |     216    |    1075    |     882    |\\n|       from large pool |     113    |     128    |     490    |     377    |\\n|       from small pool |      80    |      94    |     585    |     505    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |     193    |     216    |    1075    |     882    |\\n|       from large pool |     113    |     128    |     490    |     377    |\\n|       from small pool |      80    |      94    |     585    |     505    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |     134    |     148    |     174    |      40    |\\n|       from large pool |     117    |     130    |     152    |      35    |\\n|       from small pool |      17    |      18    |      22    |       5    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |       5    |      10    |     296    |     291    |\\n|       from large pool |       2    |       6    |     119    |     117    |\\n|       from small pool |       3    |       6    |     177    |     174    |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_summary(device=None, abbreviated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48e2dc62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e53524e4e3f4428d89d42faff8db17ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/167 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/pip_packages/huggingface_hub/repocard.py:105: UserWarning: Repo card metadata block was not found. Setting CardData to empty.\n",
      "  warnings.warn(\"Repo card metadata block was not found. Setting CardData to empty.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25ee0c6d7c874039a418bbf9a770a63b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/471M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23d354d5ef89471db016790374d0372e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (8322 > 4096). Running this sequence through the model will result in indexing errors\n",
      "AWQ: 100%|██████████| 32/32 [37:08<00:00, 69.63s/it]\n"
     ]
    }
   ],
   "source": [
    "#Quantize\n",
    "# dont run it again\n",
    "model.quantize(tokenizer, quant_config=quant_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21de8591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_quantized = AutoModelForCausalLM.from_pretrained(\n",
    "#     model,\n",
    "#     torch_dtype=torch.float16,\n",
    "#     device_map=\"auto\",\n",
    "#     quantization_config=quant_config\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb126257",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/pip_packages/transformers/generation/configuration_utils.py:527: UserWarning: The generation config instance is invalid -- `.validate()` throws warnings and/or exceptions. Fix these issues to save the configuration. This warning will be raised to an exception in v4.34.\n",
      "\n",
      "Thrown during validation:\n",
      "`do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "WARNING:root:`quant_config.json` is being deprecated in the future in favor of quantization_config in config.json.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/llmmodels/quantized_model/awq/tokenizer_config.json',\n",
       " '/llmmodels/quantized_model/awq/special_tokens_map.json',\n",
       " '/llmmodels/quantized_model/awq/tokenizer.model',\n",
       " '/llmmodels/quantized_model/awq/added_tokens.json',\n",
       " '/llmmodels/quantized_model/awq/tokenizer.json')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_quantized(quant_path)\n",
    "tokenizer.save_pretrained(quant_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac71427",
   "metadata": {},
   "source": [
    "### Inference on quantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2fc875c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "quant_path = '/data/quantization-trials/quant-model'\n",
    "model_path = '/data/quantization-trials/merged-model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ed7b2db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_id = quant_path\n",
    "quant_model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "\n",
    "def predict_from_quant(user_query):\n",
    "    _inputs = tokenizer.encode(user_query, return_tensors=\"pt\").to('cuda')\n",
    "    outputs = quant_model.generate(input_ids=_inputs, max_length= 1000, pad_token_id=tokenizer.eos_token_id)\n",
    "    output = tokenizer.decode(outputs[0])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "574a42ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ace8938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken is : 21.147445678710938\n"
     ]
    }
   ],
   "source": [
    "# Using quant model\n",
    "start = time.time()\n",
    "output1 = predict_from_quant(\"what is art\")\n",
    "print(\"time taken is :\", time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "484f1d27",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</s>what is art?\n",
      "\n",
      "Art is a way of expressing one's self. It is a way of expressing one's thoughts, feelings, and ideas. It is a way of expressing one's self through the use of various media.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to\n"
     ]
    }
   ],
   "source": [
    "print(output1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3fee82",
   "metadata": {},
   "source": [
    "### Inference on un-quantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cdf676e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba90fb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/data/quantization-trials/merged-model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4a6c0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = model_path\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "\n",
    "def predict_from_normal(user_query):\n",
    "    _inputs = tokenizer.encode(user_query, return_tensors=\"pt\").to('cuda')\n",
    "    outputs = model.generate(input_ids=_inputs, max_length= 1000, pad_token_id=tokenizer.eos_token_id)\n",
    "    output = tokenizer.decode(outputs[0])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "010b00db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken is : 23.784337282180786\n"
     ]
    }
   ],
   "source": [
    "# Using unquant model\n",
    "import time\n",
    "start = time.time()\n",
    "output2 = predict_from_normal(\"what is art\")\n",
    "print(\"time taken is :\", time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b5b6f9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</s>what is art?\n",
      "\n",
      "Art is a creative expression of the human mind. It is a way of expressing the human mind through the use of various media.\n",
      "\n",
      "The word art is derived from the Latin word artus, which means \"to make\". The word art is used in many different contexts, including:\n",
      "\n",
      "- to describe the beauty of a work of art\n",
      "\n",
      "- to describe the meaning of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of\n"
     ]
    }
   ],
   "source": [
    "print(output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0949f05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OPTForCausalLM(\n",
       "  (model): OPTModel(\n",
       "    (decoder): OPTDecoder(\n",
       "      (embed_tokens): Embedding(50272, 2048, padding_idx=1)\n",
       "      (embed_positions): OPTLearnedPositionalEmbedding(2050, 2048)\n",
       "      (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      (layers): ModuleList(\n",
       "        (0-23): 24 x OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=50272, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f139bb23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OPTForCausalLM(\n",
       "  (model): OPTModel(\n",
       "    (decoder): OPTDecoder(\n",
       "      (embed_tokens): Embedding(50272, 2048, padding_idx=1)\n",
       "      (embed_positions): OPTLearnedPositionalEmbedding(2050, 2048)\n",
       "      (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      (layers): ModuleList(\n",
       "        (0-23): 24 x OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): WQLinear_GEMM(in_features=2048, out_features=2048, bias=True, w_bit=4, group_size=512)\n",
       "            (v_proj): WQLinear_GEMM(in_features=2048, out_features=2048, bias=True, w_bit=4, group_size=512)\n",
       "            (q_proj): WQLinear_GEMM(in_features=2048, out_features=2048, bias=True, w_bit=4, group_size=512)\n",
       "            (out_proj): WQLinear_GEMM(in_features=2048, out_features=2048, bias=True, w_bit=4, group_size=512)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): WQLinear_GEMM(in_features=2048, out_features=8192, bias=True, w_bit=4, group_size=512)\n",
       "          (fc2): WQLinear_GEMM(in_features=8192, out_features=2048, bias=True, w_bit=4, group_size=512)\n",
       "          (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=50272, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quant_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
