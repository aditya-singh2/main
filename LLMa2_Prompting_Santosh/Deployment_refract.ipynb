{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bfc391f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!sudo pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb264e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff5453fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from refractml import *\n",
    "from refractml.constants import MLModelFlavours\n",
    "# # new score functions\n",
    "from mosaic_utils.ai.score.base import ScoreBase\n",
    "from typing import Tuple, Union, List, Any\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6bbd799",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\"payload\":[{\"date_info\":{\n",
    "           \"start_date\": \"01/01/2020\",\n",
    "          \"end_date\": \"15/09/2023\"\n",
    "},\"question\":\"top 2 segments and bottom 3 sub-category basis quantity\",\"context\":{\n",
    "    \"MEASURE\": [{\"ENTITY\": \"Discount\", \"other names\": [\"discount\", \"discount rate\", \"discount value\", \"deduction\"]},\n",
    "                {\"ENTITY\": \"Purchase Vol\", \"other names\": [\"purchase\", \"purchase value\", \"purchase model\"]},\n",
    "                {\"ENTITY\": \"Quantity\", \"other names\": [\"quantity\", \"volume\"]},\n",
    "                {\"ENTITY\": \"Sales\", \"other names\": [\"sales\", \"sale\"]}],\n",
    "    \"DATE VARIABLE\": [\n",
    "        {\"ENTITY\": \"Order Date\", \"other names\": [\"order date\", \"date\", \"trend\", \"time\", \"when\", \"mom\", \"yoy\"]}]\n",
    "}}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b47d45a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# print(json.dumps(payload,indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64598c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "context ={\n",
    "    \"MEASURE\": [{\"ENTITY\": \"Discount\", \"other names\": [\"discount\", \"discount rate\", \"discount value\", \"deduction\"]},\n",
    "                {\"ENTITY\": \"Purchase Vol\", \"other names\": [\"purchase\", \"purchase value\", \"purchase model\"]},\n",
    "                {\"ENTITY\": \"Quantity\", \"other names\": [\"quantity\", \"volume\"]},\n",
    "                {\"ENTITY\": \"Sales\", \"other names\": [\"sales\", \"sale\"]}],\n",
    "    \"DATE VARIABLE\": [\n",
    "        {\"ENTITY\": \"Order Date\", \"other names\": [\"order date\", \"date\", \"trend\", \"time\", \"when\", \"mom\", \"yoy\"]}]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9eaa83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "context ={\n",
    "    \"MEASURE\": [{\"ENTITY\": \"Discount\", \"other names\": [\"discount\", \"discount rate\", \"discount value\", \"deduction\"]},\n",
    "                {\"ENTITY\": \"Purchase Vol\", \"other names\": [\"purchase\", \"purchase value\", \"purchase model\"]},\n",
    "                {\"ENTITY\": \"Quantity\", \"other names\": [\"quantity\", \"volume\"]},\n",
    "                {\"ENTITY\": \"Sales\", \"other names\": [\"sales\", \"sale\"]}],\n",
    "    \"DIMENSION\": [{\"ENTITY\": \"Sub-Category\", \"other names\": [\"sub-category\", \"sub category\", \"categories\", \"section\"]},\n",
    "                  {\"ENTITY\": \"Segment\", \"other names\": [\"segment\", \"segments\", \"units\", \"divisions\"]},\n",
    "                  {\"ENTITY\": \"Parts\", \"other names\": [\"parts\", \"part\", \"section\", \"divisions\"]},\n",
    "                  {\"ENTITY\": \"Country\", \"other names\": [\"country\", \"countries\"]}],\n",
    "    \"FILTER\": [{\"ENTITY\": \"Consumer\", \"other names\": [\"consumers\", \"consumer\"], \"parent\": \"Segment\"},\n",
    "               {\"ENTITY\": \"Phone\", \"other names\": [\"phone\", \"phones\", \"mobile phones\"], \"parent\": \"Sub-Category\"},\n",
    "               {\"ENTITY\": \"Binder\", \"other names\": [\"binders\", \"binder\"], \"parent\": \"Sub-Category\"},\n",
    "               {\"ENTITY\": \"Corporate\", \"other names\": [\"corporates\", \"corporate\"], \"parent\": \"Segment\"},\n",
    "               {\"ENTITY\": \"India\", \"other names\": [\"india\"], \"parent\": \"Country\"},\n",
    "               {\"ENTITY\": \"Dubai\", \"other names\": [\"dubai\"], \"parent\": \"Country\"}],\n",
    "    \"DERIVED MEASURE\": [{\"ENTITY\": \"Ratio\",\n",
    "                         \"other names\": [\"ratio\", \"share\", \"contribution\", \"percentage\", \"proportion\", \"contributing\"]},\n",
    "                        {\"ENTITY\": \"Why\", \"other names\": [\"why\", \"cause of\", \"reason for\", \"diagnose\"]},\n",
    "                        {\"ENTITY\": \"contribution_to_growth\",\n",
    "                         \"other names\": [\"contribution to growth\", \"growth\", \"grown\"]},\n",
    "                        {\"ENTITY\": \"kda_transactional\",\n",
    "                         \"other names\": [\"kda\", \"key drivers\", \"key driver\", \"drivers\", \"driver\"]},\n",
    "                        {\"ENTITY\": \"Growth Rate\", \"other names\": [\"growth rate\", \"growth\", \"grown\"]},\n",
    "                        {\"ENTITY\": \"correlation\",\n",
    "                         \"other names\": [\"associate\", \"associated\", \"association\", \"associations\", \"correlate\",\n",
    "                                         \"correlated\",\n",
    "                                         \"correlation\", \"correlations\", \"relate\", \"related\", \"relation\", \"relations\",\n",
    "                                         \"relationship\",\n",
    "                                         \"relationships\"]}\n",
    "                        ],\n",
    "    \"DATE VARIABLE\": [\n",
    "        {\"ENTITY\": \"Order Date\", \"other names\": [\"order date\", \"date\", \"trend\", \"time\", \"when\", \"mom\", \"yoy\"]}]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51831cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScoreTemplateExample(ScoreBase):\n",
    "    \"\"\"\n",
    "    This Class Demonstrate How To Implements ScoreBase Interface Class And It Basic Usage.\n",
    "    \"\"\"    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model_loaded = None\n",
    "        self.model_name =\"/data/huggingface/cache/models--openchat--openchat_3.5/snapshots/2d39b2e68fc16446e1760700e0de14721434cbbf\"\n",
    "        #self.date_input = {\n",
    "        #    \"start_date\": \"01/01/2020\",\n",
    "        #   \"end_date\": \"15/09/2023\"}\n",
    "\n",
    "        self.base_prompt = \"\"\"You are an assistant that helps to map the user question to the context for a question answering system.\n",
    "         You might also need to act as a time tagger expert to convert the date elements present in the question to a standard format and to find possible date ranges for the same.\n",
    "        Step 1: Identify the n-grams match between question and context\n",
    "        Map the n-gram or their lemma or their inflections from the question with the 'other names' in the passed context.\n",
    "        Always consider the longest n-gram match, not the sub-string.\n",
    "        If there are multiple matches for an n-gram with context, return all such ENTITY in response.\n",
    "        If you are returning any match which is not exactly present with the 'other names', make sure that it is a noun phrase and there is a high similarity between the match and the matched \"ENTITY\". \n",
    "        Step 2: Applying other conditions\n",
    "        Once the match is identified, next step is to identify other conditions from user question and apply it to the identified matches.\n",
    "        Refer to the following statements to understand about different types of conditions to be applied:\n",
    "            1. METRIC CONSTRAINT : METRIC can be MEASURE or DERIVED MEASURE. User is asking for a comparison limit to be applied on the METRIC. It has two parts: \"COMPARISON VALUE\" is the value applied on a METRIC and \"COMPARSION OPERATOR\" is the operator (in symbols) applied between METRIC and COMPARISON VALUE.\n",
    "            2. ADJECTIVE and TONE : Identify the adjectives (like least, highest performing etc.) applied on the matched ENTITY. TONE is the intent of adjective and it can be postive or negative.\n",
    "            3. EXCEPTION : Excluded FILTER of a DIMENSION asked in question if any. DIMENSION should be the parent of the FILTER. Add a key \"EXCLUDE\" for such excluded FILTERS and set the value as \"True\" in the response.\n",
    "            4. RANK : Rank applied on a DIMENSION if any like top 5, bottom 3 etc. It has two parts: \"RANK ADJECTIVE\", the adjective like top, bottom etc. and \"RANK VALUE\", a number that comes along with the RANK ADJECTIVE, immediately before or after. If there is no explicit RANK VALUE in question, make it as 1. Based on the meaning of the RANK ADJECTIVE, make it as either top or bottom.\n",
    "            5. RATIO FILTERS : This is applicable only for ENTITY \"Ratio\" in DERIVED MEASURE. Identify the FILTER on which Ratio needs to be calculated. Example 1: Question: bike share of sales in area, (where ENTITY of 'bike' is 'Bikes'), RATIO FILTERS = [{'bike': 'Bikes'}]. Example 2: Question: in area, share of bike and cycle basis sales, (where ENTITY of 'Bike' is 'Bikes' and 'cycle' is 'Cycle') RATIO FILTERS = [{'bike': 'Bikes', 'cycle': 'Cycles'}]. If there are no matched FILTERS, then keep RATIO FILTERS = []\"\n",
    "            6. APPLIED MEASURES: This is applicable only for DERIVED MEASURE. Identify the MEASURE on which the DERIVED MEASURE needs to be calculated. \n",
    "\n",
    "            Step 3: Applying time tagger rules only if time elements are present in question\n",
    "\n",
    "            Identify the TIME ELEMENTS in the input question and convert it to a standard format (if not already) by applying the general time tagging rules. If the TIME ELEMENT is already in a standard format, then no need to convert it.\n",
    "            TIME ELEMENT can be either a temporal interval (across months, yoy, mom, qoq, wow, quarterly etc.) or a temporal expression (time points such as specific dates, relative expressions etc.).\n",
    "            Calculate date range for each time points based on the following conditions:\n",
    "            1. For relative time expressions, calculate the date range based on a reference date - By default the reference date is the end_date in date input: \"\"\" '\\n' +  '@#<date_input>@#' + '\\n' \"\"\"\n",
    "            2. To calculate the date range for \"last X years\", strictly follow the below conditions:\n",
    "                    For \"last 1 year\", consider exactly one year before the reference year and set start date as January 1 and end date as Decemebr 31 of that year.\n",
    "                    For \"last X years\", where X is greater than 1, consider starting year = (reference year - X+1) and set start date as January 1 of starting year and end date as the reference date.\n",
    "            3. To calculate the date range for \"last X months\", strictly follow the below conditions:\n",
    "                    Consider the reference month as the month in reference date\n",
    "                    For \"last 1 month\", consider exactly one month before the reference month and set start date as first day and end date as last day of that month .\n",
    "                    For \"last X months\", where X is greater than 1, consider starting month = (reference month - X+1) and set start date as first day of starting month and end date as the reference date. (Example: if reference date is 14/09/2022, then last 3 months = 01/07/2022 - 14/09/2022)\n",
    "            4. To calculate the date range for \"last X quarters\", strictly follow the below conditions:\n",
    "                    For \"last 1 quarter\", consider exactly one quarter before the reference quarter and set start date as first day and end date as last day of that quarter .\n",
    "                    For \"last X quarter\", where X is greater than 1, consider starting quarter = (reference quarter - X+1) and set start date as first day of starting quarter and end date as the reference date.\n",
    "            5. To calculate the date range for \"last X weeks\", strictly follow the below conditions:\n",
    "                    For \"last 1 week\", consider exactly one week before the reference week and set start date as Monday and end date as Sunday of that week .\n",
    "                    For \"last X weeks\", where X is greater than 1, consider starting week = (reference week - X+1) and set start date as Monday of starting week and end date as the reference date.\n",
    "            6. Provide the date range of each time point in start date - end date format always.\n",
    "\n",
    "            Step 4: Creating the response JSON\n",
    "            Strictly return the response in the exact same JSON format as follows. \n",
    "            Fill the information identified from above steps in the JSON. \n",
    "            The keys mentioned in upper case in the response are constant.\n",
    "            Return only if match is found from the context and non empty values are present.\n",
    "            Replace the placeholders \"<>\" with your findings.\n",
    "            {\n",
    "                \"MEASURE\": {\n",
    "                    \"<n-gram matched to MEASURE>\": [\n",
    "                        {\n",
    "                            \"ENTITY\": \"<Matched MEASURE>\",\n",
    "                            \"MEASURE CONSTRAINT\": [\n",
    "                                {\n",
    "                                    \"COMPARISON VALUE\": \"\",\n",
    "                                    \"COMPARSION OPERATOR\": \"\"\n",
    "                                }\n",
    "                            ],\n",
    "                            \"ADJECTIVE\": [],\n",
    "                            \"TONE\": \"\"\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "                \"DIMENSION\": {\n",
    "                    \"<n-gram matched to DIMENSION>\": [\n",
    "                        {\n",
    "                            \"ENTITY\": \"<Matched DIMENSION>\",\n",
    "                            \"RANK\": [{\"RANK ADJECTIVE\":\"\", \"RANK VALUE\": \"\"}],\n",
    "                            \"ADJECTIVE\": [],\n",
    "                            \"TONE\": \"\"\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "                \"FILTER\": {\n",
    "                    \"<n-gram matched to FILTER>\": [\n",
    "                        {\n",
    "                            \"ENTITY\": \"<Matched FILTER>\",\n",
    "                            \"PARENT\": \"<parent of the Matched FILTER>\",\n",
    "                            \"EXCLUDE\": \"\"\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "                \"DERIVED MEASURE\": {\n",
    "                    \"<n-gram matched to DERIVED MEASURE>\": [\n",
    "                        {\n",
    "                            \"ENTITY\": \"<Matched DERIVED MEASURE>\",\n",
    "                            \"RATIO FILTER\": [{}],\n",
    "                            \"APPLIED MEASURE\": [{\"<n-gram matched to MEASURE>\": \"<Matched MEASURE>\"}],\n",
    "                            \"DERIVED MEASURE CONSTRAINT\": [\n",
    "                                {\n",
    "                                    \"COMPARISON VALUE\": \"\",\n",
    "                                    \"COMPARSION OPERATOR\": \"\"\n",
    "                                }\n",
    "                            ],\n",
    "                            \"ADJECTIVE\": [],\n",
    "                            \"TONE\": \"\"\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "                \"DATE VARIABLE\": {\n",
    "                    \"asked time element\": [{\"ENTITY\": \"<Matched DATE VARIABLE>\"\n",
    "                        \"DATE RANGE\": \"date range\",\n",
    "                        \"CONVERTED TIME ELEMENT\": \"<converted time element>\"\n",
    "                        }]\n",
    "                }\n",
    "            }\n",
    "\n",
    "            Provide reasoning\n",
    "            \"\"\"\n",
    "        from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "        import time\n",
    "        import torch\n",
    "        from huggingface_hub.utils import disable_progress_bars\n",
    "        disable_progress_bars()\n",
    "        if self.model_loaded is None:\n",
    "            print(\"Model is Loading from data cache\")\n",
    "            self.model_loaded = AutoModelForCausalLM.from_pretrained(self.model_name, device_map=\"auto\", torch_dtype=torch.bfloat16)\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name, trust_remote_code=True,\n",
    "                                          # add_eos_token=True,\n",
    "                                          use_fast=False)\n",
    "            #self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "            #self.tokenizer.padding_side = \"right\"\n",
    "    def request_processing_fn(self, request) :\n",
    "        \"\"\"\n",
    "        Processes Request Object -> List[{\"question\": \"\",\"context\":\"\"},{\"question\": \"\",\"context\":\"\"},...]\n",
    "\n",
    "        :return: (n_inputs, payload's)\n",
    "\n",
    "        Warnings:\n",
    "        1. Do not reshape your final output for single sample here, do it in prediction.\n",
    "           Else payloads will be invalidated for extraction at raw and extraction level.\n",
    "        \"\"\"\n",
    "        final_payload = []\n",
    "        raw_payload = request.json[\"payload\"]\n",
    "        return (len(raw_payload), raw_payload) \n",
    "    \n",
    "    def pre_processing_fn(self,payload):\n",
    "        return payload\n",
    "\n",
    "    \n",
    "    def prediction_fn(self,\n",
    "                      model: Any,\n",
    "                      input_query\n",
    "                       ):\n",
    "        \"\"\"\n",
    "                Does the main prediction on pre_processed_input(Single Sample) using supplied model .\n",
    "\n",
    "                :param model: Supported Model\n",
    "                :param pre_processed_input: Single Preprocessed Payload\n",
    "                :return: Prediction Value From the model\n",
    "                \n",
    "                Important Notes:\n",
    "                - Reshape your data array.reshape(1, -1) before predictions as it contains a single sample.\n",
    "                    \n",
    "        \"\"\"\n",
    "        question = input_query.get(\"question\")\n",
    "        context = input_query.get(\"context\")\n",
    "        date_info = input_query.get(\"date_info\")\n",
    "        query = \"\"\"Now Based on this following context: \\n \"\"\"+ str(context) + \"\\n return a response for this question:\\n\" + question + \"\\n\"\n",
    "        prompt = f\"\"\"<s>[IDENTITY]\n",
    "                    {self.base_prompt.replace('@#<date_input>@#',str(date_info))}\n",
    "                    [/IDENTITY]</s>\n",
    "                    [INST]\n",
    "                    {query}\n",
    "                    [/INST]\n",
    "                    \"\"\"\n",
    "        print(\"Prompting has started\")\n",
    "        import time\n",
    "        start = time.time()\n",
    "        model_input = self.tokenizer(prompt, return_tensors=\"pt\")#.to(\"cuda\")\n",
    "        response=  self.tokenizer.decode(self.model_loaded.generate(**model_input, max_length=1024*3)[0], skip_special_tokens=True)\n",
    "        print(f\"Total time taken = {time.time()-start}\")\n",
    "        #response = response[0][\"generated_text\"]\n",
    "        preds = response.split(\"[SOL]\")[-1].split(\"[/SOL]\")[0]\n",
    "        print(\"prediction is \\n: \",preds)\n",
    "        return [preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3004ecc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is Loading from data cache\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1791a5c66c8144f885eb1093c00e8408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mScoreTemplateExample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m req \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mRequest()\n\u001b[1;32m      3\u001b[0m req\u001b[38;5;241m.\u001b[39mjson \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpayload\u001b[39m\u001b[38;5;124m\"\u001b[39m:[{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhat is purchase across segments\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m:context,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate_info\u001b[39m\u001b[38;5;124m\"\u001b[39m:{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_date\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m01/01/2020\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend_date\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m15/09/2023\u001b[39m\u001b[38;5;124m\"\u001b[39m}}]}\n",
      "Cell \u001b[0;32mIn[9], line 126\u001b[0m, in \u001b[0;36mScoreTemplateExample.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_loaded \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel is Loading from data cache\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_loaded \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfloat16\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name, trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    128\u001b[0m                                   \u001b[38;5;66;03m# add_eos_token=True,\u001b[39;00m\n\u001b[1;32m    129\u001b[0m                                   use_fast\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py:566\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    565\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 566\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    572\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/modeling_utils.py:3480\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3471\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3472\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   3473\u001b[0m     (\n\u001b[1;32m   3474\u001b[0m         model,\n\u001b[1;32m   3475\u001b[0m         missing_keys,\n\u001b[1;32m   3476\u001b[0m         unexpected_keys,\n\u001b[1;32m   3477\u001b[0m         mismatched_keys,\n\u001b[1;32m   3478\u001b[0m         offload_index,\n\u001b[1;32m   3479\u001b[0m         error_msgs,\n\u001b[0;32m-> 3480\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[1;32m   3484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3485\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3486\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3487\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3488\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3491\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3492\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_quantized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquantization_method\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mQuantizationMethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBITS_AND_BYTES\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3496\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3498\u001b[0m model\u001b[38;5;241m.\u001b[39mis_loaded_in_4bit \u001b[38;5;241m=\u001b[39m load_in_4bit\n\u001b[1;32m   3499\u001b[0m model\u001b[38;5;241m.\u001b[39mis_loaded_in_8bit \u001b[38;5;241m=\u001b[39m load_in_8bit\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/modeling_utils.py:3856\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, is_quantized, keep_in_fp32_modules)\u001b[0m\n\u001b[1;32m   3854\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shard_file \u001b[38;5;129;01min\u001b[39;00m disk_only_shard_files:\n\u001b[1;32m   3855\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m-> 3856\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshard_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3858\u001b[0m \u001b[38;5;66;03m# Mistmatched keys contains tuples key/shape1/shape2 of weights in the checkpoint that have a shape not\u001b[39;00m\n\u001b[1;32m   3859\u001b[0m \u001b[38;5;66;03m# matching the weights in the model.\u001b[39;00m\n\u001b[1;32m   3860\u001b[0m mismatched_keys \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m _find_mismatched_keys(\n\u001b[1;32m   3861\u001b[0m     state_dict,\n\u001b[1;32m   3862\u001b[0m     model_state_dict,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3866\u001b[0m     ignore_mismatched_sizes,\n\u001b[1;32m   3867\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/modeling_utils.py:484\u001b[0m, in \u001b[0;36mload_state_dict\u001b[0;34m(checkpoint_file)\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    483\u001b[0m         map_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 484\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_location\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/serialization.py:809\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    808\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 809\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[1;32m    811\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/serialization.py:1172\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1170\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1171\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1172\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1174\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/serialization.py:1142\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1141\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1142\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/serialization.py:1112\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_tensor\u001b[39m(dtype, numel, key, location):\n\u001b[1;32m   1110\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m-> 1112\u001b[0m     storage \u001b[38;5;241m=\u001b[39m \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_storage_from_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUntypedStorage\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_untyped_storage\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   1114\u001b[0m     \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[1;32m   1116\u001b[0m         wrap_storage\u001b[38;5;241m=\u001b[39mrestore_location(storage, location),\n\u001b[1;32m   1117\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1118\u001b[0m         _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "score = ScoreTemplateExample()\n",
    "req = requests.Request()\n",
    "req.json = {\"payload\":[{\"question\":\"what is purchase across segments\",\"context\":context,\"date_info\":{\"start_date\": \"01/01/2020\",\"end_date\": \"15/09/2023\"}}]}\n",
    "score.score(None, req, dry_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296b26ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\n",
    "req.json = {\"payload\":[{\"question\":question,\"context\":context,\"date_info\":{\"start_date\": \"01/01/2020\",\"end_date\": \"15/09/2023\"}}]}\n",
    "score.score(None, req, dry_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65399a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\n",
    "req.json = {\"payload\":[{\"question\":question,\"context\":context,\"date_info\":{\"start_date\": \"01/01/2020\",\"end_date\": \"15/09/2023\"}}]}\n",
    "score.score(None, req, dry_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdeb7301",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee7f40d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:torch.distributed.nn.jit.instantiator:Created a temporary directory at /tmp/tmp9jj8204m\n",
      "INFO:torch.distributed.nn.jit.instantiator:Writing /tmp/tmp9jj8204m/_remote_module_non_scriptable.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM model loading Open_Chat_3_5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a924fef5eab34fc39c4c36bc7b817428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VALIDATION</th>\n",
       "      <th>COMPONENT</th>\n",
       "      <th>PASSED</th>\n",
       "      <th>SKIPPED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Return Type Must Be Tuple (n_input, payloads)</td>\n",
       "      <td>request_processing_fn</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuple Must Be of length Two (n_input, payloads)</td>\n",
       "      <td>request_processing_fn</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>* if n_input &gt; 1 payload type must be List (n_input, [np.ndarray, tf.Tensor, etc])</td>\n",
       "      <td>request_processing_fn</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           VALIDATION  \\\n",
       "0                                       Return Type Must Be Tuple (n_input, payloads)   \n",
       "1                                     Tuple Must Be of length Two (n_input, payloads)   \n",
       "2  * if n_input > 1 payload type must be List (n_input, [np.ndarray, tf.Tensor, etc])   \n",
       "\n",
       "               COMPONENT  PASSED  SKIPPED  \n",
       "0  request_processing_fn    True    False  \n",
       "1  request_processing_fn    True    False  \n",
       "2  request_processing_fn    True    False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fields Marked Asterisk (*) Can Be Validated On Proper Input \n",
      "\n",
      "Prompting has started\n",
      "Total time taken = 371.7729585170746\n",
      "prediction is \n",
      ":  \n",
      "                    {\n",
      "                        \"MEASURE\": {\n",
      "                            \"Quantity\": [\n",
      "                                {\n",
      "                                    \"ENTITY\": \"Quantity\",\n",
      "                                    \"MEASURE CONSTRAINT\": [\n",
      "                                        {\n",
      "                                            \"COMPARISON VALUE\": \"\",\n",
      "                                            \"COMPARSION OPERATOR\": \"\"\n",
      "                                        }\n",
      "                                    ],\n",
      "                                    \"ADJECTIVE\": [],\n",
      "                                    \"TONE\": \"\"\n",
      "                                }\n",
      "                            ]\n",
      "                        },\n",
      "                        \"DIMENSION\": {\n",
      "                            \"Segment\": [\n",
      "                                {\n",
      "                                    \"ENTITY\": \"Segment\",\n",
      "                                    \"RANK\": [\n",
      "                                        {\n",
      "                                            \"RANK ADJECTIVE\": \"top\",\n",
      "                                            \"RANK VALUE\": \"2\"\n",
      "                                        }\n",
      "                                    ],\n",
      "                                    \"ADJECTIVE\": [],\n",
      "                                    \"TONE\": \"\"\n",
      "                                }\n",
      "                            ],\n",
      "                            \"Sub-Category\": [\n",
      "                                {\n",
      "                                    \"ENTITY\": \"Sub-Category\",\n",
      "                                    \"RANK\": [\n",
      "                                        {\n",
      "                                            \"RANK ADJECTIVE\": \"bottom\",\n",
      "                                            \"RANK VALUE\": \"3\"\n",
      "                                        }\n",
      "                                    ],\n",
      "                                    \"ADJECTIVE\": [],\n",
      "                                    \"TONE\": \"\"\n",
      "                                }\n",
      "                            ]\n",
      "                        },\n",
      "                        \"FILTER\": [],\n",
      "                        \"DERIVED MEASURE\": [],\n",
      "                        \"DATE VARIABLE\": {\n",
      "                            \"Order Date\": [\n",
      "                                {\n",
      "                                    \"ENTITY\": \"Order Date\",\n",
      "                                    \"DATE RANGE\": \"date range\",\n",
      "                                    \"CONVERTED TIME ELEMENT\": \"date range\"\n",
      "                                }\n",
      "                            ]\n",
      "                        }\n",
      "                    }\n",
      "                    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<<ScoreResponse>>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_ = ScoreTemplateExample()\n",
    "req = requests.Request()\n",
    "req.json = {\"payload\":[{\"question\":\"top 2 segments and bottom 3 sub-category basis quantity\",\"context\":context,\"date_info\":{\"start_date\": \"01/01/2020\",\"end_date\": \"15/09/2023\"}}]}\n",
    "score_.score(None, req, dry_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc341beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VALIDATION</th>\n",
       "      <th>COMPONENT</th>\n",
       "      <th>PASSED</th>\n",
       "      <th>SKIPPED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Return Type Must Be Tuple (n_input, payloads)</td>\n",
       "      <td>request_processing_fn</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuple Must Be of length Two (n_input, payloads)</td>\n",
       "      <td>request_processing_fn</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>* if n_input &gt; 1 payload type must be List (n_input, [np.ndarray, tf.Tensor, etc])</td>\n",
       "      <td>request_processing_fn</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           VALIDATION  \\\n",
       "0                                       Return Type Must Be Tuple (n_input, payloads)   \n",
       "1                                     Tuple Must Be of length Two (n_input, payloads)   \n",
       "2  * if n_input > 1 payload type must be List (n_input, [np.ndarray, tf.Tensor, etc])   \n",
       "\n",
       "               COMPONENT  PASSED  SKIPPED  \n",
       "0  request_processing_fn    True    False  \n",
       "1  request_processing_fn    True    False  \n",
       "2  request_processing_fn    True    False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fields Marked Asterisk (*) Can Be Validated On Proper Input \n",
      "\n",
      "Prompting has started\n",
      "prediction is \n",
      ":  \n",
      "                    {\n",
      "                        \"MEASURE\": {\n",
      "                            \"Quantity\": [\n",
      "                                {\n",
      "                                    \"ENTITY\": \"Quantity\",\n",
      "                                    \"MEASURE CONSTRAINT\": [\n",
      "                                        {\n",
      "                                            \"COMPARISON VALUE\": \"\",\n",
      "                                            \"COMPARSION OPERATOR\": \"\"\n",
      "                                        }\n",
      "                                    ],\n",
      "                                    \"ADJECTIVE\": [],\n",
      "                                    \"TONE\": \"\"\n",
      "                                }\n",
      "                            ]\n",
      "                        },\n",
      "                        \"DIMENSION\": {\n",
      "                            \"Segment\": [\n",
      "                                {\n",
      "                                    \"ENTITY\": \"Segment\",\n",
      "                                    \"RANK\": [\n",
      "                                        {\n",
      "                                            \"RANK ADJECTIVE\": \"top\",\n",
      "                                            \"RANK VALUE\": \"2\"\n",
      "                                        }\n",
      "                                    ],\n",
      "                                    \"ADJECTIVE\": [],\n",
      "                                    \"TONE\": \"\"\n",
      "                                }\n",
      "                            ],\n",
      "                            \"Sub-Category\": [\n",
      "                                {\n",
      "                                    \"ENTITY\": \"Sub-Category\",\n",
      "                                    \"RANK\": [\n",
      "                                        {\n",
      "                                            \"RANK ADJECTIVE\": \"bottom\",\n",
      "                                            \"RANK VALUE\": \"3\"\n",
      "                                        }\n",
      "                                    ],\n",
      "                                    \"ADJECTIVE\": [],\n",
      "                                    \"TONE\": \"\"\n",
      "                                }\n",
      "                            ]\n",
      "                        },\n",
      "                        \"FILTER\": [],\n",
      "                        \"DERIVED MEASURE\": [],\n",
      "                        \"DATE VARIABLE\": {\n",
      "                            \"Order Date\": [\n",
      "                                {\n",
      "                                    \"ENTITY\": \"Order Date\",\n",
      "                                    \"DATE RANGE\": \"date range\",\n",
      "                                    \"CONVERTED TIME ELEMENT\": \"date range\"\n",
      "                                }\n",
      "                            ]\n",
      "                        }\n",
      "                    }\n",
      "                    \n",
      "CPU times: user 40min 41s, sys: 1min, total: 41min 42s\n",
      "Wall time: 5min 14s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<<ScoreResponse>>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "req = requests.Request()\n",
    "req.json = {\"payload\":[{\"question\":\"top 2 segments and bottom 3 sub-category basis quantity\",\"context\":context}]}\n",
    "score_.score(None, req, dry_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fc61fc2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VALIDATION</th>\n",
       "      <th>COMPONENT</th>\n",
       "      <th>PASSED</th>\n",
       "      <th>SKIPPED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Return Type Must Be Tuple (n_input, payloads)</td>\n",
       "      <td>request_processing_fn</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuple Must Be of length Two (n_input, payloads)</td>\n",
       "      <td>request_processing_fn</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>* if n_input &gt; 1 payload type must be List (n_input, [np.ndarray, tf.Tensor, etc])</td>\n",
       "      <td>request_processing_fn</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           VALIDATION  \\\n",
       "0                                       Return Type Must Be Tuple (n_input, payloads)   \n",
       "1                                     Tuple Must Be of length Two (n_input, payloads)   \n",
       "2  * if n_input > 1 payload type must be List (n_input, [np.ndarray, tf.Tensor, etc])   \n",
       "\n",
       "               COMPONENT  PASSED  SKIPPED  \n",
       "0  request_processing_fn    True    False  \n",
       "1  request_processing_fn    True    False  \n",
       "2  request_processing_fn    True    False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fields Marked Asterisk (*) Can Be Validated On Proper Input \n",
      "\n",
      "promting has started\n",
      "prediction is \n",
      ":  \n",
      "                    {\n",
      "                        \"MEASURE\": {\n",
      "                            \"segment\": [\n",
      "                                {\n",
      "                                    \"ENTITY\": \"segments\",\n",
      "                                    \"MEASURE CONSTRAINT\": [\n",
      "                                        {\n",
      "                                            \"COMPARISON VALUE\": \"\",\n",
      "                                            \"COMPARSION OPERATOR\": \"\"\n",
      "                                        }\n",
      "                                    ],\n",
      "                                    \"ADJECTIVE\": [],\n",
      "                                    \"TONE\": \"\"\n",
      "                                }\n",
      "                            ]\n",
      "                        },\n",
      "                        \"DIMENSION\": {\n",
      "                            \"quantity\": [\n",
      "                                {\n",
      "                                    \"ENTITY\": \"quantity\",\n",
      "                                    \"RANK\": [\n",
      "                                        {\n",
      "                                            \"RANK ADJECTIVE\": \"top\",\n",
      "                                            \"RANK VALUE\": \"2\"\n",
      "                                        }\n",
      "                                    ],\n",
      "                                    \"ADJECTIVE\": [],\n",
      "                                    \"TONE\": \"\"\n",
      "                                }\n",
      "                            ]\n",
      "                        },\n",
      "                        \"FILTER\": {},\n",
      "                        \"DERIVED MEASURE\": {},\n",
      "                        \"DATE VARIABLE\": {}\n",
      "                    }\n",
      "                    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<<ScoreResponse>>]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "req = requests.Request()\n",
    "req.json = {\"payload\":[{\"question\":\"top 2 segments basis quantity\",\"context\":context}]}\n",
    "score_.score(None, req, dry_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e3b7ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=\"/data/huggingface/cache/models--openchat--openchat_3.5/snapshots/2d39b2e68fc16446e1760700e0de14721434cbbf\"\n",
    "#model=score_.model_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4590e224",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:PASS:: Mandatory Validation :: dict_keys(['name', 'description', 'flavour', 'scoring_func'])\n",
      "INFO:root:PASS:: AlphaNumeric Validation :: dict_keys(['name'])\n",
      "INFO:root:PASS:: Validation/IfPresentTypeCheck :: dict_keys(['schema', 'metadata_info', 'tags'])\n",
      "INFO:root:PASS:: Validation/IfPresentSubfieldMustExist :: dict_keys(['kyd'])\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): mosaic-ai-backend:5000\n",
      "DEBUG:urllib3.connectionpool:http://mosaic-ai-backend:5000 \"POST /registry/api/v1/ml-model/register HTTP/1.1\" 200 6940\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): mosaic-ai-backend:5000\n",
      "DEBUG:urllib3.connectionpool:http://mosaic-ai-backend:5000 \"GET /registry/api/v1/ml-model/6ed23fdd-6fff-4354-9047-913b00cf916a HTTP/1.1\" 200 6933\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): mosaic-ai-backend:5000\n",
      "DEBUG:urllib3.connectionpool:http://mosaic-ai-backend:5000 \"GET /registry/api/v1/ml-model/6ed23fdd-6fff-4354-9047-913b00cf916a HTTP/1.1\" 200 6933\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efa79afd86dc4fce85d9dcba632f24d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<style>.grad_1{background: #2468a4;} .grad_2{ color:white; background: #2468a4;}</s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "register_model(model,\n",
    "               ScoreTemplateExample,\n",
    "               \"Open_Chat_iMQL_Generator_for_GPU_01\",\n",
    "               \"IMQL_Generator_using_open_chat_3_5_for_GPU01\",\n",
    "               MLModelFlavours.pytorch,\n",
    "               init_script=\"\"\"sudo chmod -R 777 /home/mosaic-ai/.cache\\\\npip install torch \\\\npip install --upgrade transformers\\\\npip install accelerate\"\"\"\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c9d796",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
