{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bfc391f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/dd/f17b11a93a9ca27728e12512d167eb1281c151c4c6881d3ab59eb58f4127/transformers-4.35.2-py3-none-any.whl (7.9MB)\n",
      "\u001b[K     |████████████████████████████████| 7.9MB 8.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied, skipping upgrade: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied, skipping upgrade: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied, skipping upgrade: filelock in /opt/conda/lib/python3.8/site-packages (from transformers) (3.9.0)\n",
      "Collecting tokenizers<0.19,>=0.14\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/75/56230c5c65b226e707e1adbc759c19fdf1b20bb02c0276796b132c97118a/tokenizers-0.15.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8MB)\n",
      "\u001b[K     |████████████████████████████████| 3.9MB 58.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: requests in /opt/conda/lib/python3.8/site-packages (from transformers) (2.29.0)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied, skipping upgrade: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (1.21.1)\n",
      "Requirement already satisfied, skipping upgrade: safetensors>=0.3.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.3.2)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.1.1)\n",
      "Requirement already satisfied, skipping upgrade: fsspec in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2023.5.7)\n",
      "Requirement already satisfied, skipping upgrade: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (3.4)\n",
      "Installing collected packages: tokenizers, transformers\n",
      "  Found existing installation: tokenizers 0.13.3\n",
      "    Uninstalling tokenizers-0.13.3:\n",
      "      Successfully uninstalled tokenizers-0.13.3\n",
      "  Found existing installation: transformers 4.31.0\n",
      "    Uninstalling transformers-4.31.0:\n",
      "      Successfully uninstalled transformers-4.31.0\n",
      "Successfully installed tokenizers-0.15.0 transformers-4.35.2\n",
      "Collecting fuzzywuzzy\n",
      "  Downloading https://files.pythonhosted.org/packages/43/ff/74f23998ad2f93b945c0309f825be92e04e0348e062026998b5eefef4c33/fuzzywuzzy-0.18.0-py2.py3-none-any.whl\n",
      "Installing collected packages: fuzzywuzzy\n",
      "Successfully installed fuzzywuzzy-0.18.0\n"
     ]
    }
   ],
   "source": [
    "!sudo pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb264e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff5453fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "from refractml import *\n",
    "from refractml.constants import MLModelFlavours\n",
    "# # new score functions\n",
    "from mosaic_utils.ai.score.base import ScoreBase\n",
    "from typing import Tuple, Union, List, Any\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6bbd799",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\"payload\":[{\"question\":\"top 2 segments and bottom 3 sub-category basis quantity\",\"context\":{\n",
    "    \"MEASURE\": [{\"ENTITY\": \"Discount\", \"other names\": [\"discount\", \"discount rate\", \"discount value\", \"deduction\"]},\n",
    "                {\"ENTITY\": \"Purchase Vol\", \"other names\": [\"purchase\", \"purchase value\", \"purchase model\"]},\n",
    "                {\"ENTITY\": \"Quantity\", \"other names\": [\"quantity\", \"volume\"]},\n",
    "                {\"ENTITY\": \"Sales\", \"other names\": [\"sales\", \"sale\"]}],\n",
    "    \"DATE VARIABLE\": [\n",
    "        {\"ENTITY\": \"Order Date\", \"other names\": [\"order date\", \"date\", \"trend\", \"time\", \"when\", \"mom\", \"yoy\"]}]\n",
    "}}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b47d45a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# print(json.dumps(payload,indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64598c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "context ={\n",
    "    \"MEASURE\": [{\"ENTITY\": \"Discount\", \"other names\": [\"discount\", \"discount rate\", \"discount value\", \"deduction\"]},\n",
    "                {\"ENTITY\": \"Purchase Vol\", \"other names\": [\"purchase\", \"purchase value\", \"purchase model\"]},\n",
    "                {\"ENTITY\": \"Quantity\", \"other names\": [\"quantity\", \"volume\"]},\n",
    "                {\"ENTITY\": \"Sales\", \"other names\": [\"sales\", \"sale\"]}],\n",
    "    \"DATE VARIABLE\": [\n",
    "        {\"ENTITY\": \"Order Date\", \"other names\": [\"order date\", \"date\", \"trend\", \"time\", \"when\", \"mom\", \"yoy\"]}]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9eaa83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "context ={\n",
    "    \"MEASURE\": [{\"ENTITY\": \"Discount\", \"other names\": [\"discount\", \"discount rate\", \"discount value\", \"deduction\"]},\n",
    "                {\"ENTITY\": \"Purchase Vol\", \"other names\": [\"purchase\", \"purchase value\", \"purchase model\"]},\n",
    "                {\"ENTITY\": \"Quantity\", \"other names\": [\"quantity\", \"volume\"]},\n",
    "                {\"ENTITY\": \"Sales\", \"other names\": [\"sales\", \"sale\"]}],\n",
    "    \"DIMENSION\": [{\"ENTITY\": \"Sub-Category\", \"other names\": [\"sub-category\", \"sub category\", \"categories\", \"section\"]},\n",
    "                  {\"ENTITY\": \"Segment\", \"other names\": [\"segment\", \"segments\", \"units\", \"divisions\"]},\n",
    "                  {\"ENTITY\": \"Parts\", \"other names\": [\"parts\", \"part\", \"section\", \"divisions\"]},\n",
    "                  {\"ENTITY\": \"Country\", \"other names\": [\"country\", \"countries\"]}],\n",
    "    \"FILTER\": [{\"ENTITY\": \"Consumer\", \"other names\": [\"consumers\", \"consumer\"], \"parent\": \"Segment\"},\n",
    "               {\"ENTITY\": \"Phone\", \"other names\": [\"phone\", \"phones\", \"mobile phones\"], \"parent\": \"Sub-Category\"},\n",
    "               {\"ENTITY\": \"Binder\", \"other names\": [\"binders\", \"binder\"], \"parent\": \"Sub-Category\"},\n",
    "               {\"ENTITY\": \"Corporate\", \"other names\": [\"corporates\", \"corporate\"], \"parent\": \"Segment\"},\n",
    "               {\"ENTITY\": \"India\", \"other names\": [\"india\"], \"parent\": \"Country\"},\n",
    "               {\"ENTITY\": \"Dubai\", \"other names\": [\"dubai\"], \"parent\": \"Country\"}],\n",
    "    \"DERIVED MEASURE\": [{\"ENTITY\": \"Ratio\",\n",
    "                         \"other names\": [\"ratio\", \"share\", \"contribution\", \"percentage\", \"proportion\", \"contributing\"]},\n",
    "                        {\"ENTITY\": \"Why\", \"other names\": [\"why\", \"cause of\", \"reason for\", \"diagnose\"]},\n",
    "                        {\"ENTITY\": \"contribution_to_growth\",\n",
    "                         \"other names\": [\"contribution to growth\", \"growth\", \"grown\"]},\n",
    "                        {\"ENTITY\": \"kda_transactional\",\n",
    "                         \"other names\": [\"kda\", \"key drivers\", \"key driver\", \"drivers\", \"driver\"]},\n",
    "                        {\"ENTITY\": \"Growth Rate\", \"other names\": [\"growth rate\", \"growth\", \"grown\"]},\n",
    "                        {\"ENTITY\": \"correlation\",\n",
    "                         \"other names\": [\"associate\", \"associated\", \"association\", \"associations\", \"correlate\",\n",
    "                                         \"correlated\",\n",
    "                                         \"correlation\", \"correlations\", \"relate\", \"related\", \"relation\", \"relations\",\n",
    "                                         \"relationship\",\n",
    "                                         \"relationships\"]}\n",
    "                        ],\n",
    "    \"DATE VARIABLE\": [\n",
    "        {\"ENTITY\": \"Order Date\", \"other names\": [\"order date\", \"date\", \"trend\", \"time\", \"when\", \"mom\", \"yoy\"]}]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51831cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScoreTemplateExample(ScoreBase):\n",
    "    \"\"\"\n",
    "    This Class Demonstrate How To Implements ScoreBase Interface Class And It Basic Usage.\n",
    "    \"\"\"    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model_loaded = None\n",
    "        self.model_name =\"/data/huggingface/cache/models--openchat--openchat_3.5/snapshots/2d39b2e68fc16446e1760700e0de14721434cbbf\"\n",
    "        self.date_input = {\n",
    "            \"start_date\": \"01/01/2020\",\n",
    "            \"end_date\": \"15/09/2023\"}\n",
    "\n",
    "        self.base_prompt = \"\"\"You are an assistant that helps to map the user question to the context for a question answering system.\n",
    "         You might also need to act as a time tagger expert to convert the date elements present in the question to a standard format and to find possible date ranges for the same.\n",
    "        Step 1: Identify the n-grams match between question and context\n",
    "        Map the n-gram or their lemma or their inflections from the question with the 'other names' in the passed context.\n",
    "        Always consider the longest n-gram match, not the sub-string.\n",
    "        If there are multiple matches for an n-gram with context, return all such ENTITY in response.\n",
    "        If you are returning any match which is not exactly present with the 'other names', make sure that it is a noun phrase and there is a high similarity between the match and the matched \"ENTITY\". \n",
    "        Step 2: Applying other conditions\n",
    "        Once the match is identified, next step is to identify other conditions from user question and apply it to the identified matches.\n",
    "        Refer to the following statements to understand about different types of conditions to be applied:\n",
    "            1. METRIC CONSTRAINT : METRIC can be MEASURE or DERIVED MEASURE. User is asking for a comparison limit to be applied on the METRIC. It has two parts: \"COMPARISON VALUE\" is the value applied on a METRIC and \"COMPARSION OPERATOR\" is the operator (in symbols) applied between METRIC and COMPARISON VALUE.\n",
    "            2. ADJECTIVE and TONE : Identify the adjectives (like least, highest performing etc.) applied on the matched ENTITY. TONE is the intent of adjective and it can be postive or negative.\n",
    "            3. EXCEPTION : Excluded FILTER of a DIMENSION asked in question if any. DIMENSION should be the parent of the FILTER. Add a key \"EXCLUDE\" for such excluded FILTERS and set the value as \"True\" in the response.\n",
    "            4. RANK : Rank applied on a DIMENSION if any like top 5, bottom 3 etc. It has two parts: \"RANK ADJECTIVE\", the adjective like top, bottom etc. and \"RANK VALUE\", a number that comes along with the RANK ADJECTIVE, immediately before or after. If there is no explicit RANK VALUE in question, make it as 1. Based on the meaning of the RANK ADJECTIVE, make it as either top or bottom.\n",
    "            5. RATIO FILTERS : This is applicable only for ENTITY \"Ratio\" in DERIVED MEASURE. Identify the FILTER on which Ratio needs to be calculated. Example 1: Question: bike share of sales in area, (where ENTITY of 'bike' is 'Bikes'), RATIO FILTERS = [{'bike': 'Bikes'}]. Example 2: Question: in area, share of bike and cycle basis sales, (where ENTITY of 'Bike' is 'Bikes' and 'cycle' is 'Cycle') RATIO FILTERS = [{'bike': 'Bikes', 'cycle': 'Cycles'}]. If there are no matched FILTERS, then keep RATIO FILTERS = []\"\n",
    "            6. APPLIED MEASURES: This is applicable only for DERIVED MEASURE. Identify the MEASURE on which the DERIVED MEASURE needs to be calculated. \n",
    "\n",
    "            Step 3: Applying time tagger rules only if time elements are present in question\n",
    "\n",
    "            Identify the TIME ELEMENTS in the input question and convert it to a standard format (if not already) by applying the general time tagging rules. If the TIME ELEMENT is already in a standard format, then no need to convert it.\n",
    "            TIME ELEMENT can be either a temporal interval (across months, yoy, mom, qoq, wow, quarterly etc.) or a temporal expression (time points such as specific dates, relative expressions etc.).\n",
    "            Calculate date range for each time points based on the following conditions:\n",
    "            1. For relative time expressions, calculate the date range based on a reference date - By default the reference date is the end_date in date input: \"\"\" '\\n' + str(\n",
    "            self.date_input) + '\\n' \"\"\"\n",
    "            2. To calculate the date range for \"last X years\", strictly follow the below conditions:\n",
    "                    For \"last 1 year\", consider exactly one year before the reference year and set start date as January 1 and end date as Decemebr 31 of that year.\n",
    "                    For \"last X years\", where X is greater than 1, consider starting year = (reference year - X+1) and set start date as January 1 of starting year and end date as the reference date.\n",
    "            3. To calculate the date range for \"last X months\", strictly follow the below conditions:\n",
    "                    Consider the reference month as the month in reference date\n",
    "                    For \"last 1 month\", consider exactly one month before the reference month and set start date as first day and end date as last day of that month .\n",
    "                    For \"last X months\", where X is greater than 1, consider starting month = (reference month - X+1) and set start date as first day of starting month and end date as the reference date. (Example: if reference date is 14/09/2022, then last 3 months = 01/07/2022 - 14/09/2022)\n",
    "            4. To calculate the date range for \"last X quarters\", strictly follow the below conditions:\n",
    "                    For \"last 1 quarter\", consider exactly one quarter before the reference quarter and set start date as first day and end date as last day of that quarter .\n",
    "                    For \"last X quarter\", where X is greater than 1, consider starting quarter = (reference quarter - X+1) and set start date as first day of starting quarter and end date as the reference date.\n",
    "            5. To calculate the date range for \"last X weeks\", strictly follow the below conditions:\n",
    "                    For \"last 1 week\", consider exactly one week before the reference week and set start date as Monday and end date as Sunday of that week .\n",
    "                    For \"last X weeks\", where X is greater than 1, consider starting week = (reference week - X+1) and set start date as Monday of starting week and end date as the reference date.\n",
    "            6. Provide the date range of each time point in start date - end date format always.\n",
    "\n",
    "            Step 4: Creating the response JSON\n",
    "            Strictly return the response in the exact same JSON format as follows. \n",
    "            Fill the information identified from above steps in the JSON. \n",
    "            The keys mentioned in upper case in the response are constant.\n",
    "            Return only if match is found from the context and non empty values are present.\n",
    "            Replace the placeholders \"<>\" with your findings.\n",
    "            {\n",
    "                \"MEASURE\": {\n",
    "                    \"<n-gram matched to MEASURE>\": [\n",
    "                        {\n",
    "                            \"ENTITY\": \"<Matched MEASURE>\",\n",
    "                            \"MEASURE CONSTRAINT\": [\n",
    "                                {\n",
    "                                    \"COMPARISON VALUE\": \"\",\n",
    "                                    \"COMPARSION OPERATOR\": \"\"\n",
    "                                }\n",
    "                            ],\n",
    "                            \"ADJECTIVE\": [],\n",
    "                            \"TONE\": \"\"\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "                \"DIMENSION\": {\n",
    "                    \"<n-gram matched to DIMENSION>\": [\n",
    "                        {\n",
    "                            \"ENTITY\": \"<Matched DIMENSION>\",\n",
    "                            \"RANK\": [{\"RANK ADJECTIVE\":\"\", \"RANK VALUE\": \"\"}],\n",
    "                            \"ADJECTIVE\": [],\n",
    "                            \"TONE\": \"\"\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "                \"FILTER\": {\n",
    "                    \"<n-gram matched to FILTER>\": [\n",
    "                        {\n",
    "                            \"ENTITY\": \"<Matched FILTER>\",\n",
    "                            \"PARENT\": \"<parent of the Matched FILTER>\",\n",
    "                            \"EXCLUDE\": \"\"\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "                \"DERIVED MEASURE\": {\n",
    "                    \"<n-gram matched to DERIVED MEASURE>\": [\n",
    "                        {\n",
    "                            \"ENTITY\": \"<Matched DERIVED MEASURE>\",\n",
    "                            \"RATIO FILTER\": [{}],\n",
    "                            \"APPLIED MEASURE\": [{\"<n-gram matched to MEASURE>\": \"<Matched MEASURE>\"}],\n",
    "                            \"DERIVED MEASURE CONSTRAINT\": [\n",
    "                                {\n",
    "                                    \"COMPARISON VALUE\": \"\",\n",
    "                                    \"COMPARSION OPERATOR\": \"\"\n",
    "                                }\n",
    "                            ],\n",
    "                            \"ADJECTIVE\": [],\n",
    "                            \"TONE\": \"\"\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "                \"DATE VARIABLE\": {\n",
    "                    \"asked time element\": [{\"ENTITY\": \"<Matched DATE VARIABLE>\"\n",
    "                        \"DATE RANGE\": \"date range\",\n",
    "                        \"CONVERTED TIME ELEMENT\": \"<converted time element>\"\n",
    "                        }]\n",
    "                }\n",
    "            }\n",
    "\n",
    "            Provide reasoning\n",
    "            \"\"\"\n",
    "        from transformers import pipeline\n",
    "        import time\n",
    "        import torch\n",
    "        from huggingface_hub.utils import disable_progress_bars\n",
    "        disable_progress_bars()\n",
    "        if self.model_loaded is None:\n",
    "            print(\"LLM model loading Open_Chat_3_5\")\n",
    "            self.model_loaded = pipeline(\"text-generation\", model= self.model_name, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "            \n",
    "    def request_processing_fn(self, request) :\n",
    "        \"\"\"\n",
    "        Processes Request Object -> List[{\"question\": \"\",\"context\":\"\"},{\"question\": \"\",\"context\":\"\"},...]\n",
    "\n",
    "        :return: (n_inputs, payload's)\n",
    "\n",
    "        Warnings:\n",
    "        1. Do not reshape your final output for single sample here, do it in prediction.\n",
    "           Else payloads will be invalidated for extraction at raw and extraction level.\n",
    "        \"\"\"\n",
    "        final_payload = []\n",
    "        raw_payload = request.json[\"payload\"]\n",
    "        return (len(raw_payload), raw_payload) \n",
    "    \n",
    "    def pre_processing_fn(self,payload):\n",
    "        return payload\n",
    "\n",
    "    \n",
    "    def prediction_fn(self,\n",
    "                      model: Any,\n",
    "                      input_query\n",
    "                       ):\n",
    "        \"\"\"\n",
    "                Does the main prediction on pre_processed_input(Single Sample) using supplied model .\n",
    "\n",
    "                :param model: Supported Model\n",
    "                :param pre_processed_input: Single Preprocessed Payload\n",
    "                :return: Prediction Value From the model\n",
    "                \n",
    "                Important Notes:\n",
    "                - Reshape your data array.reshape(1, -1) before predictions as it contains a single sample.\n",
    "                    \n",
    "        \"\"\"\n",
    "        question = input_query[\"question\"]\n",
    "        context = input_query[\"context\"]\n",
    "        query = \"\"\"Now Based on this following context: \\n \"\"\"+ str(context) + \"\\n return a response for this question:\\n\" + question + \"\\n\"\n",
    "        prompt = f\"\"\"<s>[IDENTITY]\n",
    "                    {self.base_prompt}\n",
    "                    [/IDENTITY]</s>\n",
    "                    [INST]\n",
    "                    {query}\n",
    "                    [/INST]\n",
    "                    \"\"\"\n",
    "        print(\"Prompting has started\")\n",
    "        start = time.now()\n",
    "        response = self.model_loaded(prompt, max_new_tokens=1024*4)#.to(\"cuda\")\n",
    "        print(f\"Total time taken = {time.now()-start}\")\n",
    "        response = response[0][\"generated_text\"]\n",
    "        preds = response.split(\"[SOL]\")[-1].split(\"[/SOL]\")[0]\n",
    "        print(\"prediction is \\n: \",preds)\n",
    "        return [preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee7f40d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:torch.distributed.nn.jit.instantiator:Created a temporary directory at /tmp/tmpqpqouwjk\n",
      "INFO:torch.distributed.nn.jit.instantiator:Writing /tmp/tmpqpqouwjk/_remote_module_non_scriptable.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM model loading Open_Chat_3_5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not load model /data/huggingface/cache/models--openchat--openchat_3.5/snapshots/2d39b2e68fc16446e1760700e0de14721434cbbf with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForCausalLM'>, <class 'transformers.models.mistral.modeling_mistral.MistralForCausalLM'>). See the original errors:\n\nwhile loading with AutoModelForCausalLM, an error is thrown:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.8/site-packages/transformers/pipelines/base.py\", line 269, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n  File \"/opt/conda/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py\", line 566, in from_pretrained\n    return model_class.from_pretrained(\n  File \"/opt/conda/lib/python3.8/site-packages/transformers/modeling_utils.py\", line 3480, in from_pretrained\n    ) = cls._load_pretrained_model(\n  File \"/opt/conda/lib/python3.8/site-packages/transformers/modeling_utils.py\", line 3601, in _load_pretrained_model\n    raise ValueError(\nValueError: The current `device_map` had weights offloaded to the disk. Please provide an `offload_folder` for them. Alternatively, make sure you have `safetensors` installed if the model you are using offers the weights in this format.\n\nwhile loading with MistralForCausalLM, an error is thrown:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.8/site-packages/transformers/pipelines/base.py\", line 269, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n  File \"/opt/conda/lib/python3.8/site-packages/transformers/modeling_utils.py\", line 3480, in from_pretrained\n    ) = cls._load_pretrained_model(\n  File \"/opt/conda/lib/python3.8/site-packages/transformers/modeling_utils.py\", line 3601, in _load_pretrained_model\n    raise ValueError(\nValueError: The current `device_map` had weights offloaded to the disk. Please provide an `offload_folder` for them. Alternatively, make sure you have `safetensors` installed if the model you are using offers the weights in this format.\n\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m score_ \u001b[38;5;241m=\u001b[39m \u001b[43mScoreTemplateExample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m req \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mRequest()\n\u001b[1;32m      3\u001b[0m req\u001b[38;5;241m.\u001b[39mjson \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpayload\u001b[39m\u001b[38;5;124m\"\u001b[39m:[{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop 2 segments and bottom 3 sub-category basis quantity\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m:context}]}\n",
      "Cell \u001b[0;32mIn[5], line 127\u001b[0m, in \u001b[0;36mScoreTemplateExample.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_loaded \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLLM model loading Open_Chat_3_5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_loaded \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext-generation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfloat16\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/pipelines/__init__.py:870\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    869\u001b[0m     model_classes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[0;32m--> 870\u001b[0m     framework, model \u001b[38;5;241m=\u001b[39m \u001b[43minfer_framework_load_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframework\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframework\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m model_config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n\u001b[1;32m    881\u001b[0m hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39m_commit_hash\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/pipelines/base.py:282\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[0;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m class_name, trace \u001b[38;5;129;01min\u001b[39;00m all_traceback\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    281\u001b[0m             error \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhile loading with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, an error is thrown:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtrace\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 282\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    283\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not load model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with any of the following classes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_tuple\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. See the original errors:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merror\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m         )\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    287\u001b[0m     framework \u001b[38;5;241m=\u001b[39m infer_framework(model\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Could not load model /data/huggingface/cache/models--openchat--openchat_3.5/snapshots/2d39b2e68fc16446e1760700e0de14721434cbbf with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForCausalLM'>, <class 'transformers.models.mistral.modeling_mistral.MistralForCausalLM'>). See the original errors:\n\nwhile loading with AutoModelForCausalLM, an error is thrown:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.8/site-packages/transformers/pipelines/base.py\", line 269, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n  File \"/opt/conda/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py\", line 566, in from_pretrained\n    return model_class.from_pretrained(\n  File \"/opt/conda/lib/python3.8/site-packages/transformers/modeling_utils.py\", line 3480, in from_pretrained\n    ) = cls._load_pretrained_model(\n  File \"/opt/conda/lib/python3.8/site-packages/transformers/modeling_utils.py\", line 3601, in _load_pretrained_model\n    raise ValueError(\nValueError: The current `device_map` had weights offloaded to the disk. Please provide an `offload_folder` for them. Alternatively, make sure you have `safetensors` installed if the model you are using offers the weights in this format.\n\nwhile loading with MistralForCausalLM, an error is thrown:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.8/site-packages/transformers/pipelines/base.py\", line 269, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n  File \"/opt/conda/lib/python3.8/site-packages/transformers/modeling_utils.py\", line 3480, in from_pretrained\n    ) = cls._load_pretrained_model(\n  File \"/opt/conda/lib/python3.8/site-packages/transformers/modeling_utils.py\", line 3601, in _load_pretrained_model\n    raise ValueError(\nValueError: The current `device_map` had weights offloaded to the disk. Please provide an `offload_folder` for them. Alternatively, make sure you have `safetensors` installed if the model you are using offers the weights in this format.\n\n\n"
     ]
    }
   ],
   "source": [
    "score_ = ScoreTemplateExample()\n",
    "req = requests.Request()\n",
    "req.json = {\"payload\":[{\"question\":\"top 2 segments and bottom 3 sub-category basis quantity\",\"context\":context}]}\n",
    "score_.score(None, req, dry_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc341beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VALIDATION</th>\n",
       "      <th>COMPONENT</th>\n",
       "      <th>PASSED</th>\n",
       "      <th>SKIPPED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Return Type Must Be Tuple (n_input, payloads)</td>\n",
       "      <td>request_processing_fn</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuple Must Be of length Two (n_input, payloads)</td>\n",
       "      <td>request_processing_fn</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>* if n_input &gt; 1 payload type must be List (n_input, [np.ndarray, tf.Tensor, etc])</td>\n",
       "      <td>request_processing_fn</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           VALIDATION  \\\n",
       "0                                       Return Type Must Be Tuple (n_input, payloads)   \n",
       "1                                     Tuple Must Be of length Two (n_input, payloads)   \n",
       "2  * if n_input > 1 payload type must be List (n_input, [np.ndarray, tf.Tensor, etc])   \n",
       "\n",
       "               COMPONENT  PASSED  SKIPPED  \n",
       "0  request_processing_fn    True    False  \n",
       "1  request_processing_fn    True    False  \n",
       "2  request_processing_fn    True    False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fields Marked Asterisk (*) Can Be Validated On Proper Input \n",
      "\n",
      "Prompting has started\n",
      "prediction is \n",
      ":  \n",
      "                    {\n",
      "                        \"MEASURE\": {\n",
      "                            \"Quantity\": [\n",
      "                                {\n",
      "                                    \"ENTITY\": \"Quantity\",\n",
      "                                    \"MEASURE CONSTRAINT\": [\n",
      "                                        {\n",
      "                                            \"COMPARISON VALUE\": \"\",\n",
      "                                            \"COMPARSION OPERATOR\": \"\"\n",
      "                                        }\n",
      "                                    ],\n",
      "                                    \"ADJECTIVE\": [],\n",
      "                                    \"TONE\": \"\"\n",
      "                                }\n",
      "                            ]\n",
      "                        },\n",
      "                        \"DIMENSION\": {\n",
      "                            \"Segment\": [\n",
      "                                {\n",
      "                                    \"ENTITY\": \"Segment\",\n",
      "                                    \"RANK\": [\n",
      "                                        {\n",
      "                                            \"RANK ADJECTIVE\": \"top\",\n",
      "                                            \"RANK VALUE\": \"2\"\n",
      "                                        }\n",
      "                                    ],\n",
      "                                    \"ADJECTIVE\": [],\n",
      "                                    \"TONE\": \"\"\n",
      "                                }\n",
      "                            ],\n",
      "                            \"Sub-Category\": [\n",
      "                                {\n",
      "                                    \"ENTITY\": \"Sub-Category\",\n",
      "                                    \"RANK\": [\n",
      "                                        {\n",
      "                                            \"RANK ADJECTIVE\": \"bottom\",\n",
      "                                            \"RANK VALUE\": \"3\"\n",
      "                                        }\n",
      "                                    ],\n",
      "                                    \"ADJECTIVE\": [],\n",
      "                                    \"TONE\": \"\"\n",
      "                                }\n",
      "                            ]\n",
      "                        },\n",
      "                        \"FILTER\": [],\n",
      "                        \"DERIVED MEASURE\": [],\n",
      "                        \"DATE VARIABLE\": {\n",
      "                            \"Order Date\": [\n",
      "                                {\n",
      "                                    \"ENTITY\": \"Order Date\",\n",
      "                                    \"DATE RANGE\": \"date range\",\n",
      "                                    \"CONVERTED TIME ELEMENT\": \"date range\"\n",
      "                                }\n",
      "                            ]\n",
      "                        }\n",
      "                    }\n",
      "                    \n",
      "CPU times: user 40min 41s, sys: 1min, total: 41min 42s\n",
      "Wall time: 5min 14s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<<ScoreResponse>>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "req = requests.Request()\n",
    "req.json = {\"payload\":[{\"question\":\"top 2 segments and bottom 3 sub-category basis quantity\",\"context\":context}]}\n",
    "score_.score(None, req, dry_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fc61fc2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VALIDATION</th>\n",
       "      <th>COMPONENT</th>\n",
       "      <th>PASSED</th>\n",
       "      <th>SKIPPED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Return Type Must Be Tuple (n_input, payloads)</td>\n",
       "      <td>request_processing_fn</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuple Must Be of length Two (n_input, payloads)</td>\n",
       "      <td>request_processing_fn</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>* if n_input &gt; 1 payload type must be List (n_input, [np.ndarray, tf.Tensor, etc])</td>\n",
       "      <td>request_processing_fn</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           VALIDATION  \\\n",
       "0                                       Return Type Must Be Tuple (n_input, payloads)   \n",
       "1                                     Tuple Must Be of length Two (n_input, payloads)   \n",
       "2  * if n_input > 1 payload type must be List (n_input, [np.ndarray, tf.Tensor, etc])   \n",
       "\n",
       "               COMPONENT  PASSED  SKIPPED  \n",
       "0  request_processing_fn    True    False  \n",
       "1  request_processing_fn    True    False  \n",
       "2  request_processing_fn    True    False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fields Marked Asterisk (*) Can Be Validated On Proper Input \n",
      "\n",
      "promting has started\n",
      "prediction is \n",
      ":  \n",
      "                    {\n",
      "                        \"MEASURE\": {\n",
      "                            \"segment\": [\n",
      "                                {\n",
      "                                    \"ENTITY\": \"segments\",\n",
      "                                    \"MEASURE CONSTRAINT\": [\n",
      "                                        {\n",
      "                                            \"COMPARISON VALUE\": \"\",\n",
      "                                            \"COMPARSION OPERATOR\": \"\"\n",
      "                                        }\n",
      "                                    ],\n",
      "                                    \"ADJECTIVE\": [],\n",
      "                                    \"TONE\": \"\"\n",
      "                                }\n",
      "                            ]\n",
      "                        },\n",
      "                        \"DIMENSION\": {\n",
      "                            \"quantity\": [\n",
      "                                {\n",
      "                                    \"ENTITY\": \"quantity\",\n",
      "                                    \"RANK\": [\n",
      "                                        {\n",
      "                                            \"RANK ADJECTIVE\": \"top\",\n",
      "                                            \"RANK VALUE\": \"2\"\n",
      "                                        }\n",
      "                                    ],\n",
      "                                    \"ADJECTIVE\": [],\n",
      "                                    \"TONE\": \"\"\n",
      "                                }\n",
      "                            ]\n",
      "                        },\n",
      "                        \"FILTER\": {},\n",
      "                        \"DERIVED MEASURE\": {},\n",
      "                        \"DATE VARIABLE\": {}\n",
      "                    }\n",
      "                    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<<ScoreResponse>>]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "req = requests.Request()\n",
    "req.json = {\"payload\":[{\"question\":\"top 2 segments basis quantity\",\"context\":context}]}\n",
    "score_.score(None, req, dry_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e3b7ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=\"/data/huggingface/cache/models--openchat--openchat_3.5/snapshots/2d39b2e68fc16446e1760700e0de14721434cbbf\"\n",
    "#model=score_.model_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4590e224",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:PASS:: Mandatory Validation :: dict_keys(['name', 'description', 'flavour', 'scoring_func'])\n",
      "INFO:root:PASS:: AlphaNumeric Validation :: dict_keys(['name'])\n",
      "INFO:root:PASS:: Validation/IfPresentTypeCheck :: dict_keys(['schema', 'metadata_info', 'tags'])\n",
      "INFO:root:PASS:: Validation/IfPresentSubfieldMustExist :: dict_keys(['kyd'])\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): mosaic-ai-backend:5000\n",
      "DEBUG:urllib3.connectionpool:http://mosaic-ai-backend:5000 \"POST /registry/api/v1/ml-model/register HTTP/1.1\" 200 2119\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): mosaic-ai-backend:5000\n",
      "DEBUG:urllib3.connectionpool:http://mosaic-ai-backend:5000 \"GET /registry/api/v1/ml-model/c7570892-a4e2-40a6-8ca0-94eed8dea3c6 HTTP/1.1\" 200 2112\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): mosaic-ai-backend:5000\n",
      "DEBUG:urllib3.connectionpool:http://mosaic-ai-backend:5000 \"GET /registry/api/v1/ml-model/c7570892-a4e2-40a6-8ca0-94eed8dea3c6 HTTP/1.1\" 200 2112\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ada7acee67eb4cd4b616074d2399ff19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<style>.grad_1{background: #2468a4;} .grad_2{ color:white; background: #2468a4;}</s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "register_model(model,\n",
    "               ScoreTemplateExample2,\n",
    "               \"Open_Chat_iMQL_Generator_for_GPU\",\n",
    "               \"IMQL_Generator_using_open_chat_3_5_for_GPU\",\n",
    "               MLModelFlavours.pytorch,\n",
    "               init_script=\"\"\"sudo chmod -R 777 /home/mosaic-ai/.cache\\\\npip install torch \\\\npip install --upgrade transformers\\\\npip install accelerate\"\"\"\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c9d796",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
